<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ramirodcrego</title>
    <link>//localhost:4321/</link>
      <atom:link href="//localhost:4321/index.xml" rel="self" type="application/rss+xml" />
    <description>ramirodcrego</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 18 Jul 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>//localhost:4321/media/icon_hu68170e94a17a2a43d6dcb45cf0e8e589_3079_512x512_fill_lanczos_center_3.png</url>
      <title>ramirodcrego</title>
      <link>//localhost:4321/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>//localhost:4321/event/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>//localhost:4321/event/example/</guid>
      <description>&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Hugo Blox Builder&amp;rsquo;s &lt;a href=&#34;https://docs.hugoblox.com/reference/content-types/&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>//localhost:4321/projects/</link>
      <pubDate>Sun, 21 Jul 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/projects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Web apps</title>
      <link>//localhost:4321/apps/</link>
      <pubDate>Sun, 21 Jul 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/apps/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Implementation of species distribution models in Google Earth Engine</title>
      <link>//localhost:4321/teaching/gee/</link>
      <pubDate>Thu, 18 Jul 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/teaching/gee/</guid>
      <description>&lt;p&gt;Ramiro D. Crego 1,2, Jared A. Stabach 1 and Grant Connette 1,2&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Smithsonian National Zoo and Conservation Biology Institute,
Conservation Ecology Center, 1500 Remount Rd, Front Royal, VA 22630,
USA.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Working Land and Seascapes, Conservation Commons, Smithsonian
Institution, Washington, DC 20013, USA.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;This is a guide for modeling species distributions and habitat
suitability in Google Earth Engine. This guide is intended to explain
the details of the Earth Engine code developed for this manuscript.&lt;/p&gt;
&lt;figure&gt;&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1111/ddi.13491&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;./Figures/26.png&#34;/&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;We first cover the basics for importing data and setting the main
arguments used in different functions, such as, grid size and the area
of interest. We then expand on different modelling workflows using three
different case studies to demonstrate how to adapt the code workflow for
different goals.&lt;/p&gt;
&lt;p&gt;For information on how to set up a Google Earth Engine account as well
as user guidelines and tutorials visit:
&lt;a href=&#34;https://developers.google.com/earth-engine/&#34;&gt;https://developers.google.com/earth-engine/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The code found below can also be accessed through the GEE repository for
this study:
&lt;a href=&#34;https://code.earthengine.google.com/?accept_repo=users/ramirocrego84/SDM_Manuscript&#34;&gt;https://code.earthengine.google.com/?accept_repo=users/ramirocrego84/SDM_Manuscript&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This are a set of video tutorials explaining step by step the basics of GEE and fitting species distribution models in GEE.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introduction to GEE and JavaScript&lt;/strong&gt;:


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/e9QfJ0cIBcs?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Management in GEE&lt;/strong&gt;:


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/5alN74QJbqI?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Species Distribution Models in GEE&lt;/strong&gt;:


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/54PPKkblAks?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;
&lt;/p&gt;
&lt;h2 id=&#34;general-settings-for-running-sdms-in-google-earth-engine&#34;&gt;General settings for running SDMs in Google Earth Engine&lt;/h2&gt;
&lt;h3 id=&#34;importing-species-location-data-as-an-asset&#34;&gt;Importing species location data as an asset&lt;/h3&gt;
&lt;p&gt;Datasets need to be uploaded as assets in Google Earth Engine. The
easiest way to do this is by creating a csv file with spatial
coordinates and any other desired attribute information. Note that you
can also upload an ESRI Shapefile with the species location data.&lt;/p&gt;
&lt;p&gt;Below is an example for uploading the &lt;em&gt;Bradypus variegatus&lt;/em&gt; data set
from a &lt;code&gt;csv&lt;/code&gt; file. Prepare a &lt;code&gt;csv&lt;/code&gt; file with coordinates in latitude and
longitude (EPSG:4326). To include a column with date use format
Year-Month-Day (e.g., 2000-01-30).&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig1.jpg&#34;
alt=&#34;Figure S1. Steps for uploading assets to Google Earth Engine. 1) Click ‘New’ under the Assets tab and then select ‘CSV file (.csv)’. 2) Click ‘SELECT’. 3) Browse and select the file from your computer. 4) Provide a name for the asset and the names of the columns containing coordinates in degrees.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S1. Steps for uploading assets to
Google Earth Engine. 1) Click ‘New’ under the Assets tab and then select
‘CSV file (.csv)’. 2) Click ‘SELECT’. 3) Browse and select the file from
your computer. 4) Provide a name for the asset and the names of the
columns containing coordinates in degrees.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;loading-and-cleaning-your-species-data&#34;&gt;Loading and cleaning your species data&lt;/h3&gt;
&lt;p&gt;To import the asset into your active script you can click on the forward
arrow icon on your asset manager or you can use code to programmatically
load the data as a new object. We recommend using code to import data.
To import the asset with your species presence data, use the
&lt;code&gt;ee.FeatureCollection()&lt;/code&gt; function and provide the asset ID. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var Data = ee.FeatureCollection(&#39;users/yourfolder/yourdata&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One important step in modeling species distributions is to limit the
potential effect of geographic sampling bias on the model output due to
data aggregation resulting from multiple nearby observations.&lt;/p&gt;
&lt;p&gt;We thin the location data to one randomly selected occurrence record per
pixel at the chosen spatial resolution (the raster pixel or grain size
of the analysis).&lt;/p&gt;
&lt;p&gt;Here, we will apply a function to remove all points that lay within the
same raster cell at a given grain size. For this, we first need to
define the spatial resolution of our study.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Define spatial resolution to work with (m)
var GrainSize = 10000; // e.g. 10 km
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we can define a function to remove duplicates and apply it to the
species data set.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function RemoveDuplicates(data){
  var randomraster = ee.Image.random().reproject(&#39;EPSG:4326&#39;, null, GrainSize);
  var randpointvals = randomraster.sampleRegions({collection:ee.FeatureCollection(data), scale: 10, geometries: true});
  return randpointvals.distinct(&#39;random&#39;);
}

var Data = RemoveDuplicates(Data);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following figure exemplifies how points are rarefied at a 1 km grain
size.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig2.png&#34;
alt=&#34;Figure S2. Example of presence point filtering. A) Original dataset; B) Final dataset with only one presence point retained per pixel.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S2. Example of presence point
filtering. A) Original dataset; B) Final dataset with only one presence
point retained per pixel.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;You can evaluate the number of points before and after removing
duplicates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;print(ee.FeatureCollection(&#39;users/yourfolder/yourimage&#39;).size())
print(Data.size())
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;define-your-area-of-interest-for-modeling&#34;&gt;Define your area of interest for modeling&lt;/h3&gt;
&lt;p&gt;The extent of the analysis should be carefully selected and constrained
to a realistic realm of the species of study, avoiding unrealistic
extents that can hamper model accuracy and predictions (Guisan et al.,
2017; Leroy et al., 2018; Sillero et al., 2021).&lt;/p&gt;
&lt;p&gt;There are different ways you can define your area of interest. You can
directly draw a polygon using the drawing tools in GEE or manually set
the polygon (e.g., Case Study 2 in this tutorial). Here, we present two
methods for automating this process.&lt;/p&gt;
&lt;p&gt;If you are interested in working with a specific country or continent,
you can use the Large Scale International Boundary Polygons data set
available in GEE catalog.&lt;/p&gt;
&lt;p&gt;Here an example to select Kenya:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load region boundary from data catalog if working at a larger scale
var AOI = ee.FeatureCollection(&#39;USDOS/LSIB_SIMPLE/2017&#39;).filter(ee.Filter.eq(&#39;country_co&#39;, &#39;KE&#39;));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see the list of country codes at:
&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_FIPS_country_codes&#34;&gt;https://en.wikipedia.org/wiki/List_of_FIPS_country_codes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are interested in working within the entire African continent,
you can use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load country boundary from data catalog if working at a country scale
var AOI = ee.FeatureCollection(&#39;USDOS/LSIB_SIMPLE/2017&#39;).filter(ee.Filter.eq(&#39;wld_rgn&#39;, &#39;Africa&#39;));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another option is to select a bounding box around your species location
data. For example, we can define a bounding box using the function
&lt;code&gt;bounds()&lt;/code&gt; and add a buffer of 50 km.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Define the area of interest
var AOI = Data.geometry().bounds().buffer(50000);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To display the study area on the map use the following code and assign
the map layer the name ‘AOI’:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Add AOI to the map
Map.addLayer(AOI, {}, &#39;AOI&#39;, 1); // The number 1 indicates the zoom level. Higher numbers increases zoom level.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;selecting-predictor-variables&#34;&gt;Selecting predictor variables&lt;/h3&gt;
&lt;p&gt;One of the main advantages of implementing SDMs in Google Earth Engine
is to make use of the large number of datasets available as predictor
variables. This includes not only the bioclimatic variables from Hijmans
et al. (2005), but elevation data and derivatives (slope, aspect,
hillside, etc.), diverse vegetation indices, human modification indices,
nighttime light images, water bodies, hourly climatic data, land cover
classifications, roads or other infrastructure and even the raw pixel
values of satellite data. Depending on your area of interest, certain
regions have greater data availability. GEE also offers the opportunity
to directly include user-derived datasets in your analysis, such as
processed satellite imagery (e.g., a land cover classification that you
previously developed for your area of interest).&lt;/p&gt;
&lt;p&gt;Selecting predictor variables is a step in which the researcher needs to
rely on existing knowledge of the study species, such as the variables
that may affect its distribution, etc.&lt;/p&gt;
&lt;p&gt;To find spatial data sets, you can use the search bar. All information
related to each spatial dataset is available by clicking on the name of
the product. The code necessary to import the dataset is available as
shown in the following figure.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig3.JPG&#34;
alt=&#34;Figure S3. SRTM Digital Elevation Data description with code to import the dataset&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S3. SRTM Digital Elevation Data
description with code to import the dataset&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;// Example of code to import the SRTM Digital Elevation Data 30m
var Elev = ee.Image(&amp;quot;USGS/SRTMGL1_003&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the GEE function &lt;code&gt;ee.Algorithms.Terrain()&lt;/code&gt; allows you to
calculate slope, aspect, and hillshade from the elevation dataset.&lt;/p&gt;
&lt;p&gt;We will demonstrate different ways to import and manipulate spatial data
sets with the specific examples below.&lt;/p&gt;
&lt;h3 id=&#34;defining-an-area-to-create-pseudo-absences&#34;&gt;Defining an area to create pseudo-absences&lt;/h3&gt;
&lt;p&gt;When using presence only data, the most common methodology when using
data from online databases such as, GBIF, it is important to define the
area to create pseudo-absences. Choosing the proper method is a critical
step as it can affect model performance (Barbet-Massin, Jiguet, Albert,
&amp;amp; Thuiller, 2012). Here we show how to implement three different
methodologies. In all three, we first create a mask of the location of
the presence data to avoid randomly generating pseudo-absences at the
same pixels as presences.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Note: The mask to remove presence point locations from the area to
create pseudo-absences has a code problem that is now fixed. Also
see Study Case 1 on how to mask out water if your area of interest
includes areas over water.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Generate random pseudo-absences across the entire study area.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- --&gt;
&lt;pre&gt;&lt;code&gt;// Make an image out of the presence locations. The pixels where we have presence locations will be removed from the area to generate pseudo-absences.
// This will prevent having presence and pseudo-absences in the same pixel. 
var mask = Data
  .reduceToImage({
    properties: [&#39;random&#39;],
    reducer: ee.Reducer.first()
}).reproject(&#39;EPSG:4326&#39;, null, ee.Number(GrainSize)).mask().neq(1).selfMask();

var AreaForPA = mask.clip(AOI);
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;Generate pseudo-absences within a specified distance from presence
locations to limit pseudo-absences to areas potentially accessible
to the species (Araújo et al., 2019) and to account for the
potential geographical or environmental sampling bias of presence
records by creating pseudo-absences with a similar sampling bias
(Phillips et al., 2009). The &lt;code&gt;buffer()&lt;/code&gt; function determines the area
available for generating pseudo-absences, assuming that these areas
have the same sampling bias than the records and represent areas
where animals can disperse. The &lt;code&gt;buffer()&lt;/code&gt; function has two
arguments, the distance in meters for the buffer and the maximum
amount of error tolerated when approximating the buffer circle.
Larger maximum errors improve computing efficiency.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- --&gt;
&lt;pre&gt;&lt;code&gt;// Make an image out of the presence locations. The pixels where we have presence locations will be removed from the area to generate pseudo-absences.
// This will prevent having presence and pseudo-absences in the same pixel. 
var mask = Data
  .reduceToImage({
    properties: [&#39;random&#39;],
    reducer: ee.Reducer.first()
}).reproject(&#39;EPSG:4326&#39;, null, ee.Number(GrainSize)).mask().neq(1).selfMask();

// Option 2: Spatially constrained pseudo-absence selection to a buffer around presence points.
var buffer = 500000; // Distance in meters.
var AreaForPA = Data.geometry().buffer(buffer, 1000);
var AreaForPA = mask.clip(AreaForPA).clip(AOI);
right.addLayer(AreaForPA, {},&#39;Area to create pseudo-absences&#39;, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;Limit the area to select pseudo-absences by implementing an
environmental profiling technique, masking out the known
environmentally suitable locations, similar to other two-steps
methods for generating pseudo-absences (Chefaoui &amp;amp; Lobo, 2008;
Senay, Worner, &amp;amp; Ikeda, 2013).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This method requires fitting a clustering function to the occurrence
data. When you have a large presence dataset, you can randomly choose a
subset of the data with this line of code:
&lt;code&gt;Data.randomColumn().sort(&#39;random&#39;).limit(200)&lt;/code&gt; where the number in
&lt;code&gt;limit()&lt;/code&gt; specifies the number of random presence points used to train
the clustering algorithm. A critical step is to display the cluster
results and identify the correct cluster, zero or one, to use for
creation of pseudo-absences. The cluster ID is assigned in an
inconsistent manner and can change even when changing the order of the
same data input. We wrote a line of code to automatically identify the
cluster ID to define the area to create pseudo-absences. But it is
important to display the cluster results and confirm that the clustering
worked properly and that the correct cluster ID was identified before
creating the mask:
&lt;code&gt;var mask2 = Clresult.select([&#39;cluster&#39;]).eq(clustID)&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Make an image out of the presence locations. The pixels where we have presence locations will be removed from the area to generate pseudo-absences.
// This will prevent having presence and pseudo-absences in the same pixel. 
var mask = Data
  .reduceToImage({
    properties: [&#39;random&#39;],
    reducer: ee.Reducer.first()
}).reproject(&#39;EPSG:4326&#39;, null, ee.Number(GrainSize)).mask().neq(1).selfMask();

//Option 3: Environmental pseudo-absences selection (environmental profiling)
// Extract environmental values for a random subset of presence data
var PixelVals = predictors.sampleRegions({collection: Data.randomColumn().sort(&#39;random&#39;).limit(200), properties: [], tileScale: 16, scale: GrainSize});
// Perform k-means clustering based on Euclidean distance.
var clusterer = ee.Clusterer.wekaKMeans({nClusters:2, distanceFunction:&amp;quot;Euclidean&amp;quot;}).train(PixelVals);
// Assign pixels to clusters using the trained clusterer.
var Clresult = predictors.cluster(clusterer);
// Display cluster results and identify the cluster IDs for pixels similar and dissimilar to the presence data
Map.addLayer(Clresult.randomVisualizer(), {}, &#39;Clusters&#39;, 0);
// Mask pixels that are dissimilar to the presence data.
// Obtain the ID of the cluster similar to the presence data and use the opposite cluster to define the allowable area to for creating pseudo-absences.
var clustID = Clresult.sampleRegions({collection: Data.randomColumn().sort(&#39;random&#39;).limit(200), properties: [], tileScale: 16, scale: GrainSize});
clustID = ee.FeatureCollection(clustID).reduceColumns(ee.Reducer.mode(),[&#39;cluster&#39;]);
clustID = ee.Number(clustID.get(&#39;mode&#39;)).subtract(1).abs();
var mask2 = Clresult.select([&#39;cluster&#39;]).eq(clustID);
var AreaForPA = mask.updateMask(mask2).clip(AOI);

// Display area for creation of pseudo-absence
Map.addLayer(AreaForPA, {},&#39;Area to create pseudo-absences&#39;, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;case-study-1-modeling-bradypus-variegatus-habitat-suitability-and-predicted-distribution-using-presence-only-data&#34;&gt;Case Study 1: Modeling &lt;em&gt;Bradypus variegatus&lt;/em&gt; habitat suitability and predicted distribution using presence-only data&lt;/h2&gt;
&lt;p&gt;To demonstrate the basic code to conduct SDMs in Google Earth Engine, we
will use &lt;em&gt;Bradypus variegatus&lt;/em&gt; as a case study. This species has been
widely used to present other SDM software and R packages (Hijmans et
al., 2017; Kindt, 2018; Phillips et al., 2017, 2006) and allows us to
compare GEE outputs with other tools. We obtained occurrence data from
GBIF (GBIF.org &lt;/p&gt;
\[20 January 2021\]
&lt;p&gt; GBIF Occurrence Download
&lt;a href=&#34;https://doi.org/10.15468/dl.jxcv7e&#34;&gt;https://doi.org/10.15468/dl.jxcv7e&lt;/a&gt;). We filtered data to the period
from 2000 to 2020, retaining only georeferenced records with a
coordinate uncertainty &amp;lt; 250 m. We further cleaned the data set by
removing all locations that fall on top of buildings or water bodies
assuming they had incorrect coordinates.&lt;/p&gt;
&lt;h3 id=&#34;loading-species-location-data&#34;&gt;Loading species location data&lt;/h3&gt;
&lt;p&gt;We upload the presence data set, specify the spatial scale to work with
and randomly select one occurrence location per 1km grid cell.&lt;/p&gt;
&lt;p&gt;Note that the following code modifies the &lt;code&gt;ui.root&lt;/code&gt; to display two maps
on the map panel of the user interface, one for the habitat suitability
map and one for the potential distribution map.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////
// Section 1 - Species data
///////////////////////////////

// Load presence data
var Data = ee.FeatureCollection(&#39;users/ramirocrego84/BradypusVariegatus&#39;);
print(&#39;Original data size:&#39;, Data.size());

// Define spatial resolution to work with (m)
var GrainSize = 1000;

function RemoveDuplicates(data){
  var randomraster = ee.Image.random().reproject(&#39;EPSG:4326&#39;, null, GrainSize);
  var randpointvals = randomraster.sampleRegions({collection:ee.FeatureCollection(data), scale: 10, geometries: true});
  return randpointvals.distinct(&#39;random&#39;);
}

var Data = RemoveDuplicates(Data);
print(&#39;Final data size:&#39;, Data.size());

// Add two maps to the screen.
var left = ui.Map();
var right = ui.Map();
ui.root.clear();
ui.root.add(left);
ui.root.add(right);

// Link maps, so when you drag one map, the other will be moved in sync.
ui.Map.Linker([left, right], &#39;change-bounds&#39;);

// Visualize presence points on the map
//right.addLayer(Data, {color:&#39;red&#39;}, &#39;Presence&#39;, 1);
//left.addLayer(Data, {color:&#39;red&#39;}, &#39;Presence&#39;, 1);
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;In JavaScript you can activate or inactivate lines of code by using
//. JavaScript will omit all the text that comes after the //.
Commenting out code that prints objects or adds elements to the map is
a good practice to keep the code clean and efficient. Sometimes it can
help reduce the chance of reaching memory limits as we reduce the
number of processes being called. Another option is to use /* code
*/. All code in between will be inactivated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig4.png&#34;
alt=&#34;Figure S4. Presence data for Bradypus variegatus. Data were obtained from GBIF.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S4. Presence data for Bradypus
variegatus. Data were obtained from GBIF.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;defining-the-area-of-interest&#34;&gt;Defining the area of interest&lt;/h3&gt;
&lt;p&gt;The next step is to define the extent of the area of interest. Here we
defined a 100 km buffer around the bounding box containing all presence
data. The argument for the buffer distance is in meters.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;////////////////////////////////////////////
// Section 2 - Define Area of Interest
////////////////////////////////////////////

// Define the AOI
var AOI = Data.geometry().bounds().buffer({distance:50000, maxError:1000});

// Add border of study area to the map
var outline = ee.Image().byte().paint({
  featureCollection: AOI, color: 1, width: 3});
right.addLayer(outline, {palette: &#39;FF0000&#39;}, &amp;quot;Study Area&amp;quot;);
left.addLayer(outline, {palette: &#39;FF0000&#39;}, &amp;quot;Study Area&amp;quot;);

// Center each map to the area of interest
right.centerObject(AOI, 4); //Number indicates the zoom level
left.centerObject(AOI, 4); //Number indicates the zoom level
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that in the code we are using right and left instead of the
default Map statement now that we have divided the interactive map
into two elements, ‘right’ and ‘left’.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig5.png&#34;
alt=&#34;Figure S5. This figure shows the area of interest, which was defined as a 100 km buffer around the bounding box containing all presence locations.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S5. This figure shows the area of
interest, which was defined as a 100 km buffer around the bounding box
containing all presence locations.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;loading-predictor-variables&#34;&gt;Loading predictor variables&lt;/h3&gt;
&lt;p&gt;For this example, we selected a combination of climatic predictor
variables (temperature seasonality, maximum temperature of warmest
month, minimum temperature of coldest month and annual precipitation)
obtained from (Hijmans et al. 2005), elevation (Farr et al. 2007) and
percentage tree cover at 250 m resolution obtained from the Terra MODIS
Vegetation Continuous Fields (VCF) product. The VCF product is generated
yearly and produced using monthly composites of Terra MODIS Land Surface
Reflectance data. We estimated mean percentage tree cover for the period
of the occurrence data, 2003 to 2020. All predictor variables ultimately
need to be combined as bands into a single multi-band image. We also
mask oceans from the multi-band predictor image.&lt;/p&gt;
&lt;p&gt;The calculation of the median percentage tree cover for each pixel
across the annual MODIS images shows how powerful Google Earth Engine
can be for raster processing when creating predictor variables.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;////////////////////////////////////////////////
// Section 3 - Selecting Predictor Variables
////////////////////////////////////////////////

// Load WorldClim BIO Variables (a multiband image) from the data catalog
var BIO = ee.Image(&amp;quot;WORLDCLIM/V1/BIO&amp;quot;);

// Load elevation data from the data catalog and calculate slope, aspect, and a simple hillshade from the terrain Digital Elevation Model.
var Terrain = ee.Algorithms.Terrain(ee.Image(&amp;quot;USGS/SRTMGL1_003&amp;quot;));

// Load NDVI 250 m collection and estimate median annual tree cover value per pixel
var MODIS = ee.ImageCollection(&amp;quot;MODIS/006/MOD44B&amp;quot;);
var MedianPTC = MODIS.filterDate(&#39;2003-01-01&#39;, &#39;2020-12-31&#39;).select([&#39;Percent_Tree_Cover&#39;]).median();

// Combine bands into a single multi-band image
var predictors = BIO.addBands(Terrain).addBands(MedianPTC);

// Mask out ocean pixels from the predictor variable image
var watermask =  Terrain.select(&#39;elevation&#39;).gt(0); //Create a water mask
var predictors = predictors.updateMask(watermask).clip(AOI);

// Select subset of bands to keep for habitat suitability modeling
var bands = [&#39;bio04&#39;,&#39;bio05&#39;,&#39;bio06&#39;,&#39;bio12&#39;,&#39;elevation&#39;,&#39;Percent_Tree_Cover&#39;];
var predictors = predictors.select(bands);

// Display layers on the map
right.addLayer(predictors, {bands:[&#39;elevation&#39;], min: 0, max: 5000,  palette: [&#39;000000&#39;,&#39;006600&#39;, &#39;009900&#39;,&#39;33CC00&#39;,&#39;996600&#39;,&#39;CC9900&#39;,&#39;CC9966&#39;,&#39;FFFFFF&#39;,]}, &#39;Elevation (m)&#39;, 0);
right.addLayer(predictors, {bands:[&#39;bio05&#39;], min: 190, max: 400, palette:&#39;white,red&#39;}, &#39;Temperature seasonality&#39;, 0); 
right.addLayer(predictors, {bands:[&#39;bio12&#39;], min: 0, max: 4000, palette:&#39;white,blue&#39;}, &#39;Annual Mean Precipitation (mm)&#39;, 0); 
right.addLayer(predictors, {bands:[&#39;Percent_Tree_Cover&#39;], min: 1, max: 100, palette:&#39;white,yellow,green&#39;}, &#39;Percent_Tree_Cover&#39;, 0); 
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig6.png&#34;
alt=&#34;Figure S6. Examples of predictor variables. A) Elevation; B) Temperature seasonality; C) Annual precipitation; D) Median percentage of tree cover between 2003 and 2020.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S6. Examples of predictor
variables. A) Elevation; B) Temperature seasonality; C) Annual
precipitation; D) Median percentage of tree cover between 2003 and
2020.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;It is important to make sure that there is no significant correlation
among predictor variables that can cause collinearity. We account for
this by estimating the Spearman correlation among predictor variable
values at 5000 random locations. Highly correlated predictor variables
should not be included in the same model.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Estimate correlation among predictor variables

// Extract local covariate values from multi-band predictor image at 5000 random points
var DataCor = predictors.sample({scale: GrainSize, numPixels: 5000, geometries: true}); //Generate 5000 random points
var PixelVals = predictors.sampleRegions({collection: DataCor, scale: GrainSize, tileScale: 16}); //Extract covariate values

// To check all pairwise correlations we need to map the reduceColumns function across all pairwise combinations of predictors
var CorrAll = predictors.bandNames().map(function(i){
    var tmp1 = predictors.bandNames().map(function(j){
      var tmp2 = PixelVals.reduceColumns({
        reducer: ee.Reducer.spearmansCorrelation(),
        selectors: [i, j]
      });
    return tmp2.get(&#39;correlation&#39;);
    });
    return tmp1;
  });
print(&#39;Variables correlation matrix&#39;,CorrAll);
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;This is a function that requires a lot of memory in GEE as it is
working with a large feature collection. Once you have run the
correlation code and selected the final set of covariables to use, it
is recommended to comment out the print function so the correlations
between predictor variables are not run repeatedly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;creating-pseudo-absences&#34;&gt;Creating pseudo-absences&lt;/h3&gt;
&lt;p&gt;In this example, we use presence only data, the most common methodology
when using data from online databases such as, GBIF. We will generate
pseudo-absences to fit the model. But first, we need to define the area
in which random pseudo-absences can be generated.&lt;/p&gt;
&lt;p&gt;We used a two-step environmental profiling approach to restrict the area
for the creation of pseudo-absences. We first performed a k-means
clustering based on Euclidean distance for the presence data and then
created random pseudo-absences within the pixels classified as being
more dissimilar to the presence data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 4 - Defining area for pseudo-absences and spatial blocks for model fitting and cross validation
////////////////////////////////////////////////////////////////////////////////////////////////////////

// Make an image out of the presence locations. The pixels where we have presence locations will be removed from the area to generate pseudo-absences.
// This will prevent having presence and pseudo-absences in the same pixel. 
var mask = Data
  .reduceToImage({
    properties: [&#39;random&#39;],
    reducer: ee.Reducer.first()
}).reproject(&#39;EPSG:4326&#39;, null, ee.Number(GrainSize)).mask().neq(1).selfMask();

// Option 1: Simple random pseudo-absence selection across the entire area of interest.
// var AreaForPA = mask.updateMask(watermask).clip(AOI);

// Option 2: Spatially constrained pseudo-absence selection to a buffer around presence points.
//var buffer = 500000; // Distance in meters.
//var AreaForPA = Data.geometry().buffer({distance:buffer, maxError:1000});
//var AreaForPA = mask.clip(AreaForPA).updateMask(watermask).clip(AOI);
//right.addLayer(AreaForPA, {},&#39;Area to create pseudo-absences&#39;, 0);

//Option 3: Environmental pseudo-absences selection (environmental profiling)
// Extract environmental values for the a random subset of presence data
var PixelVals = predictors.sampleRegions({collection: Data.randomColumn().sort(&#39;random&#39;).limit(200), properties: [], tileScale: 16, scale: GrainSize});
// Perform k-means clusteringthe clusterer and train it using based on Eeuclidean distance.
var clusterer = ee.Clusterer.wekaKMeans({nClusters:2, distanceFunction:&amp;quot;Euclidean&amp;quot;}).train(PixelVals);
// Assign pixels to clusters using the trained clusterer
var Clresult = predictors.cluster(clusterer);
// Display cluster results and identify the cluster IDs for pixels similar and dissimilar to the presence data
right.addLayer(Clresult.randomVisualizer(), {}, &#39;Clusters&#39;, 0);
// Mask out pixels that are dissimilar to presence data.
// Obtain the ID of the cluster similar to the presence data and use the opposite cluster to define the allowable area to for creatinge pseudo-absences
var clustID = Clresult.sampleRegions({collection: Data.randomColumn().sort(&#39;random&#39;).limit(200), properties: [], tileScale: 16, scale: GrainSize});
clustID = ee.FeatureCollection(clustID).reduceColumns(ee.Reducer.mode(),[&#39;cluster&#39;]);
clustID = ee.Number(clustID.get(&#39;mode&#39;)).subtract(1).abs();
var mask2 = Clresult.select([&#39;cluster&#39;]).eq(clustID);
var AreaForPA = mask.updateMask(mask2).clip(AOI);

// Display area for creation of pseudo-absence
right.addLayer(AreaForPA, {palette: &#39;black&#39;},&#39;Area to create pseudo-absences&#39;, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./Figures/Fig7a.png&#34; alt=&#34;Figure S7a. Results from cluster analysis.&#34;&gt;
&lt;img src=&#34;./Figures/Fig7b.png&#34; alt=&#34;Figure S7b. Area to create pseudo-absences.&#34;&gt;&lt;/p&gt;
&lt;p&gt;For this case study, we implement a block repeated split-sample
cross-validation technique to randomly partition data for model training
and validation (Roberts et al., 2017; Valavi, Elith, Lahoz-Monfort, &amp;amp;
Guillera-Arroita, 2019). We then run multiple model iterations with
random block splits to create training and validation data sets.&lt;/p&gt;
&lt;p&gt;The argument &lt;code&gt;scale&lt;/code&gt; determines the range in m for each block. In this
case, we are using 200 km.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Define a function to create a grid over AOI
function makeGrid(geometry, scale) {
  // pixelLonLat returns an image with each pixel labeled with longitude and
  // latitude values.
  var lonLat = ee.Image.pixelLonLat();
  // Select the longitude and latitude bands, multiply by a large number then
  // truncate them to integers.
  var lonGrid = lonLat
    .select(&#39;longitude&#39;)
    .multiply(100000)
    .toInt();
  var latGrid = lonLat
    .select(&#39;latitude&#39;)
    .multiply(100000)
    .toInt();
  return lonGrid
    .multiply(latGrid)
    .reduceToVectors({
      geometry: geometry.buffer({distance:20000,maxError:1000}), //The buffer allows you to make sure the grid includes the borders of the AOI.
      scale: scale,
      geometryType: &#39;polygon&#39;,
    });
}
// Create grid and remove cells outside AOI
var Scale = 200000; // Set range in m to create spatial blocks
var grid = makeGrid(AOI, Scale);
var Grid = watermask.reduceRegions({collection: grid, reducer: ee.Reducer.mean()}).filter(ee.Filter.neq(&#39;mean&#39;,null));
right.addLayer(Grid, {},&#39;Grid for spatil block cross validation&#39;, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig8.png&#34;
alt=&#34;Figure S8. Visualization of blocks created for cross validation.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S8. Visualization of blocks
created for cross validation.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;model-fit-model-validation-and-model-predictions&#34;&gt;Model fit, model validation and model predictions&lt;/h3&gt;
&lt;p&gt;We can now fit the models. There are several functions that need to be
defined.&lt;/p&gt;
&lt;p&gt;The first function allows us to create random seeds for splitting
spatial blocks and generating pseudo-absences at each iteration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//////////////////////////////////
// Section 5 - Fitting SDM models
//////////////////////////////////

// Define function to generate a vector of random numbers between 1 and 1000
function runif(length) {
    return Array.apply(null, Array(length)).map(function() {
        return Math.round(Math.random() * (1000 - 1) + 1)
    });
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need to define a function to fit models.&lt;/p&gt;
&lt;p&gt;There are several non-parametric classification algorithms available in
GEE that can be implemented. These include random forest, support vector
machine, classification and regression trees, maximum entropy, and
gradient boosting.&lt;/p&gt;
&lt;p&gt;We implement a 10 block repeated split-sample cross-validation
technique. The number of pseudo-absences is balanced with the number of
presences for the training and validation data sets, as this practice is
recommended for machine learning classifiers (Evans et al., 2011;
Barbet-Massin et al. 2012). In this case, we will use random forest. But
note that in the &lt;code&gt;SDM&lt;/code&gt; function, we also provide the code to fit
gradient boosting classifiers. To change the classifier, you need to
comment out the random forest function call using two forward slashes
(&lt;code&gt;//&lt;/code&gt;) and activate the gradient boosting classifier.&lt;/p&gt;
&lt;p&gt;We use the &lt;code&gt;setOutputMode()&lt;/code&gt; function to obtain results as &lt;code&gt;PROBABILITY&lt;/code&gt;
and as &lt;code&gt;CLASSIFICATION&lt;/code&gt;. This allows us to obtain a binary output (i.e.,
predicted presence) to quickly visualize in the interactive map. Later
we will show how to define a threshold to transform the probability
output into a binary map.&lt;/p&gt;
&lt;p&gt;At each iteration, the spatial blocks will be randomly split into 70%
for model fitting and 30% for model validation, respectively.
Consequently, each of the 10 runs will have a different set of presence
and pseudo-absence points for model fitting and validation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Define SDM function
// Activate the desired classifier, random forest or gradient boosting. 
// Note that other algorithms are available in GEE. See ee.Classifiers on the documentation for more information.

function SDM(x) {
    var Seed = ee.Number(x);
    
    // Randomly split blocks for training and validation
    var GRID = ee.FeatureCollection(Grid).randomColumn({seed:Seed}).sort(&#39;random&#39;);
    var TrainingGrid = GRID.filter(ee.Filter.lt(&#39;random&#39;, split));  // Filter points with &#39;random&#39; property &amp;lt; split percentage
    var TestingGrid = GRID.filter(ee.Filter.gte(&#39;random&#39;, split));  // Filter points with &#39;random&#39; property &amp;gt;= split percentage

    // Presence
    var PresencePoints = ee.FeatureCollection(Data);
    PresencePoints = PresencePoints.map(function(feature){return feature.set(&#39;PresAbs&#39;, 1)});
    var TrPresencePoints = PresencePoints.filter(ee.Filter.bounds(TrainingGrid));  // Filter presence points for training 
    var TePresencePoints = PresencePoints.filter(ee.Filter.bounds(TestingGrid));  // Filter presence points for testing
    
    // Pseudo-absences
    var TrPseudoAbsPoints = AreaForPA.sample({region: TrainingGrid, scale: GrainSize, numPixels: TrPresencePoints.size().add(300), seed:Seed, geometries: true}); // We add extra points to account for those points that land in masked areas of the raster and are discarded. This ensures a balanced presence/pseudo-absence data set
    TrPseudoAbsPoints = TrPseudoAbsPoints.randomColumn().sort(&#39;random&#39;).limit(ee.Number(TrPresencePoints.size())); //Randomly retain the same number of pseudo-absences as presence data 
    TrPseudoAbsPoints = TrPseudoAbsPoints.map(function(feature){
        return feature.set(&#39;PresAbs&#39;, 0);
        });
    
    var TePseudoAbsPoints = AreaForPA.sample({region: TestingGrid, scale: GrainSize, numPixels: TePresencePoints.size().add(100), seed:Seed, geometries: true}); // We add extra points to account for those points that land in masked areas of the raster and are discarded. This ensures a balanced presence/pseudo-absence data set
    TePseudoAbsPoints = TePseudoAbsPoints.randomColumn().sort(&#39;random&#39;).limit(ee.Number(TePresencePoints.size())); //Randomly retain the same number of pseudo-absences as presence data 
    TePseudoAbsPoints = TePseudoAbsPoints.map(function(feature){
        return feature.set(&#39;PresAbs&#39;, 0);
        });

    // Merge presence and pseudo-absencepoints
    var trainingPartition = TrPresencePoints.merge(TrPseudoAbsPoints);
    var testingPartition = TePresencePoints.merge(TePseudoAbsPoints);

    // Extract local covariate values from multiband predictor image at training points
    var trainPixelVals = predictors.sampleRegions({collection: trainingPartition, properties: [&#39;PresAbs&#39;], scale: GrainSize, tileScale: 16, geometries: true});

    // Classify using random forest
    var Classifier = ee.Classifier.smileRandomForest({
       numberOfTrees: 500, //The number of decision trees to create.
       variablesPerSplit: null, //The number of variables per split. If unspecified, uses the square root of the number of variables.
       minLeafPopulation: 10,//Only create nodes whose training set contains at least this many points. Integer, default: 1
       bagFraction: 0.5,//The fraction of input to bag per tree. Default: 0.5.
       maxNodes: null,//The maximum number of leaf nodes in each tree. If unspecified, defaults to no limit.
       seed: Seed//The randomization seed.
      });
    
    // Classify using a gradient boosting
    // var ClassifierPr = ee.Classifier.smileGradientTreeBoost({
    //   numberOfTrees:500, //The number of decision trees to create.
    //   shrinkage: 0.005, //The shrinkage parameter in (0, 1) controls the learning rate of procedure. Default: 0.005
    //   samplingRate: 0.7, //The sampling rate for stochastic tree boosting. Default 0.07
    //   maxNodes: null, //The maximum number of leaf nodes in each tree. If unspecified, defaults to no limit.
    //   loss: &amp;quot;LeastAbsoluteDeviation&amp;quot;, //Loss function for regression. One of: LeastSquares, LeastAbsoluteDeviation, Huber.
    //   seed:Seed //The randomization seed.
    // });
  
    // Presence probability 
    var ClassifierPr = Classifier.setOutputMode(&#39;PROBABILITY&#39;).train(trainPixelVals, &#39;PresAbs&#39;, bands); 
    var ClassifiedImgPr = predictors.select(bands).classify(ClassifierPr);
    
    // Binary presence/absence map
    var ClassifierBin = Classifier.setOutputMode(&#39;CLASSIFICATION&#39;).train(trainPixelVals, &#39;PresAbs&#39;, bands); 
    var ClassifiedImgBin = predictors.select(bands).classify(ClassifierBin);
   
    return ee.List([ClassifiedImgPr, ClassifiedImgBin, trainingPartition, testingPartition]);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we need to define some parameters before executing the SDM function.
A variable with the percentage for data split, and a variable with the
number of iterations to run.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Define partition for training and testing data
var split = 0.70;  // // The proportion of the blocks used to select training data

// Define number of repetitions
var numiter = 10;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now map the model function. Instead of generating random numbers,
we will manually set 10 random numbers for reproducibility of results.
The length of the list of random seeds determines the number of
iterations of model fitting and validation to run, with each iteration
having a different set of presence and pseudo-absence points.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Fit SDM 
//var RanSeeds = runif(numiter)
//var results = ee.List(RanSeeds).map(SDM)

// While the runif function can be used to generate random seeds, we map the SDM function over random created numbers for reproducibility of results
var results = ee.List([35,68,43,54,17,46,76,88,24,12]).map(SDM);

// Extract results from list
var results = results.flatten();
//print(results); //Activate this line to visualize all elements
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can extract the model predictions and display them on the maps.
Note that we will also create some legends for each map.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////////////////////////////////////////
// Section 6 - Extracting and displaying model prediction results
///////////////////////////////////////////////////////////////////

// Habitat suitability

// Set visualization parameters
var visParams = {
  min: 0,
  max: 1,
  palette: [&amp;quot;#440154FF&amp;quot;,&amp;quot;#482677FF&amp;quot;,&amp;quot;#404788FF&amp;quot;,&amp;quot;#33638DFF&amp;quot;,&amp;quot;#287D8EFF&amp;quot;,
  &amp;quot;#1F968BFF&amp;quot;,&amp;quot;#29AF7FFF&amp;quot;,&amp;quot;#55C667FF&amp;quot;,&amp;quot;#95D840FF&amp;quot;,&amp;quot;#DCE319FF&amp;quot;],
};

// Extract all model predictions
var images = ee.List.sequence(0,ee.Number(numiter).multiply(4).subtract(1),4).map(function(x){
  return results.get(x)});

// You can add all the individual model predictions to the map. The number of layers to add will depend on how many iterations you selected.

// left.addLayer(ee.Image(images.get(0)), visParams, &#39;Run1&#39;);
// left.addLayer(ee.Image(image.get(1)), visParams, &#39;Run2&#39;);

// Calculate mean of all individual model runs
var ModelAverage = ee.ImageCollection.fromImages(images).mean();

// Add final habitat suitability layer and presence locations to the map
left.addLayer(ModelAverage, visParams, &#39;Habitat Suitability&#39;);
left.addLayer(Data, {color:&#39;red&#39;}, &#39;Presence&#39;, 1);

// Create legend for habitat suitability map.
var legend = ui.Panel({style: {position: &#39;bottom-left&#39;, padding: &#39;8px 15px&#39;}});

legend.add(ui.Label({
  value: &amp;quot;Habitat suitability&amp;quot;,
  style: {fontWeight: &#39;bold&#39;, fontSize: &#39;18px&#39;, margin: &#39;0 0 4px 0&#39;, padding: &#39;0px&#39;}
}));

legend.add(ui.Thumbnail({
  image: ee.Image.pixelLonLat().select(0),
  params: {
    bbox: [0,0,1,0.1],
    dimensions: &#39;200x20&#39;,
    format: &#39;png&#39;,
    min: 0,
    max: 1,
    palette: [&amp;quot;#440154FF&amp;quot;,&amp;quot;#482677FF&amp;quot;,&amp;quot;#404788FF&amp;quot;,&amp;quot;#33638DFF&amp;quot;,&amp;quot;#287D8EFF&amp;quot;,
  &amp;quot;#1F968BFF&amp;quot;,&amp;quot;#29AF7FFF&amp;quot;,&amp;quot;#55C667FF&amp;quot;,&amp;quot;#95D840FF&amp;quot;,&amp;quot;#DCE319FF&amp;quot;]
  },
  style: {stretch: &#39;horizontal&#39;, margin: &#39;8px 8px&#39;, maxHeight: &#39;40px&#39;},
}));

legend.add(ui.Panel({
  widgets: [
    ui.Label(&#39;Low&#39;, {margin: &#39;0px 0px&#39;, textAlign: &#39;left&#39;, stretch: &#39;horizontal&#39;}),
    ui.Label(&#39;Medium&#39;, {margin: &#39;0px 0px&#39;, textAlign: &#39;center&#39;, stretch: &#39;horizontal&#39;}),
    ui.Label(&#39;High&#39;, {margin: &#39;0px 0px&#39;, textAlign: &#39;right&#39;, stretch: &#39;horizontal&#39;}),
    ],layout: ui.Panel.Layout.Flow(&#39;horizontal&#39;)
}));

legend.add(ui.Panel(
  [ui.Label({value: &amp;quot;Presence locations&amp;quot;,style: {fontWeight: &#39;bold&#39;, fontSize: &#39;16px&#39;, margin: &#39;4px 0 4px 0&#39;}}),
   ui.Label({style:{color:&amp;quot;red&amp;quot;,margin: &#39;4px 0 0 4px&#39;}, value:&#39;◉&#39;})],
  ui.Panel.Layout.Flow(&#39;horizontal&#39;)));

left.add(legend);


// Distribution map

// Extract all model predictions
var images2 = ee.List.sequence(1,ee.Number(numiter).multiply(4).subtract(1),4).map(function(x){
  return results.get(x)});

// Calculate mean of all indivudual model runs
var DistributionMap = ee.ImageCollection.fromImages(images2).mode();

// Add final distribution map and presence locations to the map
right.addLayer(DistributionMap, 
  {palette: [&amp;quot;white&amp;quot;, &amp;quot;green&amp;quot;], min: 0, max: 1}, 
  &#39;Potential distribution&#39;);
right.addLayer(Data, {color:&#39;red&#39;}, &#39;Presence&#39;, 1);

// Create legend for distribution map
var legend2 = ui.Panel({style: {position: &#39;bottom-left&#39;,padding: &#39;8px 15px&#39;}});
legend2.add(ui.Label({
  value: &amp;quot;Potential distribution map&amp;quot;,
  style: {fontWeight: &#39;bold&#39;,fontSize: &#39;18px&#39;,margin: &#39;0 0 4px 0&#39;,padding: &#39;0px&#39;}
}));

var colors2 = [&amp;quot;green&amp;quot;,&amp;quot;white&amp;quot;];
var names2 = [&#39;Presence&#39;, &#39;Absence&#39;];
var entry2;
for (var x = 0; x&amp;lt;2; x++){
  entry2 = [
    ui.Label({style:{color:colors2[x],margin: &#39;4px 0 4px 0&#39;}, value:&#39;██&#39;}),
    ui.Label({value: names2[x],style: {margin: &#39;4px 0 4px 4px&#39;}})
  ];
  legend2.add(ui.Panel(entry2, ui.Panel.Layout.Flow(&#39;horizontal&#39;)));
}

legend2.add(ui.Panel(
  [ui.Label({value: &amp;quot;Presence locations&amp;quot;,style: {fontWeight: &#39;bold&#39;, fontSize: &#39;16px&#39;, margin: &#39;0 0 4px 0&#39;}}),
   ui.Label({style:{color:&amp;quot;red&amp;quot;,margin: &#39;0 0 4px 4px&#39;}, value:&#39;◉&#39;})],
  ui.Panel.Layout.Flow(&#39;horizontal&#39;)));

right.add(legend2);
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig9.png&#34;
alt=&#34;Figure S9. Visualization of predicted habitat suitability and potential distribution of Bradypus variegatus.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S9. Visualization of predicted
habitat suitability and potential distribution of &lt;em&gt;Bradypus
variegatus&lt;/em&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;It is important to understand that GEE does a resampling on the fly
for displaying maps. The resolution of the model output will change
with the zoom level. To set the visualization at the resolution of the
analysis defined with the grain size, you need to specify the
resolution of the image using the function &lt;code&gt;reproject()&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the next section, we will calculate the Area Under the Curve of the
Receiver Operator Characteristic (AUC-ROC)(Fielding and Bell, 1997) and
the Area Under the Precision-Recall Curve (AUC-PR; Sofaer, Hoeting, &amp;amp;
Jarnevich, 2019) for each run using the validation data sets. We will
then calculate the mean AUC-ROC and AUC-PR for the &lt;strong&gt;n&lt;/strong&gt; iterations.&lt;/p&gt;
&lt;p&gt;It is important to check that you have a sufficient number of points for
model validation at each run. Because the final number of points depends
on the random split of spatial blocks, you want to make sure there are
enough presence and pseudo-absence points for model validation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/////////////////////////////////////
// Section 7 - Accuracy assessment
/////////////////////////////////////

// Extract testing/validation data sets
var TestingDatasets = ee.List.sequence(3,ee.Number(numiter).multiply(4).subtract(1),4).map(function(x){
                      return results.get(x)});

// Double check that you have a satisfactory number of points for model validation
print(&#39;Number of presence and pseudo-absence points for model validation&#39;, ee.List.sequence(0,ee.Number(numiter).subtract(1),1)
.map(function(x){
  return ee.List([ee.FeatureCollection(TestingDatasets.get(x)).filter(ee.Filter.eq(&#39;PresAbs&#39;,1)).size(),
         ee.FeatureCollection(TestingDatasets.get(x)).filter(ee.Filter.eq(&#39;PresAbs&#39;,0)).size()]);
})
);

// Define functions to estimate sensitivity, specificity and precision at different thresholds.
function getAcc(img,TP){
  var Pr_Prob_Vals = img.sampleRegions({collection: TP, properties: [&#39;PresAbs&#39;], scale: GrainSize, tileScale: 16});
  var seq = ee.List.sequence({start: 0, end: 1, count: 25});
  return ee.FeatureCollection(seq.map(function(cutoff) {
  var Pres = Pr_Prob_Vals.filterMetadata(&#39;PresAbs&#39;,&#39;equals&#39;,1);
  // true-positive and true-positive rate, sensitivity  
  var TP =  ee.Number(Pres.filterMetadata(&#39;classification&#39;,&#39;greater_than&#39;,cutoff).size());
  var TPR = TP.divide(Pres.size());
  var Abs = Pr_Prob_Vals.filterMetadata(&#39;PresAbs&#39;,&#39;equals&#39;,0);
  // false-negative
  var FN = ee.Number(Pres.filterMetadata(&#39;classification&#39;,&#39;less_than&#39;,cutoff).size());
  // true-negative and true-negative rate, specificity  
  var TN = ee.Number(Abs.filterMetadata(&#39;classification&#39;,&#39;less_than&#39;,cutoff).size());
  var TNR = TN.divide(Abs.size());
  // false-positive and false-positive rate
  var FP = ee.Number(Abs.filterMetadata(&#39;classification&#39;,&#39;greater_than&#39;,cutoff).size());
  var FPR = FP.divide(Abs.size());
  // precision
  var Precision = TP.divide(TP.add(FP));
  // sum of sensitivity and specificity
  var SUMSS = TPR.add(TNR);
  return ee.Feature(null,{cutoff: cutoff, TP:TP, TN:TN, FP:FP, FN:FN, TPR:TPR, TNR:TNR, FPR:FPR, Precision:Precision, SUMSS:SUMSS});
  }));
}

// Calculate AUC of the Receiver Operator Characteristic
function getAUCROC(x){
  var X = ee.Array(x.aggregate_array(&#39;FPR&#39;));
  var Y = ee.Array(x.aggregate_array(&#39;TPR&#39;)); 
  var X1 = X.slice(0,1).subtract(X.slice(0,0,-1));
  var Y1 = Y.slice(0,1).add(Y.slice(0,0,-1));
  return X1.multiply(Y1).multiply(0.5).reduce(&#39;sum&#39;,[0]).abs().toList().get(0);
}

function AUCROCaccuracy(x){
  var HSM = ee.Image(images.get(x));
  var TData = ee.FeatureCollection(TestingDatasets.get(x));
  var Acc = getAcc(HSM, TData);
  return getAUCROC(Acc);
}


var AUCROCs = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(AUCROCaccuracy);
print(&#39;AUC-ROC:&#39;, AUCROCs);
print(&#39;Mean AUC-ROC&#39;, AUCROCs.reduce(ee.Reducer.mean()));


// Calculate AUC of Precision Recall Curve
function getAUCPR(roc){
  var X = ee.Array(roc.aggregate_array(&#39;TPR&#39;));
  var Y = ee.Array(roc.aggregate_array(&#39;Precision&#39;)); 
  var X1 = X.slice(0,1).subtract(X.slice(0,0,-1));
  var Y1 = Y.slice(0,1).add(Y.slice(0,0,-1));
  return X1.multiply(Y1).multiply(0.5).reduce(&#39;sum&#39;,[0]).abs().toList().get(0);
}

function AUCPRaccuracy(x){
  var HSM = ee.Image(images.get(x));
  var TData = ee.FeatureCollection(TestingDatasets.get(x));
  var Acc = getAcc(HSM, TData);
  return getAUCPR(Acc);
}

var AUCPRs = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(AUCPRaccuracy);
print(&#39;AUC-PR:&#39;, AUCPRs);
print(&#39;Mean AUC-PR&#39;, AUCPRs.reduce(ee.Reducer.mean()));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Accuracy assessment results are:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;AUC-ROC&lt;/th&gt;
&lt;th&gt;AUC-PR&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 1&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;td&gt;0.78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 2&lt;/td&gt;
&lt;td&gt;0.88&lt;/td&gt;
&lt;td&gt;0.81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 3&lt;/td&gt;
&lt;td&gt;0.79&lt;/td&gt;
&lt;td&gt;0.77&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 4&lt;/td&gt;
&lt;td&gt;0.96&lt;/td&gt;
&lt;td&gt;0.88&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 5&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;td&gt;0.92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 6&lt;/td&gt;
&lt;td&gt;0.96&lt;/td&gt;
&lt;td&gt;0.78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 7&lt;/td&gt;
&lt;td&gt;0.87&lt;/td&gt;
&lt;td&gt;0.82&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 8&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;td&gt;0.91&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 9&lt;/td&gt;
&lt;td&gt;0.94&lt;/td&gt;
&lt;td&gt;0.83&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 10&lt;/td&gt;
&lt;td&gt;0.83&lt;/td&gt;
&lt;td&gt;0.78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Mean&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.91&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.83&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In the next section we will extract sensitivity (correct predictions of
the occurrence) and specificity (correct predictions of the absence;
Fielding &amp;amp; Bell, 1997). These metrics require defining a threshold. For
each iteration, we use the threshold that maximizes the sum of
sensitivity and specificity. This threshold has been shown to perform
well with presence-only data (Liu, Newell, &amp;amp; White, 2016).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Function to extract other metrics
function getMetrics(x){
  var HSM = ee.Image(images.get(x));
  var TData = ee.FeatureCollection(TestingDatasets.get(x));
  var Acc = getAcc(HSM, TData);
  return Acc.sort({property:&#39;SUMSS&#39;,ascending:false}).first();
}

// Extract sensitivity, specificity and mean threshold values
var Metrics = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(getMetrics);
print(&#39;Sensitivity:&#39;, ee.FeatureCollection(Metrics).aggregate_array(&amp;quot;TPR&amp;quot;));
print(&#39;Specificity:&#39;, ee.FeatureCollection(Metrics).aggregate_array(&amp;quot;TNR&amp;quot;));

var MeanThresh = ee.Number(ee.FeatureCollection(Metrics).aggregate_array(&amp;quot;cutoff&amp;quot;).reduce(ee.Reducer.mean()));
print(&#39;Mean threshold:&#39;, MeanThresh);
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Sensitivity&lt;/th&gt;
&lt;th&gt;Specificity&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 1&lt;/td&gt;
&lt;td&gt;0.82&lt;/td&gt;
&lt;td&gt;0.94&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 2&lt;/td&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;0.63&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 3&lt;/td&gt;
&lt;td&gt;0.89&lt;/td&gt;
&lt;td&gt;0.63&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 4&lt;/td&gt;
&lt;td&gt;0.93&lt;/td&gt;
&lt;td&gt;0.91&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 5&lt;/td&gt;
&lt;td&gt;0.96&lt;/td&gt;
&lt;td&gt;0.87&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 6&lt;/td&gt;
&lt;td&gt;0.90&lt;/td&gt;
&lt;td&gt;0.96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 7&lt;/td&gt;
&lt;td&gt;0.75&lt;/td&gt;
&lt;td&gt;0.84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 8&lt;/td&gt;
&lt;td&gt;0.92&lt;/td&gt;
&lt;td&gt;0.90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 9&lt;/td&gt;
&lt;td&gt;0.89&lt;/td&gt;
&lt;td&gt;0.82&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 10&lt;/td&gt;
&lt;td&gt;0.91&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;strong&gt;Mean&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.90&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.81&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Finally, we can create a binary potential distribution map using the
mean threshold from the 10 model iterations.This operation is more
computationally demanding and is likely to give a memory limit error if
trying to add the resulting binary image directly to the interactive
map. If memory limits are reached, it is then necessary to use the batch
mode on GEE, directly exporting the output to Google Drive or Google
Cloud Storage.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;////////////////////////////////////////////////////////////////////////////////
// Section 8 - Create a custom binary distribution map based on best threshold
////////////////////////////////////////////////////////////////////////////////

// Calculating the potential distribution map based on the threshold 
// that maximizes the sum of sensitivity and specificity is computationally intensive and
// for large number of iterations may need to be executed using batch mode.
// In batch mode, the final image needs to exported to Google Drive and opened in 
// another software for visualization (or imported to GEE as an asset for visualization.
// Transform probability model output into a binary map using the defined threshold and set NA into -9999
// Transform probability model output into a binary map using the defined threshold and set NA into -9999
var DistributionMap2 = ModelAverage.gte(MeanThresh);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next section we will show how to export results to Google Drive
to then display it on a third party software.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig10.png&#34;
alt=&#34;Figure S10. Potential distribution of Bradypus variegatus calculated using a custom threshold. The final map was exported to Google Drive and displayed using QGIS.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S10. Potential distribution of
&lt;em&gt;Bradypus variegatus&lt;/em&gt; calculated using a custom threshold. The
final map was exported to Google Drive and displayed using
QGIS.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;exporting-results&#34;&gt;Exporting results&lt;/h3&gt;
&lt;p&gt;Here, we present code to export the final probability maps as well as
the accuracy metrics, training and validation data sets used for each
model. Note that there are other options to export data in GEE (see the
&lt;a href=&#34;https://developers.google.com/earth-engine/guides/exporting/&#34;&gt;https://developers.google.com/earth-engine/guides/exporting/&lt;/a&gt;(user
guide) for other ways to export data).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//////////////////////////////////////////////////////
// Section 9 - Export outputs
//////////////////////////////////////////////////////

// Export final model predictions to drive

// Averaged habitat suitability
Export.image.toDrive({
  image: ModelAverage, //Object to export
  description: &#39;HSI&#39;, //Name of the file
  scale: GrainSize, //Spatial resolution of the exported raster
  maxPixels: 1e10,
  region: AOI //Area of interest
});

// Export final binary model based on a mayority vote
Export.image.toDrive({
  image: DistributionMap, //Object to export
  description: &#39;PotentialDistribution&#39;, //Name of the file
  scale: GrainSize, //Spatial resolution of the exported raster
  maxPixels: 1e10,
  region: AOI //Area of interest
});

// Export final binary model based on the threshold that maximises the sum of specificity and sensitivity
Export.image.toDrive({
  image: DistributionMap2.unmask(-9999),
  description: &#39;PotentialDistributionThreshold&#39;,
  scale: GrainSize,
  maxPixels: 1e10,
  region: AOI
});


// Export Accuracy Assessment Metrics

Export.table.toDrive({
  collection: ee.FeatureCollection(AUCROCs
                        .map(function(element){
                        return ee.Feature(null,{AUCROC:element})})),
  description: &#39;AUCROC&#39;,
  fileFormat: &#39;CSV&#39;,
});

Export.table.toDrive({
  collection: ee.FeatureCollection(AUCPRs
                        .map(function(element){
                        return ee.Feature(null,{AUCPR:element})})),
  description: &#39;AUCPR&#39;,
  fileFormat: &#39;CSV&#39;,
});

Export.table.toDrive({
  collection: ee.FeatureCollection(Metrics),
  description: &#39;Metrics&#39;,
  fileFormat: &#39;CSV&#39;,
});

// Export training and validation data sets

// Extract training datasets
var TrainingDatasets = ee.List.sequence(1,ee.Number(numiter).multiply(4).subtract(1),4).map(function(x){
  return results.get(x)});

// If you are interested in exporting any of the training or testing datasets used for modeling,
// you need to extract the feature collections from the SDM output list and export them.
// Here is an example for exporting the training and validation data sets from the first iteration. 
// For other iterations you need to change the number in the get function. In JavaScript the first element of the list is indexed by 0.

Export.table.toDrive({
  collection: TrainingDatasets.get(0),
  description: &#39;TestingDataRun1&#39;,
  fileFormat: &#39;CSV&#39;,
});

Export.table.toDrive({
  collection: TestingDatasets.get(0),
  description: &#39;TestingDataRun1&#39;,
  fileFormat: &#39;CSV&#39;,
});
/*
*/
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;case-study-2-accounting-for-temporal-resolution-in-species-distribution-models&#34;&gt;Case Study 2: Accounting for temporal resolution in species distribution models&lt;/h2&gt;
&lt;p&gt;One main limitation in many SDMs is the lack of consideration for
temporal resolution when modeling habitat suitability and species
distributions (Araújo et al., 2019). We used &lt;em&gt;Cebus capucinus&lt;/em&gt; as an
example to demonstrate a framework that takes advantage of GEE to match
the observation date for each presence record to the raster image from a
collection that is closest in time. For example, we could extract the
normalized difference vegetation index (NDVI) at an occurrence location
from the satellite image that is closest in time to that species
observation.&lt;/p&gt;
&lt;h3 id=&#34;species-data-and-aoi&#34;&gt;Species data and AOI&lt;/h3&gt;
&lt;p&gt;We obtained occurrence data from GBIF (GBIF.org (27 January 2021)
&lt;a href=&#34;https://doi.org/10.15468/dl.qus4ha&#34;&gt;https://doi.org/10.15468/dl.qus4ha&lt;/a&gt;). We retained only georeferenced
records with a coordinate uncertainty &amp;lt; 250 m.&lt;/p&gt;
&lt;p&gt;For this example we will model &lt;em&gt;Cebus capucinus&lt;/em&gt; distribution in Panama
and Costa Rica, where most occurrence records are.&lt;/p&gt;
&lt;p&gt;As a note, some authors consider the subspecies &lt;em&gt;Cebus capucinus
imitator&lt;/em&gt; and &lt;em&gt;Cebus capucinus capucinus&lt;/em&gt; two distinct species which
distribution split in central Panama (Mittermeier et al., 2013). In this
study, we consider &lt;em&gt;Cebus capucinus&lt;/em&gt; as one taxon.&lt;/p&gt;
&lt;p&gt;For this example, we will manually define a study area geometry
encompassing the countries of Costa Rica and Panama.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;////////////////////////////////////
// Section 1 - Species data and AOI
////////////////////////////////////

var Data = ee.FeatureCollection(&#39;users/ramirocrego84/CebusCapucinus&#39;);

var AOI = ee.Geometry.Polygon([
  [-86.25662272529605,6.799166493750054],
  [-77.15994303779605,6.799166493750054],
  [-77.15994303779605,11.171211677305884],
  [-86.25662272529605,11.171211677305884],
  [-86.25662272529605,6.799166493750054]
]);

print(&#39;Original data size:&#39;, Data.size());
var Data = Data.filter(ee.Filter.bounds(AOI));

// Add border of study area to the map
var outline = ee.Image().byte().paint({
  featureCollection: AOI, color: 1, width: 3});
Map.addLayer(outline, {palette: &#39;FF0000&#39;}, &amp;quot;Study Area&amp;quot;);

// Center map to the area of interest
Map.centerObject(AOI, 6); //Number indicates the zoom level
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig11.png&#34;
alt=&#34;Figure S11. Defined area of interest to study change in Cebus capucinus habitat suitability.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S11. Defined area of interest to
study change in Cebus capucinus habitat suitability.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;We will use data between 2003 and 2018 for model fitting, after
filtering the data to retain a single record per year from each 250 m
pixel. To do so, we need to run the &lt;code&gt;removeduplicate()&lt;/code&gt; function for
each year at the specified grain size and then merge filtered data from
all years back together.&lt;/p&gt;
&lt;h3 id=&#34;define-spatial-resolution-and-remove-duplicates&#34;&gt;Define spatial resolution and remove duplicates&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;//////////////////////////////////////////////////////////////
// Section 2 - Define spatial resolution and remove duplicates
//////////////////////////////////////////////////////////////

// Define spatial resolution to work with (m)
var GrainSize = 250;

function RemoveDuplicates(data){
  var randomraster = ee.Image.random().reproject(&#39;EPSG:4326&#39;, null, GrainSize);
  var randpointvals = randomraster.sampleRegions({collection:ee.FeatureCollection(data), scale: 10, geometries: true});
  return randpointvals.distinct(&#39;random&#39;);
}

// Filter by year and eliminate points withing the same pixel at each year
var Data03 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2003-01-01&#39;, &#39;2003-12-31&#39;)));
var Data04 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2004-01-01&#39;, &#39;2004-12-31&#39;)));
var Data05 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2005-01-01&#39;, &#39;2005-12-31&#39;)));
var Data06 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2006-01-01&#39;, &#39;2006-12-31&#39;)));
var Data07 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2007-01-01&#39;, &#39;2007-12-31&#39;)));
var Data08 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2008-01-01&#39;, &#39;2008-12-31&#39;)));
var Data09 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2009-01-01&#39;, &#39;2009-12-31&#39;)));
var Data10 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2010-01-01&#39;, &#39;2010-12-31&#39;)));
var Data11 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2011-01-01&#39;, &#39;2011-12-31&#39;)));
var Data12 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2012-01-01&#39;, &#39;2012-12-31&#39;)));
var Data13 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2013-01-01&#39;, &#39;2013-12-31&#39;)));
var Data14 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2014-01-01&#39;, &#39;2014-12-31&#39;)));
var Data15 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2015-01-01&#39;, &#39;2015-12-31&#39;)));
var Data16 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2016-01-01&#39;, &#39;2016-12-31&#39;)));
var Data17 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2017-01-01&#39;, &#39;2017-12-31&#39;)));
var Data18 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2018-01-01&#39;, &#39;2018-12-31&#39;)));

// Combine all datasets
var Data2 = Data03.merge(Data04).merge(Data05).merge(Data06).merge(Data07)
            .merge(Data08).merge(Data09).merge(Data10).merge(Data11).merge(Data12)
            .merge(Data13).merge(Data14).merge(Data15).merge(Data16).merge(Data17).merge(Data18);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;predictor-variables&#34;&gt;Predictor Variables&lt;/h3&gt;
&lt;p&gt;We will use mean annual temperature, annual precipitation (Hijmans et
al. 2005), elevation (Farr et al. 2007) and percentage tree cover (Terra
MODIS VCF, 250 m resolution) as predictor variables. We set the grain
size of the analysis at 250 m resolution to match the MODIS data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//////////////////////////////////////////////
// Section 3 - Selecting Predictor Variables
//////////////////////////////////////////////

// Load bioclimatic data set
var BIO = ee.Image(&amp;quot;WORLDCLIM/V1/BIO&amp;quot;);

// Load elevation data 
var Elevation = ee.Image(&amp;quot;USGS/SRTMGL1_003&amp;quot;);

// Combine bands into a single image
var predictors = BIO.addBands(Elevation);

// Load MODIS surface reflectance
var start = ee.Date(&#39;2003-01-01&#39;);
var end = ee.Date(&#39;2020-01-01&#39;);
var MODIS = ee.ImageCollection(&amp;quot;MODIS/006/MOD44B&amp;quot;)
             .filterDate(start, end);

// Mask ocean from predictor variables
var watermask =  Elevation.gt(0); //Create a water mask
var predictors = predictors.updateMask(watermask).clip(AOI);
var bands = [&#39;bio01&#39;,&#39;bio12&#39;,&#39;elevation&#39;,&#39;Percent_Tree_Cover&#39;];

Map.addLayer(predictors, {bands:[&#39;elevation&#39;], min: 0, max: 5000,  palette: [&#39;000000&#39;,&#39;006600&#39;, &#39;009900&#39;,&#39;33CC00&#39;,&#39;996600&#39;,&#39;CC9900&#39;,&#39;CC9966&#39;,&#39;FFFFFF&#39;,]}, &#39;Elevation (m)&#39;, 0);
Map.addLayer(MODIS.first(), {bands:[&#39;Percent_Tree_Cover&#39;], min: 0, max: 100, palette:&#39;white,yellow,green&#39;}, &#39;Percent_Tree_Cover&#39;, 0); 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For each data location, we need to identify the closest recorded MODIS
image in time and extract the percentage tree cover value. We need to
define a series of function to do this. In this case, because the data
product is produced yearly, we define a max difference of 360 days.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/////////////////////////////////////////////////////////////////////////////////
// Section 4 - Match each point to the closest image in time and extract the pixel value
/////////////////////////////////////////////////////////////////////////////////

// Function to add property with time in milliseconds to the data
var add_date = function(feature) {
  return feature.set({date_millis: ee.Date(ee.String(feature.get(&amp;quot;Date&amp;quot;))).millis()});
};
var Data2 = Data2.map(add_date);

// Join Image and Points based on a maxDifference Filter within a day
var tempwin = 360;  // set time window (days)

var maxDiffFilter = ee.Filter.maxDifference({
  difference: tempwin * 24 * 60 * 60 * 1000,  // 8 day * hr * min * sec * milliseconds
  leftField: &#39;date_millis&#39;, //date data was collected
  rightField: &#39;system:time_start&#39; // image date
});

// Define the join.
var saveBestJoin = ee.Join.saveBest({
  matchKey: &#39;bestImage&#39;,
  measureKey: &#39;timeDiff&#39;
});

// Apply the join
var Data_match = saveBestJoin.apply(Data2, MODIS, maxDiffFilter);
//print(Data_match.limit(2)) //Activate to visualize results

// Function to add property with Percent Tree Cover value from the matched MODIS image
var add_value = function(feature) {
   var img1 = ee.Image(feature.get(&#39;bestImage&#39;)).select(&#39;Percent_Tree_Cover&#39;);
   var point = feature.geometry();
   var pixel_Value = img1.sample({region: point, scale: 10, tileScale: 15, dropNulls: false});
   return feature.set({Percent_Tree_Cover: pixel_Value.first().get(&#39;Percent_Tree_Cover&#39;)});
};

var DataFinal = Data_match.map(add_value);

// Remove points that were outside the MODIS image footprint (e.g., in the ocean)
var DataFinal = DataFinal.filter(ee.Filter.neq(&#39;Percent_Tree_Cover&#39;, null))

// Check the final number of presence locations for analysis
print(&#39;Presence data size:&#39;, DataFinal.size());
//print(DataFinal.limit(2)) //Activate to visualize results
Map.addLayer(DataFinal, {color:&#39;red&#39;}, &#39;Presence&#39;, 1)  //Add points to the map
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig12.png&#34;
alt=&#34;Figure S12. Cebus capucinus presence locations.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S12. &lt;em&gt;Cebus capucinus&lt;/em&gt;
presence locations.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;After all this process, we end up with 330 occurrence records.&lt;/p&gt;
&lt;h3 id=&#34;model-fit&#34;&gt;Model fit&lt;/h3&gt;
&lt;p&gt;The next step is to define an area to create pseudo-absences. We will
first create an image where presence records are marked to avoid
creating pseudo-absences in the same locations where we have known
presences.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////////////////////////////////////////
// Section 5 - Defining area for creation of pseudo-absence points
///////////////////////////////////////////////////////////////////

// Make an image out of the presence locations to mask from the area to generate pseudo-absences. This will impede having presence and pseudo-absences in a 1km around the presence location.
var mask = DataFinal
  .reduceToImage({
    properties: [&#39;random&#39;],
    reducer: ee.Reducer.first()
}).reproject(&#39;EPSG:4326&#39;, null, ee.Number(1000)).mask().neq(1).selfMask();

var AreaForPA = mask.updateMask(watermask).clip(AOI);
Map.addLayer(AreaForPA)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To create a matching pseudo-absence location for each occurrence
location, we generated a random pseudo-absence point within a 100 km
buffer, extracting the percent tree cover from the VCF image that
corresponded to the time period of the occurrence point. We repeated
this process five times, resulting in five balanced datasets for each
iteration, each with a different set of pseudo-absences.&lt;/p&gt;
&lt;p&gt;To do this, we defined a function that creates a random point within a
100 km buffer and extracts the pixel value of the percent tree cover
image. We then merge the presence data with the pseudo-absences.
Finally, we extract the value for the other predictors, elevation, mean
annual temperature, annual precipitation. Each of the 5 resulting
training data sets is used to fit a random forest classifier.&lt;/p&gt;
&lt;p&gt;We pack all this into a function that we can map across a list of random
seeds for each iteration of model fitting and validation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////
// Section 6 - Model fit
///////////////////////////

// Define SDM function
function SDM(x) {
    // Presence points
    var PresencePoints = DataFinal.map(function(feature){return feature.set(&#39;PresAbs&#39;, 1)});
    var PresencePoints = predictors.sampleRegions({collection: PresencePoints, properties: [&#39;PresAbs&#39;, &#39;Percent_Tree_Cover&#39;], scale: 250, tileScale: 4});
    var npoints = PresencePoints.size();
    
    // Pseudoabsences
    var PseudoAbs = DataFinal.map(function(feature){
                        var img1 = ee.Image(feature.get(&#39;bestImage&#39;)).select(&#39;Percent_Tree_Cover&#39;);
                        var pointbuff = feature.geometry().buffer(100000);
                        var randpoints = AreaForPA.sample({region: pointbuff, scale: 10, numPixels: 30, seed:x, geometries: true, tileScale: 15, dropNulls: true}); // If error appears on drop null, increase the number of pixels
                        var PTC = img1.sampleRegions({collection: randpoints, scale: 10, tileScale: 16, geometries: true});
                        return PTC.first();
                      });
    var PseudoAbs = PseudoAbs.map(function(feature){return feature.set(&#39;PresAbs&#39;, 0)});
    var PseudoAbsPoints = predictors.sampleRegions({collection: PseudoAbs, properties: [&#39;PresAbs&#39;, &#39;Percent_Tree_Cover&#39;], scale: 250, tileScale: 4, geometries: true});

    // Merge points
    var trainingData = PresencePoints.merge(PseudoAbsPoints);

    // Classify using Random Forest
    var rfClassifier = ee.Classifier.smileRandomForest(500).setOutputMode(&#39;PROBABILITY&#39;).train(trainingData, &#39;PresAbs&#39;, bands); 
   
    return ee.List([rfClassifier, trainingData]);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now fit the models. We use a pre-defined list of random numbers
for reproducibility of results.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Define number of repetitions
var numiter = 5;

// Fit SDM
var results = ee.List([81,96,57,22,2]).map(SDM);

// Extract results from list
var results = results.flatten();
//print(results) //Activate this line to visualize all elements
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;In this example we are using 5 iterations. Adding more iterations
could cause a memory limit issue. If more iterations are desired, then
instead of adding resulting predictions to the interactive map, you
can directly export results to Google Drive (batch mode) to prevent
the computation from reaching the memory limit.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;accuracy-assessment&#34;&gt;Accuracy assessment&lt;/h3&gt;
&lt;p&gt;Because model predictions will vary each year due to changes in
underlying predictor variables, we withheld data from 2019 for model
validation. We use 2019 for out-of-sample model validation as this year
had a large number of occurrence records and was the last year the MODIS
VCF was available in GEE. We assume that if the model predicts well for
withheld data in 2019, then the model likely performed well in other
years and is useful for making predictions and studying change over
time. We used 125 occurrence records and a set of 125 pseudo-absences
randomly created across the study area (within a 100 km buffer around
each occurrence location) to estimate the AUC-RP for each of the five
individual model predictions using the percentage of tree cover for
2019, together with mean annual temperature, annual precipitation and
elevation as the predictor variables.&lt;/p&gt;
&lt;p&gt;We need to define the AUC-RP functions as we did in the previous
example.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;////////////////////////////////////
// Section 7 - Accuracy assessment
////////////////////////////////////

// Define functions to estimate sensitivity, specificity and precision.
function getAcc(img,TP){
  var Pr_Prob_Vals = img.sampleRegions({collection: TP, properties: [&#39;PresAbs&#39;], scale: GrainSize, tileScale: 16});
  var seq = ee.List.sequence({start: 0, end: 1, count: 25});
  return ee.FeatureCollection(seq.map(function(cutoff) {
  var Pres = Pr_Prob_Vals.filterMetadata(&#39;PresAbs&#39;,&#39;equals&#39;,1);
  // true-positive and true-positive rate, sensitivity  
  var TP =  ee.Number(Pres.filterMetadata(&#39;classification&#39;,&#39;greater_than&#39;,cutoff).size());
  var TPR = TP.divide(Pres.size());
  var Abs = Pr_Prob_Vals.filterMetadata(&#39;PresAbs&#39;,&#39;equals&#39;,0);
  // true-negative rate, specificity  
  var TNR = ee.Number(Abs.filterMetadata(&#39;classification&#39;,&#39;less_than&#39;,cutoff).size()).divide(Abs.size());
  // false-positive and false-positive rate
  var FP = ee.Number(Abs.filterMetadata(&#39;classification&#39;,&#39;greater_than&#39;,cutoff).size());
  var FPR = FP.divide(Abs.size());
  // precision
  var Precision = TP.divide(TP.add(FP));
  return ee.Feature(null,{TPR:TPR, FPR:FPR, Precision:Precision});
  }));
}

// Calculate AUC of Precision Recall Curve
function getAUCPR(x){
  var X = ee.Array(x.aggregate_array(&#39;TPR&#39;));
  var Y = ee.Array(x.aggregate_array(&#39;Precision&#39;)); 
  var X1 = X.slice(0,1).subtract(X.slice(0,0,-1));
  var Y1 = Y.slice(0,1).add(Y.slice(0,0,-1));
  return X1.multiply(Y1).multiply(0.5).reduce(&#39;sum&#39;,[0]).abs().toList().get(0);
}

// Extract all model classifiers
var classifiers = ee.List.sequence(0,ee.Number(numiter).multiply(2).subtract(1),2)
                  .map(function(x){return results.get(x)});
                  
// We will use 2019 data to validate the model
var Data19 = RemoveDuplicates(Data.filter(ee.Filter.rangeContains(&#39;Date&#39;, &#39;2019-01-01&#39;, &#39;2019-12-31&#39;)));
var Presence19 = Data19.map(function(feature){return feature.set(&#39;PresAbs&#39;, 1)});
Map.addLayer(Presence19, {color:&#39;red&#39;}, &#39;Presence 2019&#39;, 1)  //Add points to the map

// Make an image out of the presence locations to mask from the area to generate pseudoabsences. This will impede having presence and pseudoabsences near the same pixel.
var mask2 = Presence19
  .reduceToImage({
    properties: [&#39;random&#39;],
    reducer: ee.Reducer.first()
}).reproject(&#39;EPSG:4326&#39;, null, ee.Number(1000));

// Limit pseudo-absences to a buffer around presence points. 
var buffer = 100000; // E.g., 100 km.
var AreaForPA2 = Data19.geometry().buffer(buffer);
var AreaForPA2 = mask2.mask().clip(AreaForPA2).updateMask(watermask).clip(AOI);

// Create random pseudo-absences
var Abs19 = AreaForPA2.sample({region: AOI, scale: GrainSize, numPixels: 1000, geometries: true}); //Because many points will on the ocean, we need to create more than needed.
var Abs19 = Abs19.randomColumn().sort(&#39;random&#39;).limit(Presence19.size()); // We keep the same amount of pseudoabsences than presences
var Abs19 = Abs19.map(function(feature){
    return feature.set(&#39;PresAbs&#39;, 0);
    });
print(&#39;Presence 2019&#39;, Presence19.size());
print(&#39;Pseudo-absences 2019&#39;, Abs19.size());

// Merge presence and pseudo-absences
var testingdata2019 = Presence19.merge(Abs19);

// Create the predictor variables for 2019
var mod2019 = MODIS.filterDate(&#39;2019-01-01&#39;, &#39;2019-12-31&#39;).select([&#39;Percent_Tree_Cover&#39;]).first();
var pred19 = predictors.addBands(mod2019);

// Predict HSI for 2019 and estimate ROC-AUC
function accuracy(x){
  var Classifier = classifiers.get(x);
  var HSM = pred19.classify(Classifier);
  var Acc = getAcc(HSM, testingdata2019);
  return getAUCPR(Acc);
}

var AUCPRs = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(accuracy);
print(&#39;AUC of the precision-recall:&#39;, AUCPRs);
print(&#39;Mean AUC of the precision-recall&#39;, AUCPRs.reduce(ee.Reducer.mean()));

// Function to extract other metrics
function getMetrics(x){
  var Classifier = classifiers.get(x);
  var HSM = pred19.classify(Classifier);
  var Acc = getAcc(HSM, testingdata2019);
  return Acc.sort({property:&#39;SUMSS&#39;,ascending:false}).first();
}

// Extract threshold values
var Metrics = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(getMetrics);
print(&#39;Sensitivity:&#39;, ee.FeatureCollection(Metrics).aggregate_array(&amp;quot;TPR&amp;quot;));
print(&#39;Specificity:&#39;, ee.FeatureCollection(Metrics).aggregate_array(&amp;quot;TNR&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig13.png&#34;
alt=&#34;Figure S13. 2019 presence data used for model validation.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S13. 2019 presence data used for
model validation.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr&gt;
&lt;p&gt;The individual model accuracy is:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Random Forest AUC-PR&lt;/th&gt;
&lt;th&gt;Sensitivity&lt;/th&gt;
&lt;th&gt;Specificity&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 1&lt;/td&gt;
&lt;td&gt;0.89&lt;/td&gt;
&lt;td&gt;0.81&lt;/td&gt;
&lt;td&gt;0.85&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 2&lt;/td&gt;
&lt;td&gt;0.82&lt;/td&gt;
&lt;td&gt;0.83&lt;/td&gt;
&lt;td&gt;0.76&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 3&lt;/td&gt;
&lt;td&gt;0.78&lt;/td&gt;
&lt;td&gt;0.77&lt;/td&gt;
&lt;td&gt;0.84&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Run 4&lt;/td&gt;
&lt;td&gt;0.83&lt;/td&gt;
&lt;td&gt;0.74&lt;/td&gt;
&lt;td&gt;0.91&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Run 5&lt;/td&gt;
&lt;td&gt;0.72&lt;/td&gt;
&lt;td&gt;0.75&lt;/td&gt;
&lt;td&gt;0.85&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;strong&gt;Mean&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.81&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.78&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.84&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;model-predictions&#34;&gt;Model predictions&lt;/h3&gt;
&lt;p&gt;After validating our models, we can predict suitable habitat across all
years to reflect changes over time in the Terra MODIS VCF image
composite. We need to define a function that adds the Terra MODIS VCF of
each year to the mean annual temperature, annual precipitation and
elevations variables and predicts the habitat suitability for each
single model. We then obtain the median habitat suitability per pixel as
the final prediction.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////
// Section 8 - Predictions
///////////////////////////

var PTC = ee.ImageCollection(&amp;quot;MODIS/006/MOD44B&amp;quot;).select([&#39;Percent_Tree_Cover&#39;]);
var HSI = PTC.map(function(img){
  var predimg = predictors.addBands(img); 
  return ee.ImageCollection.fromImages(ee.List.sequence(0,ee.Number(numiter).subtract(1),1)
  .map(function prediction(x){
        var Classifier = classifiers.get(x);
        return predimg.classify(Classifier)}))
  .mean().copyProperties(img, [&#39;system:time_start&#39;]);
  });

//print(HSI);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can plot some outputs. We need to convert the resulting image
collection into a list to display each year. Here we display years 2000
and 2019.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Define visualization parameters.
var visParams = {
  min: 0,
  max: 0.9,
  palette: [&amp;quot;#440154FF&amp;quot;,&amp;quot;#482677FF&amp;quot;,&amp;quot;#404788FF&amp;quot;,&amp;quot;#33638DFF&amp;quot;,&amp;quot;#287D8EFF&amp;quot;,
  &amp;quot;#1F968BFF&amp;quot;,&amp;quot;#29AF7FFF&amp;quot;,&amp;quot;#55C667FF&amp;quot;,&amp;quot;#95D840FF&amp;quot;,&amp;quot;#DCE319FF&amp;quot;],
};

var HSIlist = HSI.toList(20);

// Add final habitat suitability layer to the map. Use the function get to select specific years. 0 is the first element in the list.
Map.addLayer(ee.Image(HSIlist.get(0)), visParams, &#39;Habitat Suitability - 2000&#39;);
Map.addLayer(ee.Image(HSIlist.get(19)), visParams, &#39;Habitat Suitability - 2019&#39;);

// Create legend for habitat suitability map.
var legend = ui.Panel({style: {position: &#39;bottom-left&#39;, padding: &#39;8px 15px&#39;}});

legend.add(ui.Label({
  value: &amp;quot;Habitat suitability&amp;quot;,
  style: {fontWeight: &#39;bold&#39;, fontSize: &#39;18px&#39;, margin: &#39;0 0 4px 0&#39;, padding: &#39;0px&#39;}
}));

var colors = [&amp;quot;#DCE319FF&amp;quot;,&amp;quot;#287D8EFF&amp;quot;,&amp;quot;#440154FF&amp;quot;];
var names = [&#39;High&#39;, &#39;Medium&#39;,&#39;Low&#39;];
var entry;
for (var x = 0; x&amp;lt;3; x++){
  entry = [
    ui.Label({style:{color:colors[x],margin: &#39;0 0 4px 0&#39;}, value:&#39;██&#39;}),
    ui.Label({value: names[x],style: {margin: &#39;0 0 4px 4px&#39;}})
  ];
  legend.add(ui.Panel(entry, ui.Panel.Layout.Flow(&#39;horizontal&#39;)));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig14.png&#34;
alt=&#34;Figure S14. Predicted Cebus capucinus habitat suitability for 2000.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S14. Predicted &lt;em&gt;Cebus
capucinus&lt;/em&gt; habitat suitability for 2000.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;./Figures/Fig15.png&#34; alt=&#34;Figure S15. Predicted Cebus capucinus habitat suitability for
2019.&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;habitat-suitability-change-assessment&#34;&gt;Habitat suitability change assessment&lt;/h2&gt;
&lt;p&gt;To assess habitat suitability change across time, we fit a pixel-based
linear regression. We applied the &lt;code&gt;formaTrend()&lt;/code&gt; function to the image
collection containing habitat suitability predictions for each year of
our 20-year study. This function fits a pixel-based linear regression to
identify areas where habitat suitability increased or decreased across
the 20-year period. The output is an image with four bands, two of which
are of particular interest, 1) the slope of the linear regression and 2)
a t-test statistic on the significance of the slope. Finally, we create
an output map showing the slope of the linear regression at each pixel
while using the t-test statistic to mask out any pixels with
non-significant trends. Positive values indicate areas that increased in
habitat suitability over time and negative values indicate areas that
decreased in habitat suitability.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;////////////////////////////////////////////////////////////////////////////
// Section 9 - Fit linear regression to 20 years of HSI values at each pixel
////////////////////////////////////////////////////////////////////////////

// Use the formaTrend function to fit a linear regression to the habitat suitability collection.
var TempTrend = HSI.formaTrend();
//print(TempTrend);

// Display pixels with significant trends at an alpha = 0.05.
// To mask out pixels with non-significant trends, we need to find those pixels with 
// a two tailed t-test statistic larger or lower than the threshold value for the specific degrees of freedom.
// In our case we have 20 years, so 19 degrees of freedom, at an alpha of 0.05.  This gives us critical values for the t-test statistic of 2.093 and -2.093

var negative = TempTrend.select(&#39;long-tstat&#39;).lt(-2.093);
var possitive = TempTrend.select(&#39;long-tstat&#39;).gt(2.093);
var sign = negative.add(possitive);

Map.addLayer(TempTrend.select(&#39;long-trend&#39;).updateMask(sign), {
  min: -0.02,
  max: 0.02,
  palette: [&#39;ff0000&#39;,&#39;e96666&#39;,&#39;d6aeae&#39;,&#39;f1f1f1&#39;,&#39;c8ccff&#39;,&#39;6e8dff&#39;,&#39;000dad&#39;]
}, &#39;HSI long-trend&#39;);

// Add regression slope legend to the map
legend.add(ui.Label({
  value: &amp;quot;Regression slope&amp;quot;,
  style: {fontWeight: &#39;bold&#39;, fontSize: &#39;18px&#39;, margin: &#39;0 0 4px 0&#39;, padding: &#39;0px&#39;}
}));

var colors = [&#39;ff0000&#39;,&#39;f1f1f1&#39;,&#39;000dad&#39;];
var names = [&#39;-0.02&#39;, &#39;0&#39;,&#39;0.02&#39;];
var entry;
for (var x = 0; x&amp;lt;3; x++){
  entry = [
    ui.Label({style:{color:colors[x],margin: &#39;0 0 4px 0&#39;}, value:&#39;██&#39;}),
    ui.Label({value: names[x],style: {margin: &#39;0 0 4px 4px&#39;}})
  ];
  legend.add(ui.Panel(entry, ui.Panel.Layout.Flow(&#39;horizontal&#39;)));
}

Map.add(legend);
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig16.png&#34;
alt=&#34;Figure S16. Regression slope values show areas with positive (blue) to negative (red) trends in habitat suitability change between 2000 and 2019 for Cebus capucinus. Only pixels with significant trends are shown.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S16. Regression slope values show
areas with positive (blue) to negative (red) trends in habitat
suitability change between 2000 and 2019 for Cebus capucinus. Only
pixels with significant trends are shown.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;It is also possible to create a gif animation showing the change of
habitat suitability across years.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Create RGB visualization images for use as animation frames.
var rgbVis = HSM.map(function(img) {
  var scale = 250;
  return img.visualize(visParams);
});

// Define GIF visualization parameters.
var gifParams = {
  &#39;region&#39;: geometry2,
  &#39;dimensions&#39;: 500,
  &#39;crs&#39;: &#39;EPSG:3857&#39;,
  &#39;framesPerSecond&#39;: 2
};

//Print the GIF URL to the console.
print(rgbVis.getVideoThumbURL(gifParams));
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&#34;./Figures/Fig17.gif&#34;
alt=&#34;Figure S17. Cebus capucinus habitat suitability change across years.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Figure S17. &lt;em&gt;Cebus capucinus&lt;/em&gt;
habitat suitability change across years.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;As before, we can export results to Google Drive.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;//////////////////////////////////////////////////////
// Section 10 - Export final map
//////////////////////////////////////////////////////

// Export final model to drive
Export.image.toDrive({
   image: TempTrend, //Image to export
   description: &#39;Cebuscapucinus&#39;, //File name
   scale: GrainSize, // Spatial resolution
   maxPixels: 1e10,
   region: AOI //Area of interest
 });
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;case-study-3-modelling-species-distribution-at-high-spatial-resolution-using-unclassified-satellite-images-as-predictor-variables&#34;&gt;Case Study 3: Modelling species distribution at high spatial resolution using unclassified satellite images as predictor variables&lt;/h2&gt;
&lt;p&gt;In this third case study, we demonstrate the implementation of the SDM
workflow to predict habitat suitability based on presence records and
unclassified satellite data. The code workflow is very similar to case
study 1, and differs primarily in the predictor variables used and the
fact that this analysis has to be run on batch mode to avoid memory
limits. Therefore, all results have to be exported to Google Drive. Note
that it is possible to run a couple of iterations to quickly visualize
results on the interactive map before exporting the model with a larger
number of iterations.&lt;/p&gt;
&lt;h3 id=&#34;loading-data-and-defining-grid-size-and-extent&#34;&gt;Loading data and defining grid size and extent&lt;/h3&gt;
&lt;p&gt;For this example, we obtained the eBird observation dataset for
&lt;em&gt;Hylocichla mustelina&lt;/em&gt; from GBIF (GBIF.org (12 November 2021);
&lt;a href=&#34;https://doi.org/10.15468/dl.hpjfup&#34;&gt;https://doi.org/10.15468/dl.hpjfup&lt;/a&gt;) for the month of June (middle of
breeding season when observation of migrants is more unlikely) for the
years 2018, 2019 and 2020. The dataset was first ingested into GEE as an
asset.&lt;/p&gt;
&lt;p&gt;In the first section we load the data and set the spatial resolution of
the analysis to 90 m.&lt;/p&gt;
&lt;p&gt;We define the extent of the analysis to be the eastern continental USA
(4,606,284 km2), limiting the extent to the westernmost observation in
the dataset (longitude: -103 degrees). To do this we used the Large
Scale International Boundary (LSIB) dataset and filtered out the USA
boundary. We used the &lt;code&gt;intersection()&lt;/code&gt; function to limit the geometry to
the -103 degrees of longitude.&lt;/p&gt;
&lt;p&gt;We rarified the original 99,939 observations to keep one per pixel,
resulting in 34,880 observations for modelling.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 1 - Load species data, AOI, and remove duplicates
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Load presence data
var DataRaw = ee.FeatureCollection(&#39;users/ramirocrego84/WoodThrush&#39;);
//print(&#39;Original data size:&#39;, DataRaw.size());

//Define the AOI
var USA = ee.FeatureCollection(&amp;quot;USDOS/LSIB_SIMPLE/2017&amp;quot;).filter(ee.Filter.eq(&#39;country_co&#39;,&#39;US&#39;));
var AOI = USA.filter(ee.Filter.eq(&#39;country_na&#39;,&#39;United States&#39;)).limit(2).union();
var AOI = ee.Feature(AOI.first()).geometry();
var AOI = AOI.intersection(ee.Geometry.Polygon(
        [[[-103, 49],
          [-103, 23],
          [-64, 23],
          [-64, 49]]]),1000)
          
//var Area = AOI.area()
//var AreaSqKm = ee.Number(Area).divide(1e6).round() //This calculates the area of the AOI in km2
//print(AreaSqKm)

// Define spatial resolution to work with (m)
var GrainSize = 90;

function RemoveDuplicates(data){
  var randomraster = ee.Image.random().reproject(&#39;EPSG:4326&#39;, null, GrainSize);
  var randpointvals = randomraster.sampleRegions({collection:ee.FeatureCollection(data), scale: 10, geometries: true});
  return randpointvals.distinct(&#39;random&#39;);
}

DataRaw = DataRaw.filter(ee.Filter.bounds(AOI));
var Data = RemoveDuplicates(DataRaw)
print(&#39;Final data size:&#39;, Data.size());

// Add border of study area to the map
var outline = ee.Image().byte().paint({
  featureCollection: AOI, color: 1, width: 3});
Map.addLayer(outline, {palette: &#39;FF0000&#39;}, &amp;quot;Study Area&amp;quot;);

// Center map to the center of the screen
Map.centerObject(AOI,3); //Number indicates the zoom level

// Visualize presence points on the map
Map.addLayer(Data, {color:&#39;red&#39;}, &#39;Presence&#39;, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;predictor-variables-1&#34;&gt;Predictor variables&lt;/h3&gt;
&lt;p&gt;In the next step we prepare the predictor variables for analysis.&lt;/p&gt;
&lt;p&gt;We modeled &lt;em&gt;Hylocichla mustelina&lt;/em&gt; habitat suitability using
atmospherically corrected Landsat 8 surface reflectance (SR) collection
2, Advanced Land Observing Satellite (ALOS) Phased Arrayed L-band
Synthetic Aperture Radar (SAR) HH and HV polarization datasets, and
temperature products as predictor variables.&lt;/p&gt;
&lt;p&gt;We first loaded and filtered the Landsat 8 SR product to keep only
images between the months of April and August and for 2018, 2019, and
2020. We included those months to obtain a cloud-free mosaic for the
entire study area.&lt;/p&gt;
&lt;p&gt;For each image, we masked bad quality pixels with clouds, cloud shadows
and saturated pixels and rescaled pixel values with the appropriate
scaling factors using a predefined &lt;code&gt;maskL8sr()&lt;/code&gt; mask function available
in GEE.&lt;/p&gt;
&lt;p&gt;We selected the blue, red, green, near-infrared and shortwave infrared 1
bands for analysis (30 m spatial resolution).&lt;/p&gt;
&lt;p&gt;For each image we also calculated NDVI using the
&lt;code&gt;normalizedDifference()&lt;/code&gt; function available in GEE.&lt;/p&gt;
&lt;p&gt;We finally created a mosaic of the entire study area by calculating the
median value from the time series for each pixel across all Landsat
image bands.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 2 - Selecting Predictor Variables
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Load and process landsat data
var l8sr = ee.ImageCollection(&#39;LANDSAT/LC08/C02/T1_L2&#39;)
                .filterBounds(AOI)
                //.filterMetadata(&#39;CLOUD_COVER&#39;, &#39;less_than&#39;, 100)
                .filterDate(&#39;2018-01-01&#39;, &#39;2020-12-31&#39;)
                .filter(ee.Filter.calendarRange({start:5, end:8, field:&#39;month&#39;}));
                

// Function to mask clouds
function maskL8sr(image) {
  // Bit 0 - Fill
  // Bit 1 - Dilated Cloud
  // Bit 2 - Cirrus
  // Bit 3 - Cloud
  // Bit 4 - Cloud Shadow
  var qaMask = image.select(&#39;QA_PIXEL&#39;).bitwiseAnd(parseInt(&#39;11111&#39;, 2)).eq(0);
  var saturationMask = image.select(&#39;QA_RADSAT&#39;).eq(0);

  // Apply the scaling factors to the appropriate bands.
  var opticalBands = image.select(&#39;SR_B.&#39;).multiply(0.0000275).add(-0.2);
  var thermalBands = image.select(&#39;ST_B.*&#39;).multiply(0.00341802).add(149.0);

  // Replace the original bands with the scaled ones and apply the masks.
  return image.addBands(opticalBands, null, true)
      .addBands(thermalBands, null, true)
      .updateMask(qaMask)
      .updateMask(saturationMask);
}

// Function to rename Landsat 8 bands for cross-Landsat compatibility &amp;amp; rescale
var renameBandsL8 = function(image) {
    var imgNewBands = image.select([&#39;SR_B2&#39;, &#39;SR_B3&#39;, &#39;SR_B4&#39;, &#39;SR_B5&#39;, &#39;SR_B6&#39;]).rename([&#39;blue&#39;, &#39;green&#39;, &#39;red&#39;, &#39;nir&#39;, &#39;swir1&#39;]);
    return imgNewBands.copyProperties(image,[&#39;system:time_start&#39;]);
};

// Function to compute NDVI
var addNDVI = function(image) {
    var ndvi = image.normalizedDifference([&#39;nir&#39;, &#39;red&#39;]).rename(&#39;ndvi&#39;);
    return image.addBands(ndvi);
};

// Apply functions
var l8sr8nocld = l8sr.map(maskL8sr)
                      .map(renameBandsL8)
                      .map(addNDVI);

// Create a median composite image (takes the median value from each band across all available images)
var l8srcompmedian = l8sr8nocld.median();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also used the 2018, 2019, and 2020 global mosaics of Advanced Land
Observing Satellite (ALOS) Phased Arrayed L-band Synthetic Aperture
Radar (SAR) HH and HV polarization datasets (25 m spatial resolution).
For each pixel of the two bands, we also obtained the median value among
the three years.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load Radar Data
var radar = ee.ImageCollection(&#39;JAXA/ALOS/PALSAR/YEARLY/SAR&#39;)
                  .filterDate(&#39;2018-01-01&#39;, &#39;2020-12-31&#39;);
                
var radar = radar.select([&#39;HH&#39;,&#39;HV&#39;]).median();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, to account for the variation in temperature across the breeding
range we included the mean temperature for the month of June (1 km
spatial resolution).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load WorldClim BIO Variables (a multiband image) from the data catalog
var juneTemp = ee.ImageCollection(&#39;WORLDCLIM/V1/MONTHLY&#39;).filter(ee.Filter.eq(&#39;month&#39;,6)).first().select(&#39;tavg&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then combined all predictor variables into one multiband image.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Combine bands into a single multi-band image
var predictors = l8srcompmedian.addBands(radar).addBands(juneTemp);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we masked out all pixels containing permanent water using the
global water surface product.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Mask water pixels from the predictor variable image collection
var watermask = ee.Image(&amp;quot;JRC/GSW1_3/GlobalSurfaceWater&amp;quot;).select(&#39;max_extent&#39;).eq(0);
var predictors = predictors.updateMask(watermask).clip(AOI);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You need to display the resulting images to make sure you have a
complete mosaic for the study area with minimal gaps due to clouds or
bad quality pixels. In our case study, we had to modify the filter
parameters until the complete Lansdat mosaic was obtained without
missing data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Get band names
var bands = predictors.bandNames();

// Display layers on the map
Map.addLayer(predictors, {bands:[&#39;ndvi&#39;], min: 0, max: 1,  palette: [&#39;white&#39;,&#39;yellow&#39;,&#39;green&#39;]}, &#39;NDVI&#39;, 0);
Map.addLayer(predictors, {bands: [&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;], gamma: 1, min: 0, max: 0.2, opacity: 1}, &#39;L8 SR True color&#39;,0);
Map.addLayer(predictors, {bands:[&#39;tavg&#39;], min: 0, max: 300,  palette: [&#39;blue&#39;, &#39;purple&#39;, &#39;cyan&#39;, &#39;green&#39;, &#39;yellow&#39;, &#39;red&#39;]}, &#39;Mean T June&#39;, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;defining-spatial-blocks-for-model-fitting-and-cross-validation&#34;&gt;Defining spatial blocks for model fitting and cross validation&lt;/h3&gt;
&lt;p&gt;For this analysis, we implemented a two-step environmental profiling
technique to generate pseudo-absences. We performed a k-means clustering
based on Euclidean distance for a subset of 1,000 randomly selected
occurrences to restrict the area for the creation of pseudo-absences to
pixels more dissimilar to the environmental profile of the occurrence
data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 3 - Defining spatial blocks for model fitting and cross validation
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Make an image out of the presence locations. The pixels where we have presence locations will be removed from the area to generate pseudo-absences.
// This will prevent having presence and pseudo-absences in the same pixel. 
var mask = Data
  .reduceToImage({
    properties: [&#39;random&#39;],
    reducer: ee.Reducer.first()
}).reproject(&#39;EPSG:4326&#39;, null, ee.Number(GrainSize)).mask().neq(1).selfMask();

// Extract local covariate values from multiband predictor image at presence points
var PixelVals = predictors.sampleRegions({collection: Data.randomColumn({seed:5}).sort(&#39;random&#39;).limit(1000), properties: [], scale: 30, tileScale: 8});
// Instantiate the clusterer and train it.
var clusterer = ee.Clusterer.wekaKMeans({nClusters:2, distanceFunction:&amp;quot;Euclidean&amp;quot;, fast: true}).train(PixelVals);
// Cluster the input using the trained clusterer.
var ClResult = predictors.cluster(clusterer);

// Retain cluster class mode dissimilar to occurrence data
var ClMask = ClResult.select([&#39;cluster&#39;]).eq(1);
          
var AreaForPA =  mask.updateMask(ClMask);

Map.addLayer(AreaForPA, {},&#39;Area to create pseudo-absences&#39;, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We implemented a repeated (5-times) spatial block cross validation
technique, randomly partitioning 200 x 200 km spatial blocks for model
training (70%) and validation (30%) while randomly generating
pseudo-absences at each iteration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Define a function to create a grid over AOI
function makeGrid(Geometry, scale) {
  // pixelLonLat returns an image with each pixel labeled with longitude and
  // latitude values.
  var lonLat = ee.Image.pixelLonLat();
  // Select the longitude and latitude bands, multiply by a large number then
  // truncate them to integers.
  var lonGrid = lonLat
    .select(&#39;longitude&#39;)
    .multiply(100000)
    .toInt();
  var latGrid = lonLat
    .select(&#39;latitude&#39;)
    .multiply(100000)
    .toInt();
  return lonGrid
    .multiply(latGrid)
    .reduceToVectors({
      geometry: Geometry,
      scale: scale,
      geometryType: &#39;polygon&#39;,
    });
}
// Create grid and remove cells outside AOI
var Scale = 200000; // Set range in m to create spatial blocks
var Grid = makeGrid(AOI, Scale);
Map.addLayer(Grid, {},&#39;Grid for spatail block cross validation&#39;, 0);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;fitting-sdm-models&#34;&gt;Fitting SDM models&lt;/h3&gt;
&lt;p&gt;For the analysis, we generated an equal number of pseudo-absences as
occurrence data for each of the 5 datasets. To ensure an equal number of
pseudo-absences, we first generated an arbitrarily large sample of 50000
random points to allow for pixels to be discarded that fell outside land
area (withing the ocean or lakes) within the spatial blocks selected for
model training. After dropping these masked pixels, we then limited the
number of pseudo-absence points to match the number of presence points
for a given dataset. We then fit a random forest model (500 trees) to
each individual training dataset and then averaged model outputs to
calculate the mean habitat suitability of the five iterations.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 4 - Fitting SDM models
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Define SDM function
// Activate the desired classifier, random forest or gradient boosting. 
// Note that other algorithms are available in GEE. See ee.Classifiers on the documentation for more information.

function SDM(x) {
    var Seed = ee.Number(x);
    // Randomly split blocks for training and validation
    var GRID = ee.FeatureCollection(Grid).randomColumn({seed:Seed}).sort(&#39;random&#39;);
    var TrainingGrid = GRID.filter(ee.Filter.lt(&#39;random&#39;, split));  // Filter points with &#39;random&#39; property &amp;lt; split percentage
    var TestingGrid = GRID.filter(ee.Filter.gte(&#39;random&#39;, split));  // Filter points with &#39;random&#39; property &amp;gt;= split percentage

    // Presence
    var PresencePoints = ee.FeatureCollection(Data);
    PresencePoints = PresencePoints.map(function(feature){return feature.set(&#39;PresAbs&#39;, 1)});
    var TrPresencePoints = PresencePoints.filter(ee.Filter.bounds(TrainingGrid));  // Filter points with &#39;random&#39; property &amp;lt; split percentage
    var TePresencePoints = PresencePoints.filter(ee.Filter.bounds(TestingGrid));  // Filter points with &#39;random&#39; property &amp;gt;= split percentage

    // Pseudo-absences
    var TrPseudoAbsPoints = AreaForPA.sample({region: TrainingGrid, scale: GrainSize, numPixels: 50000, seed:Seed, geometries: true, tileScale: 16}); // We add extra points to account for those points that land in masked areas of the raster and are discarded. This ensures a balanced presence/pseudo-absence data set
    TrPseudoAbsPoints = TrPseudoAbsPoints.randomColumn().sort(&#39;random&#39;).limit(ee.Number(TrPresencePoints.size())); //Randomly retain the same number of pseudo-absences as presence data 
    TrPseudoAbsPoints = TrPseudoAbsPoints.map(function(feature){
        return feature.set(&#39;PresAbs&#39;, 0);
        });
 
    var TePseudoAbsPoints = AreaForPA.sample({region: TestingGrid, scale: GrainSize, numPixels: TePresencePoints.size(), seed:Seed, geometries: true, tileScale: 16}); // We add extra points to account for those points that land in masked areas of the raster and are discarded. This ensures a balanced presence/pseudo-absence data set
    TePseudoAbsPoints = TePseudoAbsPoints.randomColumn().sort(&#39;random&#39;).limit(ee.Number(TePresencePoints.size())); //Randomly retain the same number of pseudo-absences as presence data 
    TePseudoAbsPoints = TePseudoAbsPoints.map(function(feature){
        return feature.set(&#39;PresAbs&#39;, 0);
        });

    // Merge points
    var trainingPartition = TrPresencePoints.merge(TrPseudoAbsPoints);
    var testingPartition = TePresencePoints.merge(TePseudoAbsPoints);

    // Extract local covariate values from multiband predictor image at training points
    var trainPixelVals = predictors.sampleRegions({collection: trainingPartition, properties: [&#39;PresAbs&#39;], scale: GrainSize, tileScale: 16, geometries: false});

    // Classify using random forest
    var Classifier = ee.Classifier.smileRandomForest({
       numberOfTrees: 500, //The number of decision trees to create.
       variablesPerSplit: null, //The number of variables per split. If unspecified, uses the square root of the number of variables.
       minLeafPopulation: 10,//Only create nodes whose training set contains at least this many points. Integer, default: 1
       bagFraction: 0.5,//The fraction of input to bag per tree. Default: 0.5.
       maxNodes: null,//The maximum number of leaf nodes in each tree. If unspecified, defaults to no limit.
       seed: Seed//The randomization seed.
      });
  
    // Presence probability 
    var ClassifierPr = Classifier.setOutputMode(&#39;PROBABILITY&#39;).train(trainPixelVals, &#39;PresAbs&#39;, bands); 
    var ClassifiedImgPr = predictors.select(bands).classify(ClassifierPr);

    // Binary presence/absence map
    //var ClassifierBin = Classifier.setOutputMode(&#39;CLASSIFICATION&#39;).train(trainPixelVals, &#39;PresAbs&#39;, bands); 
    //var ClassifiedImgBin = predictors.select(bands).classify(ClassifierBin);
   
    return ee.List([ClassifiedImgPr, testingPartition]);
}


// Define partition for training and testing data
var split = 0.70;  // The proportion of the blocks used to select training data

// Define number of repetitions
var numiter = 5;

// Fit SDM 
var results = ee.List([55,7,25,65,23]).map(SDM);

// Extract results from list
var results = results.flatten();

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 5 - Extracting and displaying model prediction results
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Habitat suitability

// Extract all model predictions
var images = ee.List.sequence(0,ee.Number(numiter).multiply(2).subtract(1),2).map(function(x){
  return results.get(x)});

// Calculate mean of all individual model runs
var ModelAverage = ee.ImageCollection.fromImages(images).mean();
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;accuracy-assessment-1&#34;&gt;Accuracy assessment&lt;/h3&gt;
&lt;p&gt;We assessed model accuracy by calculating the AUC-PR, sensitivity, and
specificity on the validation dataset for each model iteration. To
obtain a binary potential distribution map, we used the mean threshold
that maximized the sum of sensitivity and specificity of each of the
individual model predictions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 6 - Accuracy assessment
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Extract testing/validation datasets
var TestingDatasets = ee.List.sequence(1,ee.Number(numiter).multiply(2).subtract(1),2).map(function(x){
                      return results.get(x)});

// Double check that you have a satisfactory number of points for model validation
// print(&#39;Number of presence and pseudo-absence points for model validation&#39;, ee.List.sequence(0,ee.Number(numiter).subtract(1),1)
// .map(function(x){
//   return ee.List([ee.FeatureCollection(TestingDatasets.get(x)).filter(ee.Filter.eq(&#39;PresAbs&#39;,1)).size(),
//         ee.FeatureCollection(TestingDatasets.get(x)).filter(ee.Filter.eq(&#39;PresAbs&#39;,0)).size()]);
// })
// );

// Define functions to estimate sensitivity, specificity and precision.
function getAcc(img,TP){
  var Pr_Prob_Vals = img.sampleRegions({collection: TP, properties: [&#39;PresAbs&#39;], scale: GrainSize, tileScale: 16});
  var seq = ee.List.sequence({start: 0, end: 1, count: 25});
  return ee.FeatureCollection(seq.map(function(cutoff) {
  var Pres = Pr_Prob_Vals.filterMetadata(&#39;PresAbs&#39;,&#39;equals&#39;,1);
  // true-positive and true-positive rate, sensitivity  
  var TP =  ee.Number(Pres.filterMetadata(&#39;classification&#39;,&#39;greater_than&#39;,cutoff).size());
  var TPR = TP.divide(Pres.size());
  var Abs = Pr_Prob_Vals.filterMetadata(&#39;PresAbs&#39;,&#39;equals&#39;,0);
  // false-negative
  var FN = ee.Number(Pres.filterMetadata(&#39;classification&#39;,&#39;less_than&#39;,cutoff).size());
  // true-negative and true-negative rate, specificity  
  var TN = ee.Number(Abs.filterMetadata(&#39;classification&#39;,&#39;less_than&#39;,cutoff).size());
  var TNR = TN.divide(Abs.size());
  // false-positive and false-positive rate
  var FP = ee.Number(Abs.filterMetadata(&#39;classification&#39;,&#39;greater_than&#39;,cutoff).size());
  var FPR = FP.divide(Abs.size());
  // precision
  var Precision = TP.divide(TP.add(FP));
  // sum of sensitivity and specificity
  var SUMSS = TPR.add(TNR);
  return ee.Feature(null,{cutoff: cutoff, TP:TP, TN:TN, FP:FP, FN:FN, TPR:TPR, TNR:TNR, FPR:FPR, Precision:Precision, SUMSS:SUMSS});
  }));
}


// Calculate AUC of Precision Recall Curve

function getAUCPR(roc){
  var X = ee.Array(roc.aggregate_array(&#39;TPR&#39;));
  var Y = ee.Array(roc.aggregate_array(&#39;Precision&#39;)); 
  var X1 = X.slice(0,1).subtract(X.slice(0,0,-1));
  var Y1 = Y.slice(0,1).add(Y.slice(0,0,-1));
  return X1.multiply(Y1).multiply(0.5).reduce(&#39;sum&#39;,[0]).abs().toList().get(0);
}

function AUCPRaccuracy(x){
  var HSM = ee.Image(images.get(x));
  var TData = ee.FeatureCollection(TestingDatasets.get(x));
  var Acc = getAcc(HSM, TData);
  return getAUCPR(Acc);
}

var AUCPRs = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(AUCPRaccuracy);

// Function to extract other metrics
function getMetrics(x){
  var HSM = ee.Image(images.get(x));
  var TData = ee.FeatureCollection(TestingDatasets.get(x));
  var Acc = getAcc(HSM, TData);
  return Acc.sort({property:&#39;SUMSS&#39;,ascending:false}).first();
}

// Extract sensitivity, specificity and mean threshold values
var Metrics = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(getMetrics);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;exporting-model-outputs&#34;&gt;Exporting model outputs&lt;/h3&gt;
&lt;p&gt;We ran the model in batch mode, exporting the results to Google Drive.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 7 - Export outputs
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Export final outputs to Google Drive

Export.image.toDrive({
  image: ModelAverage, //Object to export
  description: &#39;HSI&#39;, //Name of the file
  scale: GrainSize, //Spatial resolution of the exported raster
  maxPixels: 1e10,
  region: AOI //Area of interest
});

Export.table.toDrive({
  collection: ee.FeatureCollection(AUCPRs
                        .map(function(element){
                        return ee.Feature(null,{AUCPR:element})})),
  description: &#39;AUCPR&#39;,
  fileFormat: &#39;CSV&#39;,
});

Export.table.toDrive({
  collection: ee.FeatureCollection(Metrics),
  description: &#39;Metrics&#39;,
  fileFormat: &#39;CSV&#39;,
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because exporting results for this analysis takes a long time, instead
of directly exporting the binary presence-absence map, we manually
calculated the average threshold from the exported accuracy metrics and
set the threshold on the visualization parameters in QGIS.&lt;/p&gt;
&lt;h2 id=&#34;code-to-model-presence-absence-data&#34;&gt;Code to model presence-absence data&lt;/h2&gt;
&lt;p&gt;Using presence and absence data is always recommended for SDM analysis.&lt;/p&gt;
&lt;p&gt;Here we present code that will allow you to fit an SDM using presence
and absence data. Because there is no need to create pseudo-absences,
the code has some modifications from the previous examples. However, the
work flow is very similar.&lt;/p&gt;
&lt;p&gt;It is important that the data set that is uploaded into GEE as an asset
contains a field with 1 indicating presence and 0 indicating absence for
each location.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Presence absence model

///////////////////////////////
// Section 1 - Species data
///////////////////////////////

// Load presence absence data
//var Data = ee.FeatureCollection(&#39;users/yourdata&#39;);
var Data = table
print(&#39;Data size:&#39;, Data.size());

// Define spatial resolution to work with (m)
var GrainSize = 1000;


// Add two maps to the screen.
var left = ui.Map();
var right = ui.Map();
ui.root.clear();
ui.root.add(left);
ui.root.add(right);

// Link maps, so when you drag one map, the other will be moved in sync.
ui.Map.Linker([left, right], &#39;change-bounds&#39;);

// Add presence points to the map
// Visualize presence points on the map
//right.addLayer(Data, {color:&#39;red&#39;}, &#39;Data&#39;, 1);
//left.addLayer(Data, {color:&#39;red&#39;}, &#39;Data&#39;, 1);

////////////////////////////////////////
// Section 2 - Define Area of Interest
////////////////////////////////////////

// Define the AOI
var AOI = Data.geometry().bounds().buffer(10000);

// Add border of study area to the map
var outline = ee.Image().byte().paint({
  featureCollection: AOI, color: 1, width: 3});
right.addLayer(outline, {palette: &#39;FF0000&#39;}, &amp;quot;Study Area&amp;quot;);
left.addLayer(outline, {palette: &#39;FF0000&#39;}, &amp;quot;Study Area&amp;quot;);

// Center map to the area of interest
right.centerObject(AOI, 9); //Number indicates the zoom level
left.centerObject(AOI, 9); //Number indicates the zoom level


//////////////////////////////////////////////
// Section 3 - Selecting Predictor Variables
//////////////////////////////////////////////

// Here as an example we are using elevation data.
// Load elevation data from the data catalog and calculate slope, aspect, and a simple hillshade from the terrain Digital Elevation Model.
var Terrain = ee.Algorithms.Terrain(ee.Image(&amp;quot;USGS/SRTMGL1_003&amp;quot;));
var Terrain = Terrain.select([&#39;elevation&#39;,&#39;slope&#39;,&#39;aspect&#39;]); // Select elevation, slope and aspect

// Load NDVI 250 m collection and estimate median value per pixel
var MODIS = ee.ImageCollection(&amp;quot;MODIS/006/MOD13Q1&amp;quot;);
var MedianNDVI = MODIS.filterDate(&#39;2003-01-01&#39;, &#39;2020-12-31&#39;).select([&#39;NDVI&#39;]).median();

// Combine bands into a single image
var predictors = Terrain.addBands(MedianNDVI).clip(AOI);

// Mask ocean from predictor variables
var watermask =  Terrain.select(&#39;elevation&#39;).gt(0); //Create a water mask
var predictors = predictors.updateMask(watermask).clip(AOI);

left.addLayer(predictors.clip(AOI), {bands:[&#39;elevation&#39;], min: 900, max: 1700,  palette: [&#39;000000&#39;,&#39;006600&#39;, &#39;009900&#39;,&#39;33CC00&#39;,&#39;996600&#39;,&#39;CC9900&#39;,&#39;CC9966&#39;,&#39;FFFFFF&#39;,]}, &#39;Elevation (m)&#39;, 0);
left.addLayer(predictors.clip(AOI), {bands:[&#39;slope&#39;], min: 0, max: 45, palette:&#39;white,red&#39;}, &#39;Slope (Degrees)&#39;, 0); 
left.addLayer(predictors.clip(AOI), {bands:[&#39;aspect&#39;], min: 0, max: 350, palette:&#39;red,blue&#39;}, &#39;Aspect (Degrees)&#39;, 0); 

// Estimate correlation among predictor variables

// Extract local covariate values from multiband predictor image at training points
var DataCor = predictors.sample({scale: GrainSize, numPixels: 5000, geometries: true}); //Generate 5000 random points
var PixelVals = predictors.sampleRegions({collection: DataCor, scale: GrainSize, tileScale: 16}); //Extract covariate values

// To check all pairwise correlations we need to map the reduceColumns function across all pairwise combinations of predictors
var CorrAll = predictors.bandNames().map(function(i){
    var tmp1 = predictors.bandNames().map(function(j){
      var tmp2 = PixelVals.reduceColumns({
        reducer: ee.Reducer.spearmansCorrelation(),
        selectors: [i, j]
      });
    return tmp2.get(&#39;correlation&#39;);
    });
    return tmp1;
  });
print(&#39;Variables correlation matrix&#39;,CorrAll);

// Select bands for modeling
var bands = [&#39;elevation&#39;,&#39;slope&#39;,&#39;aspect&#39;,&#39;NDVI&#39;];
var predictors = predictors.select(bands);

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Section 4 - Defining blocks to fold randomly for cross validation
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Define a function to create a grid over AOI
function makeGrid(geometry, scale) {
  // pixelLonLat returns an image with each pixel labeled with longitude and
  // latitude values.
  var lonLat = ee.Image.pixelLonLat();
  // Select the longitude and latitude bands, multiply by a large number then
  // truncate them to integers.
  var lonGrid = lonLat
    .select(&#39;longitude&#39;)
    .multiply(100000)
    .toInt();
  var latGrid = lonLat
    .select(&#39;latitude&#39;)
    .multiply(100000)
    .toInt();
  return lonGrid
    .multiply(latGrid)
    .reduceToVectors({
      geometry: geometry.buffer(100, 1000), //Buffer to expand grid and include borders
      scale: scale,
      geometryType: &#39;polygon&#39;,
    });
}
// Create grid and remove cells outside AOI
var Scale = 5000; // Set range in m to create spatial blocks
var grid = makeGrid(AOI, Scale);
var Grid = watermask.reduceRegions({collection: grid, reducer: ee.Reducer.mean()}).filter(ee.Filter.neq(&#39;mean&#39;,null));
right.addLayer(Grid, {},&#39;Grid for spatail block cross validation&#39;, 0);



//////////////////////////////////////
// Section 5 - Fitting SDM models
//////////////////////////////////////

// Define function to generate a vector of random numbers between 1 and 1000
function runif(length) {
    return Array.apply(null, Array(length)).map(function() {
        return Math.round(Math.random() * (1000 - 1) + 1);
    });
}

// Define SDM function
// Activate the desired classifier, Random Forest or Gradient Boosting. 
// Note that other algorithms are available in GEE. See ee.Classifiers on the documentation for more information.

function SDM(x) {
    var Seed = ee.Number(x);
    
    // Randomly split blocks for training and validation
    var GRID = ee.FeatureCollection(Grid).randomColumn({seed:Seed}).sort(&#39;random&#39;);
    var TrainingGrid = GRID.filter(ee.Filter.lt(&#39;random&#39;, split));  // Filter points with &#39;random&#39; property &amp;lt; split percentage
    var TestingGrid = GRID.filter(ee.Filter.gte(&#39;random&#39;, split));  // Filter points with &#39;random&#39; property &amp;gt;= split percentage

    // Presence
    var PresencePoints = ee.FeatureCollection(Data).filter(ee.Filter.eq(&#39;PresAbs&#39;,1)); //Filter all presence points
    var TrPresencePoints = PresencePoints.filter(ee.Filter.bounds(TrainingGrid));  // Filter points with &#39;random&#39; property &amp;lt; split percentage
    var TePresencePoints = PresencePoints.filter(ee.Filter.bounds(TestingGrid));  // Filter points with &#39;random&#39; property &amp;gt;= split percentage

    //Absence   
    var AbsPoints = ee.FeatureCollection(Data).filter(ee.Filter.eq(&#39;PresAbs&#39;,0)); //Filter all absence points
    var TrAbsencePoints = AbsPoints.filter(ee.Filter.bounds(TrainingGrid));  // Filter points with &#39;random&#39; property &amp;lt; split percentage
    var TeAbsencePoints = AbsPoints.filter(ee.Filter.bounds(TestingGrid));  // Filter points with &#39;random&#39; property &amp;gt;= split percentage

    // Merge points
    var trainingPartition = TrPresencePoints.merge(TrAbsencePoints);
    var testingPartition = TePresencePoints.merge(TeAbsencePoints);
    
    // Extract local covariate values from multiband predictor image at training points
    var trainPixelVals = predictors.sampleRegions({collection: trainingPartition, properties: [&#39;PresAbs&#39;], scale: GrainSize, tileScale: 16});

    // Classify using random forest 
    var Classifier = ee.Classifier.smileRandomForest({
       numberOfTrees: 500, //The number of decision trees to create.
       variablesPerSplit: null, //The number of variables per split. If unspecified, uses the square root of the number of variables.
       minLeafPopulation: 10,//Only create nodes whose training set contains at least this many points. Integer, default: 1
       bagFraction: 0.5,//The fraction of input to bag per tree. Default: 0.5.
       maxNodes: null,//The maximum number of leaf nodes in each tree. If unspecified, defaults to no limit.
       seed: Seed//The randomization seed.
      });
    
    // Classify using gradient boosting 
    // var ClassifierPr = ee.Classifier.smileGradientTreeBoost({
    //   numberOfTrees:500, //The number of decision trees to create.
    //   shrinkage: 0.005, //The shrinkage parameter in (0, 1) controls the learning rate of procedure. Default: 0.005
    //   samplingRate: 0.7, //The sampling rate for stochastic tree boosting. Default 0.07
    //   maxNodes: null, //The maximum number of leaf nodes in each tree. If unspecified, defaults to no limit.
    //   loss: &amp;quot;LeastAbsoluteDeviation&amp;quot;, //Loss function for regression. One of: LeastSquares, LeastAbsoluteDeviation, Huber.
    //   seed:Seed //The randomization seed.
    // });
  
    // Presence probability 
    var ClassifierPr = Classifier.setOutputMode(&#39;PROBABILITY&#39;).train(trainPixelVals, &#39;PresAbs&#39;, bands); 
    var ClassifiedImgPr = predictors.select(bands).classify(ClassifierPr);
    
    // Binary presence/absence map
    var ClassifierBin = Classifier.setOutputMode(&#39;CLASSIFICATION&#39;).train(trainPixelVals, &#39;PresAbs&#39;, bands); 
    var ClassifiedImgBin = predictors.select(bands).classify(ClassifierBin);
   
    return ee.List([ClassifiedImgPr, ClassifiedImgBin, trainingPartition, testingPartition]);
  
}


// Define partition for training and testing data
var split = 0.70;  // The proportion of the blocks used to select training data

// Define number of repetitions
var numiter = 10;

// Fit SDM 
// Create random seeds
var RanSeeds = runif(numiter);
var results = ee.List(RanSeeds).map(SDM);
// Extract results from list
var results = results.flatten();
//print(results); //Activate this line to visualize all elements

////////////////////////////////////////////////////////////////////
// Section 6 - Extracting and displaying model prediction results
////////////////////////////////////////////////////////////////////

// Habitat suitability

// Set visualization parameters
var visParams = {
  min: 0,
  max: 0.8,
  palette: [&amp;quot;#440154FF&amp;quot;,&amp;quot;#482677FF&amp;quot;,&amp;quot;#404788FF&amp;quot;,&amp;quot;#33638DFF&amp;quot;,&amp;quot;#287D8EFF&amp;quot;,
  &amp;quot;#1F968BFF&amp;quot;,&amp;quot;#29AF7FFF&amp;quot;,&amp;quot;#55C667FF&amp;quot;,&amp;quot;#95D840FF&amp;quot;,&amp;quot;#DCE319FF&amp;quot;],
};

// Extract all model predictions
var images = ee.List.sequence(0,ee.Number(numiter).multiply(4).subtract(1),4).map(function(x){
  return results.get(x)});

// You can add all the individual model predictions to the map. The number of layers to add will depend on how many iterations you selected.

// left.addLayer(ee.Image(images.get(0)), visParams, &#39;Run1&#39;);
// left.addLayer(ee.Image(image.get(1)), visParams, &#39;Run2&#39;);

// Calculate mean of all individual model runs
var ModelAverage = ee.ImageCollection.fromImages(images).mean();

// Add final habitat suitability layer and presence locations to the map
left.addLayer(ModelAverage, visParams, &#39;Habitat Suitability&#39;);
left.addLayer(Data, {color:&#39;red&#39;}, &#39;Presence&#39;, 1);

// Create legend for habitat suitability map.
var legend = ui.Panel({style: {position: &#39;bottom-left&#39;, padding: &#39;8px 15px&#39;}});

legend.add(ui.Label({
  value: &amp;quot;Habitat suitability&amp;quot;,
  style: {fontWeight: &#39;bold&#39;, fontSize: &#39;18px&#39;, margin: &#39;0 0 4px 0&#39;, padding: &#39;0px&#39;}
}));

var colors = [&amp;quot;#DCE319FF&amp;quot;,&amp;quot;#287D8EFF&amp;quot;,&amp;quot;#440154FF&amp;quot;];
var names = [&#39;High&#39;, &#39;Medium&#39;,&#39;Low&#39;];
var entry;
for (var x = 0; x&amp;lt;3; x++){
  entry = [
    ui.Label({style:{color:colors[x],margin: &#39;0 0 4px 0&#39;}, value:&#39;██&#39;}),
    ui.Label({value: names[x],style: {margin: &#39;0 0 4px 4px&#39;}})
  ];
  legend.add(ui.Panel(entry, ui.Panel.Layout.Flow(&#39;horizontal&#39;)));
}

legend.add(ui.Panel(
  [ui.Label({value: &amp;quot;Presence locations&amp;quot;,style: {fontWeight: &#39;bold&#39;, fontSize: &#39;16px&#39;, margin: &#39;0 0 4px 0&#39;}}),
   ui.Label({style:{color:&amp;quot;red&amp;quot;,margin: &#39;0 0 0 4px&#39;}, value:&#39;◉&#39;})],
  ui.Panel.Layout.Flow(&#39;horizontal&#39;)));

left.add(legend);


// Distribution map

// Extract all model predictions
var images2 = ee.List.sequence(1,ee.Number(numiter).multiply(4).subtract(1),4).map(function(x){
  return results.get(x)});

// Calculate mean of all indivudual model runs
var DistributionMap = ee.ImageCollection.fromImages(images2).mode();

// Add final distribution map and presence locations to the map
right.addLayer(DistributionMap, 
  {palette: [&amp;quot;white&amp;quot;, &amp;quot;green&amp;quot;], min: 0, max: 1}, 
  &#39;Potential distribution&#39;);
right.addLayer(Data, {color:&#39;red&#39;}, &#39;Presence&#39;, 1);

// Create legend for distribution map
var legend2 = ui.Panel({style: {position: &#39;bottom-left&#39;,padding: &#39;8px 15px&#39;}});
legend2.add(ui.Label({
  value: &amp;quot;Potential distribution map&amp;quot;,
  style: {fontWeight: &#39;bold&#39;,fontSize: &#39;18px&#39;,margin: &#39;0 0 4px 0&#39;,padding: &#39;0px&#39;}
}));

var colors2 = [&amp;quot;green&amp;quot;,&amp;quot;white&amp;quot;];
var names2 = [&#39;Presence&#39;, &#39;Absence&#39;];
var entry2;
for (var x = 0; x&amp;lt;2; x++){
  entry2 = [
    ui.Label({style:{color:colors2[x],margin: &#39;0 0 4px 0&#39;}, value:&#39;██&#39;}),
    ui.Label({value: names2[x],style: {margin: &#39;0 0 4px 4px&#39;}})
  ];
  legend2.add(ui.Panel(entry2, ui.Panel.Layout.Flow(&#39;horizontal&#39;)));
}

legend2.add(ui.Panel(
  [ui.Label({value: &amp;quot;Presence locations&amp;quot;,style: {fontWeight: &#39;bold&#39;, fontSize: &#39;16px&#39;, margin: &#39;0 0 4px 0&#39;}}),
   ui.Label({style:{color:&amp;quot;red&amp;quot;,margin: &#39;0 0 4px 4px&#39;}, value:&#39;◉&#39;})],
  ui.Panel.Layout.Flow(&#39;horizontal&#39;)));

right.add(legend2);

/////////////////////////////////////////
// Section 7 - Accuracy assessment
/////////////////////////////////////////

// Extract testing/validation datasets
var TestingDatasets = ee.List.sequence(3,ee.Number(numiter).multiply(4).subtract(1),4).map(function(x){
                      return results.get(x)});

// Double check that you have a satisfactory number of points for model validation
print(&#39;Number of presence and absence points for model validation&#39;, ee.List.sequence(0,ee.Number(numiter).subtract(1),1)
.map(function(x){
  return ee.List([ee.FeatureCollection(TestingDatasets.get(x)).filter(ee.Filter.eq(&#39;PresAbs&#39;,1)).size(),
         ee.FeatureCollection(TestingDatasets.get(x)).filter(ee.Filter.eq(&#39;PresAbs&#39;,0)).size()]);
})
);

// Define functions to estimate, sensitivity, specificity and precision.
function getAcc(img,TP){
  var Pr_Prob_Vals = img.sampleRegions({collection: TP, properties: [&#39;PresAbs&#39;], scale: GrainSize, tileScale: 16});
  var seq = ee.List.sequence({start: 0, end: 1, count: 25});
  return ee.FeatureCollection(seq.map(function(cutoff) {
  var Pres = Pr_Prob_Vals.filterMetadata(&#39;PresAbs&#39;,&#39;equals&#39;,1);
  // true-positive and true-positive rate, sensitivity  
  var TP =  ee.Number(Pres.filterMetadata(&#39;classification&#39;,&#39;greater_than&#39;,cutoff).size());
  var TPR = TP.divide(Pres.size());
  var Abs = Pr_Prob_Vals.filterMetadata(&#39;PresAbs&#39;,&#39;equals&#39;,0);
  // false-negative
  var FN = ee.Number(Pres.filterMetadata(&#39;classification&#39;,&#39;less_than&#39;,cutoff).size());
  // true-negative and true-negative rate, specificity  
  var TN = ee.Number(Abs.filterMetadata(&#39;classification&#39;,&#39;less_than&#39;,cutoff).size());
  var TNR = TN.divide(Abs.size());
  // false-positive and false-positive rate
  var FP = ee.Number(Abs.filterMetadata(&#39;classification&#39;,&#39;greater_than&#39;,cutoff).size());
  var FPR = FP.divide(Abs.size());
  // precision
  var Precision = TP.divide(TP.add(FP));
  // sum of sensitivity and specificity
  var SUMSS = TPR.add(TNR);
  return ee.Feature(null,{cutoff: cutoff, TP:TP, TN:TN, FP:FP, FN:FN, TPR:TPR, TNR:TNR, FPR:FPR, Precision:Precision, SUMSS:SUMSS});
  }));
}

// Calculate AUC of the Receiver Operator Characteristic
function getAUCROC(x){
  var X = ee.Array(x.aggregate_array(&#39;FPR&#39;));
  var Y = ee.Array(x.aggregate_array(&#39;TPR&#39;)); 
  var X1 = X.slice(0,1).subtract(X.slice(0,0,-1));
  var Y1 = Y.slice(0,1).add(Y.slice(0,0,-1));
  return X1.multiply(Y1).multiply(0.5).reduce(&#39;sum&#39;,[0]).abs().toList().get(0);
}

function AUCROCaccuracy(x){
  var HSM = ee.Image(images.get(x));
  var TData = ee.FeatureCollection(TestingDatasets.get(x));
  var Acc = getAcc(HSM, TData);
  return getAUCROC(Acc);
}


var AUCROCs = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(AUCROCaccuracy);
print(&#39;AUC-ROC:&#39;, AUCROCs);
print(&#39;Mean AUC-ROC&#39;, AUCROCs.reduce(ee.Reducer.mean()));

/////////////////////////////////////////////////////////////////////////////////
// Section 8 - Create a custom binary distribution map based on best threshold
/////////////////////////////////////////////////////////////////////////////////

// Calculating the potential distribution map based on the threshold 
// that maximizes the sum of sensitivity and specificity is computationally intensive and 
// may need to be executed in batch mode for a large number of iterations.
// In batch mode, the final image needs to exported to Google Drive and opened in 
// another software for visualization (or imported to GEE as an asset for visualization.

// Function to extract threshold values
function getThreshold(x){
  var HSM = ee.Image(images.get(x));
  var TData = ee.FeatureCollection(TestingDatasets.get(x));
  var Acc = getAcc(HSM, TData);
  return Acc.sort({property:&#39;SUMSS&#39;,ascending:false}).first().get(&amp;quot;cutoff&amp;quot;);
}

// Extract threshold values
var Thresholds = ee.List.sequence(0,ee.Number(numiter).subtract(1),1).map(getThreshold);
var MT = ee.Number(Thresholds.reduce(ee.Reducer.mean()));
print(&#39;Mean threshold:&#39;, MT);

// Transform probability model output into a binary map using the defined threshold and set NA into -9999
var DistributionMap2 = ModelAverage.gte(MT).unmask(-9999);

// Export final model to drive
Export.image.toDrive({
  image: DistributionMap2,
  description: &#39;filename&#39;,
  scale: GrainSize,
  maxPixels: 1e10,
  region: AOI
});


///////////////////////////////////////
// Section 9 - Export outputs
///////////////////////////////////////

// Export final outputs to Google Drive
/*
Export.image.toDrive({
  image: DistributionMap, //Object to export
  description: &#39;PotentialDistribution&#39;, //Name of the file
  scale: GrainSize, //Spatial resolution of the exported raster
  maxPixels: 1e10,
  region: AOI //Area of interest
});

Export.image.toDrive({
  image: ModelAverage, //Object to export
  description: &#39;HSI&#39;, //Name of the file
  scale: GrainSize, //Spatial resolution of the exported raster
  maxPixels: 1e10,
  region: AOI //Area of interest
});

// Export training and validation data sets

// Extract training datasets
var TrainingDatasets = ee.List.sequence(1,ee.Number(numiter).multiply(4).subtract(1),4).map(function(x){
  return results.get(x)});

// If you are interested in exporting any of the training or testing data sets used for modelling,
// you need to extract the feature collections from the list and export them.
// Here an example to export the trainign and validation data sets from the first iteration. 
// For other iterations you need to change the number in the get function. In JavaScript the first element of the list is 0.

Export.table.toDrive({
  collectio : TrainingDatasets.get(0),
  description: &#39;TestingDataRun1&#39;,
  fileFormat: &#39;CSV&#39;,
});

Export.table.toDrive({
  collectio : TestingDatasets.get(0),
  description: &#39;TestingDataRun1&#39;,
  fileFormat: &#39;CSV&#39;,
});
*/
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;Araújo, M. B., Anderson, R. P., Barbosa, A. M., Beale, C. M., Dormann,
C. F., Early, R., Garcia, R. A., Guisan, A., Maioran, L., Naimi, B.,
O’Hara, R. B., Zimmermann, N. E., &amp;amp; Rahbek, C. (2019). Standards for
distribution models in biodiversity assessments. Science Advances, 5(1),
1–12. &lt;a href=&#34;https://doi.org/10.1126/sciadv.aat4858&#34;&gt;https://doi.org/10.1126/sciadv.aat4858&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Barbet-Massin, M., Jiguet, F., Albert, C. H., &amp;amp; Thuiller, W. (2012).
Selecting pseudo-absences for species distribution models: How, where
and how many? Methods in Ecology and Evolution, 3(2), 327–338.
&lt;a href=&#34;https://doi.org/10.1111/j.2041-210X.2011.00172.x&#34;&gt;https://doi.org/10.1111/j.2041-210X.2011.00172.x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chefaoui, R. M., &amp;amp; Lobo, J. M. (2008). Assessing the effects of
pseudo-absences on predictive distribution model performance. Ecological
Modelling, 210(4), 478–486.
&lt;a href=&#34;https://doi.org/10.1016/j.ecolmodel.2007.08.010&#34;&gt;https://doi.org/10.1016/j.ecolmodel.2007.08.010&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Evans, J. S., Murphy, M. A., Holden, Z. A., &amp;amp; Cushman, S. A. (2011).
Modeling Species Distribution and Change Using Random Forest. In C. A.
Drew, Y. F. Wiersma, &amp;amp; F. Huettmann (Eds.), Predictive Species and
Habitat Modeling in Landscape Ecology: Concepts and Applications
(pp. 139–159). New York, NY: Springer New York.
&lt;a href=&#34;https://doi.org/10.1007/978-1-4419-7390-0_8&#34;&gt;https://doi.org/10.1007/978-1-4419-7390-0_8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Farr, T. G., Rosen, P. A., Caro, E., Crippen, R., Duren, R., Hensley,
S., Kobrick, M., Paller, M., Rodriguez, E., Roth, L., Seal, D., Shaffer,
S., Shimada, J., Umland, J., Werner, M., Oskin, M., Burbank, D.,
&amp;amp;Alsdorf, D. (2007). The shuttle radar topography mission. Reviews of
Geophysics, 45(2), RG2004. &lt;a href=&#34;https://doi.org/10.1029/2005RG000183&#34;&gt;https://doi.org/10.1029/2005RG000183&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fielding, A. H., &amp;amp; Bell, J. F. (1997). A review of methods for the
assessment of prediction errors in conservation presence/absence models.
Environmental Conservation, 24(1), 38–49.
&lt;a href=&#34;https://doi.org/10.1017/S0376892997000088&#34;&gt;https://doi.org/10.1017/S0376892997000088&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Guisan, A., Thuiller, W., &amp;amp; Zimmermann, N. (2017). Habitat Suitability
and Distribution Models: With Applications in R. Cambridge, UK.:
Cambridge University Press. &lt;a href=&#34;https://doi.org/doi:10.1017/9781139028271&#34;&gt;https://doi.org/doi:10.1017/9781139028271&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hijmans, R.J., Cameron, S.E., Parra, J.L., Jones, P.G., &amp;amp; Jarvis, A.
(2005). Very High Resolution Interpolated Climate Surfaces for Global
Land Areas. International Journal of Climatology 25: 1965-1978.&lt;/p&gt;
&lt;p&gt;Hijmans, R. J., Phillips, S., Leathwick, J., &amp;amp; Elith, J. (2017). dismo:
Species distribution modeling. R package version 1.1-4.&lt;/p&gt;
&lt;p&gt;Kindt, R. (2018). Ensemble species distribution modelling with
transformed suitability values. Environmental Modelling and Software,
100, 136–145. &lt;a href=&#34;https://doi.org/10.1016/j.envsoft.2017.11.009&#34;&gt;https://doi.org/10.1016/j.envsoft.2017.11.009&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Leroy, B., Delsol, R., Hugueny, B., Meynard, C. N., Barhoumi, C.,
Barbet-Massin, M., &amp;amp; Bellard, C. (2018). Without quality
presence–absence data, discrimination metrics such as TSS can be
misleading measures of model performance. Journal of Biogeography,
45(9), 1994–2002. &lt;a href=&#34;https://doi.org/10.1111/jbi.13402&#34;&gt;https://doi.org/10.1111/jbi.13402&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Liu, C., Newell, G., &amp;amp; White, M. (2016). On the selection of thresholds
for predicting species occurrence with presence-only data. Ecology and
Evolution, 6(1), 337–348. &lt;a href=&#34;https://doi.org/10.1002/ece3.1878&#34;&gt;https://doi.org/10.1002/ece3.1878&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Marmion, M., Parviainen, M., Luoto, M., Heikkinen, R. K., &amp;amp; Thuiller, W.
(2009). Evaluation of consensus methods in predictive species
distribution modelling. Diversity and Distributions, 15(1), 59–69.
&lt;a href=&#34;https://doi.org/10.1111/j.1472-4642.2008.00491.x&#34;&gt;https://doi.org/10.1111/j.1472-4642.2008.00491.x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mittermeier, R. A., Rylands, A. B., &amp;amp; Wilson, D. E., (Eds.). (2013).
Handbook of the Mammals of the World: Volume 3, Primates. Barcelona,
Spain.: Linx Ediciones.&lt;/p&gt;
&lt;p&gt;Phillips, S. J., Anderson, R. P., Dudík, M., Schapire, R. E., &amp;amp; Blair,
M. E. (2017). Opening the black box: an open-source release of Maxent.
Ecography, 40(7), 887–893. &lt;a href=&#34;https://doi.org/10.1111/ecog.03049&#34;&gt;https://doi.org/10.1111/ecog.03049&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Phillips, S. J., Anderson, R. P., &amp;amp; Schapire, R. E. (2006). Maximum
entropy modeling of species geographic distributions. Ecological
Modelling, 190(3–4), 231–259.
&lt;a href=&#34;https://doi.org/10.1016/j.ecolmodel.2005.03.026&#34;&gt;https://doi.org/10.1016/j.ecolmodel.2005.03.026&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Phillips, S. J., Dudík, M., Elith, J., Graham, C. H., Lehmann, A.,
Leathwick, J., &amp;amp; Ferrier, S. (2009). Sample selection bias and
presence-only distribution models: Implications for background and
pseudo-absence data. Ecological Applications, 19(1), 181–197.
&lt;a href=&#34;https://doi.org/10.1890/07-2153.1&#34;&gt;https://doi.org/10.1890/07-2153.1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Roberts, D. R., Bahn, V., Ciuti, S., Boyce, M. S., Elith, J.,
Guillera-Arroita, G., Hauenstein, S., Lahoz-Monford, J. J., Schröder,
B., Thuiller, W., Warton, D. I., Wintle, B. A., Hartig, F., &amp;amp; Dormann,
C. F. (2017). Cross-validation strategies for data with temporal,
spatial, hierarchical, or phylogenetic structure. Ecography, 40(8),
913–929. &lt;a href=&#34;https://doi.org/10.1111/ecog.02881&#34;&gt;https://doi.org/10.1111/ecog.02881&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Senay, S. D., Worner, S. P., &amp;amp; Ikeda, T. (2013). Novel Three-Step
Pseudo-Absence Selection Technique for Improved Species Distribution
Modelling. PLoS ONE, 8(8).
&lt;a href=&#34;https://doi.org/10.1371/journal.pone.0071218&#34;&gt;https://doi.org/10.1371/journal.pone.0071218&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sillero, N., Arenas-Castro, S., Enriquez‐Urzelai, U., Vale, C. G.,
Sousa-Guedes, D., Martínez-Freiría, F., … Barbosa, A. M. (2021). Want to
model a species niche? A step-by-step guideline on correlative
ecological niche modelling. Ecological Modelling, 456.
&lt;a href=&#34;https://doi.org/10.1016/j.ecolmodel.2021.109671&#34;&gt;https://doi.org/10.1016/j.ecolmodel.2021.109671&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sofaer, H. R., Hoeting, J. A., &amp;amp; Jarnevich, C. S. (2019). The area under
the precision-recall curve as a performance metric for rare binary
events. Methods in Ecology and Evolution, 10(4), 565–577.
&lt;a href=&#34;https://doi.org/10.1111/2041-210X.13140&#34;&gt;https://doi.org/10.1111/2041-210X.13140&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Valavi, R., Elith, J., Lahoz-Monfort, J. J., &amp;amp; Guillera-Arroita, G.
(2019). blockCV: An r package for generating spatially or
environmentally separated folds for k-fold cross-validation of species
distribution models. Methods in Ecology and Evolution, 10(2), 225–232.
&lt;a href=&#34;https://doi.org/10.1111/2041-210X.13107&#34;&gt;https://doi.org/10.1111/2041-210X.13107&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>//localhost:4321/publications/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/publications/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reticulated giraffe habitat suitability</title>
      <link>//localhost:4321/project/gcf/</link>
      <pubDate>Thu, 30 Nov 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/project/gcf/</guid>
      <description>&lt;p&gt;This is a free web app powered by Goolge Earth Engine where managers can visualize and interact with the 30 m resolution map to help guide future surveys to search for existing populations and to inform future reintroduction assessments.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>🎉 Easily create your own simple yet highly customizable blog</title>
      <link>//localhost:4321/post/get-started/</link>
      <pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/post/get-started/</guid>
      <description>&lt;p&gt;Welcome 👋&lt;/p&gt;



&lt;details class=&#34;print:hidden xl:hidden&#34; open&gt;
  &lt;summary&gt;Table of Contents&lt;/summary&gt;
  &lt;div class=&#34;text-sm&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#get-started&#34;&gt;Get Started&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#-click-here-to-become-a-sponsor-and-help-support-hugo-bloxs-future-httpshugobloxcomsponsor&#34;&gt;&lt;a href=&#34;https://hugoblox.com/sponsor/&#34;&gt;❤️ Click here to become a sponsor and help support Hugo Blox&amp;rsquo;s future ❤️&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ecosystem&#34;&gt;Ecosystem&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#inspiration&#34;&gt;Inspiration&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#themes&#34;&gt;Themes&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
  &lt;/div&gt;
&lt;/details&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The Hugo Blox website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site&lt;/li&gt;
&lt;li&gt;The template can be modified and customised to suit your needs. It&amp;rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a &lt;strong&gt;no-code solution (write in Markdown and customize with YAML parameters)&lt;/strong&gt; and having &lt;strong&gt;flexibility to later add even deeper personalization with HTML and CSS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;get-started&#34;&gt;Get Started&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;👉 &lt;a href=&#34;https://hugoblox.com/templates/&#34;&gt;&lt;strong&gt;Create a new site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;📚 &lt;a href=&#34;https://docs.hugoblox.com/&#34;&gt;&lt;strong&gt;Personalize your site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;💬 &lt;a href=&#34;https://discord.gg/z8wNYzb&#34;&gt;Chat with the &lt;strong&gt;Hugo Blox community&lt;/strong&gt;&lt;/a&gt; or &lt;a href=&#34;https://discourse.gohugo.io&#34;&gt;&lt;strong&gt;Hugo community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;🐦 Twitter: &lt;a href=&#34;https://twitter.com/GetResearchDev&#34;&gt;@GetResearchDev&lt;/a&gt; &lt;a href=&#34;https://twitter.com/GeorgeCushen&#34;&gt;@GeorgeCushen&lt;/a&gt; #MadeWithHugoBlox&lt;/li&gt;
&lt;li&gt;💡 &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/issues&#34;&gt;Request a &lt;strong&gt;feature&lt;/strong&gt; or report a &lt;strong&gt;bug&lt;/strong&gt; for &lt;em&gt;Hugo Blox&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;⬆️ &lt;strong&gt;Updating Hugo Blox?&lt;/strong&gt; View the &lt;a href=&#34;https://docs.hugoblox.com/reference/update/&#34;&gt;Update Guide&lt;/a&gt; and &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/releases&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/h2&gt;
&lt;p&gt;To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.&lt;/p&gt;
&lt;h3 id=&#34;-click-here-to-become-a-sponsor-and-help-support-hugo-bloxs-future-httpshugobloxcomsponsor&#34;&gt;&lt;a href=&#34;https://hugoblox.com/sponsor/&#34;&gt;❤️ Click here to become a sponsor and help support Hugo Blox&amp;rsquo;s future ❤️&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As a token of appreciation for sponsoring, you can &lt;strong&gt;unlock &lt;a href=&#34;https://hugoblox.com/sponsor/&#34;&gt;these&lt;/a&gt; awesome rewards and extra features 🦄✨&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/GetRD/academic-file-converter&#34;&gt;Bibtex To Markdown&lt;/a&gt;:&lt;/strong&gt; Automatically import publications from BibTeX&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;inspiration&#34;&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://hugoblox.com/creators/&#34;&gt;Learn what other &lt;strong&gt;creators&lt;/strong&gt;&lt;/a&gt; are building with this template.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with no-code &lt;a href=&#34;https://hugoblox.com/blocks/&#34;&gt;&lt;strong&gt;blocks&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34;&gt;&lt;strong&gt;elements&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.hugoblox.com/getting-started/cms/&#34;&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&lt;/a&gt;, or &lt;a href=&#34;https://docs.hugoblox.com/getting-started/cms/&#34;&gt;&lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable &lt;a href=&#34;https://docs.hugoblox.com/getting-started/customize/&#34;&gt;&lt;strong&gt;color&lt;/strong&gt; and &lt;strong&gt;font themes&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code syntax highlighting and LaTeX math supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - &lt;a href=&#34;https://analytics.google.com&#34;&gt;Google Analytics&lt;/a&gt;, &lt;a href=&#34;https://disqus.com&#34;&gt;Disqus commenting&lt;/a&gt;, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one-page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 35+ language packs including English, 中文, and Português&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Hugo Blox and its templates come with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Visitors can choose their preferred mode by clicking the sun/moon icon in the header.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.hugoblox.com/getting-started/customize/&#34;&gt;Choose a stunning &lt;strong&gt;theme&lt;/strong&gt; and &lt;strong&gt;font&lt;/strong&gt;&lt;/a&gt; for your site. Themes are fully customizable.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present &lt;a href=&#34;https://georgecushen.com&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Released under the &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/blob/main/LICENSE.md&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Naboisho Conservancy</title>
      <link>//localhost:4321/project/naboisho/</link>
      <pubDate>Thu, 26 Oct 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/project/naboisho/</guid>
      <description>&lt;p&gt;This Shiny app is the result of a collaboration with the Naboisho Conservancy in Kenya. It is a tool to help them monitor the impact of their conservation efforts on the abundance of large herbivores. The app allows users to explore the data collected by the conservancy and to visualize the abundance trends of large herbivores.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>🧠 Sharpen your thinking with a second brain</title>
      <link>//localhost:4321/post/second-brain/</link>
      <pubDate>Thu, 26 Oct 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/post/second-brain/</guid>
      <description>&lt;p&gt;Create a personal knowledge base and share your knowledge with your peers.&lt;/p&gt;
&lt;p&gt;Hugo Blox web framework empowers you with one of the most flexible note-taking capabilities out there.&lt;/p&gt;
&lt;p&gt;Create a powerful knowledge base that works on top of a local folder of plain text Markdown files.&lt;/p&gt;
&lt;p&gt;Use it as your second brain, either publicly sharing your knowledge with your peers via your website, or via a private GitHub repository and password-protected site just for yourself.&lt;/p&gt;
&lt;h2 id=&#34;mindmaps&#34;&gt;Mindmaps&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports a Markdown extension for mindmaps.&lt;/p&gt;
&lt;p&gt;With this open format, can even edit your mindmaps in other popular tools such as Obsidian.&lt;/p&gt;
&lt;p&gt;Simply insert a Markdown code block labelled as &lt;code&gt;markmap&lt;/code&gt; and optionally set the height of the mindmap as shown in the example below.&lt;/p&gt;
&lt;p&gt;Mindmaps can be created by simply writing the items as a Markdown list within the &lt;code&gt;markmap&lt;/code&gt; code block, indenting each item to create as many sub-levels as you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap {height=&#34;200px&#34;}
- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34; height=&#34;200px&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;- Hugo Modules
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - Hugo Blox
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - blox-plugins-netlify
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - blox-plugins-netlify-cms
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - blox-plugins-reveal
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Anh here&amp;rsquo;s a more advanced mindmap with formatting, code blocks, and math:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap
- Mindmaps
  - Links
    - [Hugo Blox Docs](https://docs.hugoblox.com/)
    - [Discord Community](https://discord.gg/z8wNYzb)
    - [GitHub](https://github.com/HugoBlox/hugo-blox-builder)
  - Features
    - Markdown formatting
    - **inline** ~~text~~ *styles*
    - multiline
      text
    - `inline code`
    -
      ```js
      console.log(&#39;hello&#39;);
      console.log(&#39;code block&#39;);
      ```
    - Math: $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;- Mindmaps
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - Links
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    - [Hugo Blox Docs](https://docs.hugoblox.com/)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    - [Discord Community](https://discord.gg/z8wNYzb)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    - [GitHub](https://github.com/HugoBlox/hugo-blox-builder)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - Features
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    - Markdown formatting
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    - **inline** ~~text~~ *styles*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    - multiline
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      text
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    - `inline code`
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    -
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      ```js
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      console.log(&amp;#39;hello&amp;#39;);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      console.log(&amp;#39;code block&amp;#39;);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      ```
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    - Math: $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;highlighting&#34;&gt;Highlighting&lt;/h2&gt;
&lt;p&gt;&lt;mark&gt;Highlight&lt;/mark&gt; important text with &lt;code&gt;mark&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Highlighted text&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;callouts&#34;&gt;Callouts&lt;/h2&gt;
&lt;p&gt;Use &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/#callouts&#34;&gt;callouts&lt;/a&gt; (aka &lt;em&gt;asides&lt;/em&gt;, &lt;em&gt;hints&lt;/em&gt;, or &lt;em&gt;alerts&lt;/em&gt;) to draw attention to notes, tips, and warnings.&lt;/p&gt;
&lt;p&gt;By wrapping a paragraph in &lt;code&gt;{{% callout note %}} ... {{% /callout %}}&lt;/code&gt;, it will render as an aside.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% callout note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% /callout %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Or use the &lt;code&gt;warning&lt;/code&gt; callout type so your readers don&amp;rsquo;t miss critical details:&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-yellow-100 dark:bg-yellow-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-red-400&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.&lt;/span&gt;
&lt;/div&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>📈 Communicate your results effectively with the best data visualizations</title>
      <link>//localhost:4321/post/data-visualization/</link>
      <pubDate>Wed, 25 Oct 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/post/data-visualization/</guid>
      <description>&lt;p&gt;Hugo Blox is designed to give technical content creators a seamless experience. You can focus on the content and Hugo Blox handles the rest.&lt;/p&gt;
&lt;p&gt;Use popular tools such as Plotly, Mermaid, and data frames.&lt;/p&gt;
&lt;h2 id=&#34;charts&#34;&gt;Charts&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the popular &lt;a href=&#34;https://plot.ly/&#34;&gt;Plotly&lt;/a&gt; format for interactive data visualizations. With Plotly, you can design almost any kind of visualization you can imagine!&lt;/p&gt;
&lt;p&gt;Save your Plotly JSON in your page folder, for example &lt;code&gt;line-chart.json&lt;/code&gt;, and then add the &lt;code&gt;{{&amp;lt; chart data=&amp;quot;line-chart&amp;quot; &amp;gt;}}&lt;/code&gt; shortcode where you would like the chart to appear.&lt;/p&gt;
&lt;p&gt;Demo:&lt;/p&gt;




&lt;div id=&#34;chart-458629317&#34; class=&#34;chart&#34;&gt;&lt;/div&gt;
&lt;script&gt;
  async function fetchChartJSON() {
    console.debug(&#39;Hugo Blox fetching chart JSON...&#39;)
    const response = await fetch(&#39;.\/line-chart.json&#39;);
    return await response.json();
  }

  (function() {
    let a = setInterval( function() {
      if ( typeof window.Plotly === &#39;undefined&#39; ) {
        console.debug(&#39;Plotly not loaded yet...&#39;)
        return;
      }
      clearInterval( a );

      fetchChartJSON().then(chart =&gt; {
        console.debug(&#39;Plotting chart...&#39;)
        window.Plotly.newPlot(&#39;chart-458629317&#39;, chart.data, chart.layout, {responsive: true});
      });
    }, 500 );
  })();
&lt;/script&gt;

&lt;p&gt;You might also find the &lt;a href=&#34;http://plotly-json-editor.getforge.io/&#34;&gt;Plotly JSON Editor&lt;/a&gt; useful.&lt;/p&gt;
&lt;h2 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the &lt;em&gt;Mermaid&lt;/em&gt; Markdown extension for diagrams.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;flowchart&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;graph TD
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A[Hard] --&amp;gt;|Text| B(Round)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;B --&amp;gt; C{Decision}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;C --&amp;gt;|One| D[Result 1]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;C --&amp;gt;|Two| E[Result 2]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An example &lt;strong&gt;sequence diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sequenceDiagram
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;loop Healthcheck
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    John-&amp;gt;&amp;gt;John: Fight against hypochondria
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;end
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Note right of John: Rational thoughts!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;John--&amp;gt;&amp;gt;Alice: Great!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;John-&amp;gt;&amp;gt;Bob: How about you?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Bob--&amp;gt;&amp;gt;John: Jolly good!
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An example &lt;strong&gt;class diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
Class08 &amp;lt;--&amp;gt; C2: Cool label
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;classDiagram
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class01 &amp;lt;|-- AveryLongClass : Cool
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class03 *-- Class04
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class05 o-- Class06
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class07 .. Class08
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class09 --&amp;gt; C2 : Where am i?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class09 --* C3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class09 --|&amp;gt; Class07
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class07 : equals()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class07 : Object[] elementData
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class01 : size()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class01 : int chimp
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class01 : int gorilla
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Class08 &amp;lt;--&amp;gt; C2: Cool label
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An example &lt;strong&gt;state diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;stateDiagram
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[*] --&amp;gt; Still
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Still --&amp;gt; [*]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Still --&amp;gt; Moving
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Moving --&amp;gt; Still
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Moving --&amp;gt; Crash
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Crash --&amp;gt; [*]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;data-frames&#34;&gt;Data Frames&lt;/h2&gt;
&lt;p&gt;Save your spreadsheet as a CSV file in your page&amp;rsquo;s folder and then render it by adding the &lt;em&gt;Table&lt;/em&gt; shortcode to your page:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;results.csv&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;header&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;caption&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Table 1: My results&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;














&lt;table class=&#34;table-auto w-full&#34;&gt;
  
    
    
    &lt;thead&gt;
      &lt;tr&gt;  &lt;th class=&#34;border-b dark:border-slate-600 font-medium p-4 pt-0 pb-3 text-slate-400 dark:text-slate-200 text-left&#34;&gt;customer_id&lt;/th&gt;  &lt;th class=&#34;border-b dark:border-slate-600 font-medium p-4 pt-0 pb-3 text-slate-400 dark:text-slate-200 text-left&#34;&gt;score&lt;/th&gt;  &lt;/tr&gt;
    &lt;/thead&gt;
  
  &lt;tbody&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;1&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;0&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;2&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;text&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;0.5&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;3&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;1&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
  &lt;/tbody&gt;
  
    &lt;caption class=&#34;table-caption&#34;&gt;Table 1: My results&lt;/caption&gt;
  
&lt;/table&gt;

&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>👩🏼‍🏫 Teach academic courses</title>
      <link>//localhost:4321/post/teach-courses/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/post/teach-courses/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube D2vj0WcvH5c &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili BV1WV4y1r7DF &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;w-full h-auto aspect-video relative&#34;&gt;
  &lt;iframe src=&#34;//player.bilibili.com/player.html?bvid=BV1WV4y1r7DF&amp;page=1&#34;
  allow=&#34;accelerometer; clipboard-write; encrypted-media; gyroscope; fullscreen; picture-in-picture;&#34;
  class=&#34;w-full h-full&#34;
  &gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;//localhost:4321/post/teach-courses/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;👉 Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;👉 Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me 🎉
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. Enable math by setting the &lt;code&gt;math: true&lt;/code&gt; option in your page&amp;rsquo;s front matter, or enable math for your entire site by toggling math in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;$...$&lt;/code&gt; or &lt;code&gt;$$...$$&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$
&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;$\nabla F(\mathbf{x}_{n})$&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$
&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Learn JavaScript</title>
      <link>//localhost:4321/post/js/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/post/js/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube w7Ft2ymGmfc &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili id=&amp;quot;BV1WV4y1r7DF&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;//localhost:4321/post/js/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;👉 Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;👉 Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me 🎉
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;{{&amp;lt; math &amp;gt;}}$...${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; or &lt;code&gt;{{&amp;lt; math &amp;gt;}}$$...$${{&amp;lt; /math &amp;gt;}}&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;We wrap the LaTeX math in the Hugo Blox &lt;em&gt;math&lt;/em&gt; shortcode to prevent Hugo rendering our math as Markdown.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;

$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$


&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;{{&amp;lt; math &amp;gt;}}$\nabla F(\mathbf{x}_{n})${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$
.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;


$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$



&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Learn Python</title>
      <link>//localhost:4321/post/python/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/post/python/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;


    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube w7Ft2ymGmfc &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili id=&amp;quot;BV1WV4y1r7DF&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;//localhost:4321/post/python/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;👉 Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;👉 Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me 🎉
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;{{&amp;lt; math &amp;gt;}}$...${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; or &lt;code&gt;{{&amp;lt; math &amp;gt;}}$$...$${{&amp;lt; /math &amp;gt;}}&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;We wrap the LaTeX math in the Hugo Blox &lt;em&gt;math&lt;/em&gt; shortcode to prevent Hugo rendering our math as Markdown.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;

$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$


&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;{{&amp;lt; math &amp;gt;}}$\nabla F(\mathbf{x}_{n})${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$
.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;


$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$



&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>✅ Manage your projects</title>
      <link>//localhost:4321/post/project-management/</link>
      <pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/post/project-management/</guid>
      <description>&lt;p&gt;Easily manage your projects - create ideation mind maps, Gantt charts, todo lists, and more!&lt;/p&gt;
&lt;h2 id=&#34;ideation&#34;&gt;Ideation&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports a Markdown extension for mindmaps.&lt;/p&gt;
&lt;p&gt;Simply insert a Markdown code block labelled as &lt;code&gt;markmap&lt;/code&gt; and optionally set the height of the mindmap as shown in the example below.&lt;/p&gt;
&lt;p&gt;Mindmaps can be created by simply writing the items as a Markdown list within the &lt;code&gt;markmap&lt;/code&gt; code block, indenting each item to create as many sub-levels as you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap {height=&#34;200px&#34;}
- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the &lt;em&gt;Mermaid&lt;/em&gt; Markdown extension for diagrams.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;Gantt diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
&lt;/div&gt;
&lt;h2 id=&#34;todo-lists&#34;&gt;Todo lists&lt;/h2&gt;
&lt;p&gt;You can even write your todo lists in Markdown too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write math example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write diagram example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [ ]&lt;/span&gt; Do something else
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write math example
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write diagram example&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Do something else&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>The Eyes of the Tree: Applying Field Environmental Philosophy to Tackle Conservation Problems at Long-Term Socio-ecological Research Sites</title>
      <link>//localhost:4321/books/book2/</link>
      <pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/books/book2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Enhancing animal movement analyses - Spatiotemporal matching of animal positions with remotely sensed data using Google Earth Engine and R</title>
      <link>//localhost:4321/teaching/rgee/</link>
      <pubDate>Thu, 18 Aug 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/teaching/rgee/</guid>
      <description>&lt;p&gt;Ramiro D. Crego &lt;sup&gt;a,b&lt;/sup&gt;, Majaliwa M. Masolele &lt;sup&gt;c&lt;/sup&gt;, Grant Connette &lt;sup&gt;a,b&lt;/sup&gt;, and Jared A. Stabach &lt;sup&gt;a&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;a - Smithsonian National Zoo and Conservation Biology Institute,
Conservation Ecology Center, 1500 Remount Rd, Front Royal, VA 22630,
USA.&lt;/p&gt;
&lt;p&gt;b - Working Land and Seascapes, Conservation Commons, Smithsonian
Institution, Washington, DC 20013, USA.&lt;/p&gt;
&lt;p&gt;c - Boyd Orr Centre for Population and Ecosystem Health, Institute of
Biodiversity, Animal Health &amp;amp; Comparative Medicine (IBAHCM), University
of Glasgow, G12 8QQ, UK.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The following tutorial describes the code workflow presented in the
manuscript “Enhancing animal movement analyses - Spatiotemporal matching
of animal positions with remotely sensed data using Google Earth Engine
and R.”&lt;/p&gt;
&lt;figure&gt;&lt;a href=&#34;https://www.mdpi.com/2072-4292/13/20/4154&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;./Figures/23.png&#34;/&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;The code workflow allows you to find the closest image from an image
collection to the time at which each GPS location was acquired and
extract the pixel value.&lt;/p&gt;
&lt;p&gt;To use this code it is necessary to have a &lt;a href=&#34;https://earthengine.google.com/&#34;&gt;Google Earth
Engine&lt;/a&gt; account and to install the
&lt;code&gt;rgee&lt;/code&gt;
&lt;a href=&#34;https://r-spatial.github.io/rgee/#quick-start-users-guide-for-rgee&#34;&gt;package&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;loading-and-preparing-tracking-data&#34;&gt;Loading and preparing tracking data&lt;/h2&gt;
&lt;p&gt;The first step is to read a csv file with the telemetry data.&lt;/p&gt;
&lt;p&gt;For this example we randomly selected 100 GPS fixes from the entire
wildebeest dataset used in the manuscript, obtained from
&lt;a href=&#34;https://www.datarepository.movebank.org/handle/10255/move.1098&#34;&gt;Movebank&lt;/a&gt;.
The data is provided in the repository within the folder Data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(sf)
library(dplyr)
trackingdata &amp;lt;- read.csv(&amp;quot;./Data/Data.csv&amp;quot;, header = T) #Load your dataset
head(trackingdata)

##             timestamp location.long location.lat
## 1 2010-08-10 15:00:00      35.21622    -1.164488
## 2 2011-06-26 12:00:00      36.83339    -1.462866
## 3 2011-10-19 03:00:00      36.90053    -1.404862
## 4 2011-11-20 12:00:00      36.91039    -1.430901
## 5 2010-08-29 14:00:00      35.30668    -1.345507
## 6 2010-12-20 05:00:00      36.91189    -1.433012
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next step, we need to convert the dataframe into an sf object. We
also need to set the date as a string with a ‘YYYY-MM-DDTHH:MM:SS’. We
will use this data to convert it into milliseconds since midnight on
January 1, 1970, a format used in Google Earth Engine to manage dates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;trackingdata$Date &amp;lt;- as.POSIXct(trackingdata$timestamp, format = &amp;quot;%Y-%m-%d %H:%M:%S&amp;quot;, tz=&amp;quot;UTC&amp;quot;) #Modify as necessary
trackingdata$Date &amp;lt;- as.factor(trackingdata$Date)
trackingdata$Date &amp;lt;- sub(&amp;quot; &amp;quot;, &amp;quot;T&amp;quot;, trackingdata$Date) #Put in a format that can be read by javascript
trackingdata$ID &amp;lt;- seq(1:nrow(trackingdata)) # Add ID to each point (optional)
datasf &amp;lt;- st_as_sf(trackingdata, coords = c(&#39;location.long&#39;,&#39;location.lat&#39;), crs = 4326) #Transform the dataframe into sf object. Make sure the name of the columns for the coordinates match. CRS needs to be in longlat WGS84.
head(datasf)

## Simple feature collection with 6 features and 3 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: 35.21622 ymin: -1.462866 xmax: 36.91189 ymax: -1.164488
## Geodetic CRS:  WGS 84
##             timestamp                Date ID
## 1 2010-08-10 15:00:00 2010-08-10T15:00:00  1
## 2 2011-06-26 12:00:00 2011-06-26T12:00:00  2
## 3 2011-10-19 03:00:00 2011-10-19T03:00:00  3
## 4 2011-11-20 12:00:00 2011-11-20T12:00:00  4
## 5 2010-08-29 14:00:00 2010-08-29T14:00:00  5
## 6 2010-12-20 05:00:00 2010-12-20T05:00:00  6
##                     geometry
## 1 POINT (35.21622 -1.164488)
## 2 POINT (36.83339 -1.462866)
## 3 POINT (36.90053 -1.404862)
## 4 POINT (36.91039 -1.430901)
## 5 POINT (35.30668 -1.345507)
## 6 POINT (36.91189 -1.433012)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;initialize-rgee&#34;&gt;Initialize rgee&lt;/h2&gt;
&lt;p&gt;Next, we need to load and initialize rgee.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(rgee)
ee_Initialize()
ee_check()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;define-google-earth-engine-functions&#34;&gt;Define Google Earth Engine functions&lt;/h2&gt;
&lt;p&gt;The next set of functions will be used to match images to the data and
extract pixel values.&lt;/p&gt;
&lt;p&gt;Note that you can edit the maximum temporal window allowed to find a
match.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#Function to add property with time in milliseconds
add_date&amp;lt;-function(feature) {
  date &amp;lt;- ee$Date(ee$String(feature$get(&amp;quot;Date&amp;quot;)))$millis()
  feature$set(list(date_millis=date))
}

#Join Image and Points based on a maxDifference Filter within a temporal window

#Set temporal window in days for filter. This will depend on the remote sensing data used.
tempwin &amp;lt;- 16 

#Set the filter
maxDiffFilter&amp;lt;-ee$Filter$maxDifference(
  difference=tempwin*24*60*60*1000, #days * hr * min * sec * milliseconds
  leftField= &amp;quot;date_millis&amp;quot;, #Timestamp of the telemetry data
  rightField=&amp;quot;system:time_start&amp;quot; #Image date
)

# Define the join. We implement the saveBest function for the join, which finds the image that best matches the filter (i.e., the image closest in time to the particular GPS fix location). 
saveBestJoin&amp;lt;-ee$Join$saveBest(
  matchKey=&amp;quot;bestImage&amp;quot;,
  measureKey=&amp;quot;timeDiff&amp;quot;
)

#Function to add property with raster pixel value from the matched image
add_value&amp;lt;-function(feature){
  #Get the image selected by the join
  img1&amp;lt;-ee$Image(feature$get(&amp;quot;bestImage&amp;quot;))$select(band)
  #Extract geometry from the feature
  point&amp;lt;-feature$geometry()
  #Get pixel value for each point at the desired spatial resolution (argument scale)
  pixel_value&amp;lt;-img1$sample(region=point, scale=250, tileScale = 16, dropNulls = F) 
  #Return the data containing pixel value and image date.
  feature$setMulti(list(PixelVal = pixel_value$first()$get(band), DateTimeImage = img1$get(&#39;system:index&#39;)))
}

# Function to remove image property from features
removeProperty&amp;lt;- function(feature) {
  #Get the properties of the data
  properties = feature$propertyNames()
  #Select all items except images
  selectProperties = properties$filter(ee$Filter$neq(&amp;quot;item&amp;quot;, &amp;quot;bestImage&amp;quot;))
  #Return selected features
  feature$select(selectProperties)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;load-image-collection&#34;&gt;Load image collection&lt;/h2&gt;
&lt;p&gt;In this example, we are using NDVI from MODIS Terra Vegetation Indexes
16-Day Global 250m data set. However, you can use any other remote
sensing product of interest and filter to the desired dates.&lt;/p&gt;
&lt;p&gt;One of the main advantages offered by Google Earth Engine is the
enormous amount of data available to be used. The constantly growing
database consists on more than a petabyte archive of publicly available
remotely sensed imagery and other related data sets. In the study cases
of the manuscript we used MOD13Q1 and ERA5_LAND/HOURLY, but data
available includes other products from MODIS, data from other satellites
such as Landsat, National Oceanographic and Atmospheric Administration
Advanced Very High Resolution Radiometer (NOAA AVHRR), Sentinel 1, 2, 3
and 5-P, Advanced Land Observing Satellite (ALOS), and other products
such as sea surface temperature data, CHIRPS climate data, topography
data, and land cover data. The entire list of datasets is available at
this
&lt;a href=&#34;https://developers.google.com/earth-engine/datasets/catalog&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note that all image collections in Earth Engine have a code that you can
extract from the link provided above and use to import into the workflow
by modifying this example.&lt;/p&gt;
&lt;p&gt;We will set the start and end days to filter the image collections.
Temporal availability depends on each dataset.&lt;/p&gt;
&lt;p&gt;We will also create an object with the name of the band we are
interested in working with. The name of the band is also specific to
each image collection.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;start&amp;lt;-&amp;quot;2010-01-01&amp;quot;
end&amp;lt;-&amp;quot;2013-01-01&amp;quot;
imagecoll&amp;lt;-ee$ImageCollection(&#39;MODIS/006/MOD13Q1&#39;)$filterDate(start,end)
band &amp;lt;- &amp;quot;NDVI&amp;quot; #Name of the band to use. You can change to EVI for instance when using MOD13Q1.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;extract-pixel-value&#34;&gt;Extract pixel value&lt;/h2&gt;
&lt;p&gt;A key function in this process is the &lt;code&gt;ee_as_sf&lt;/code&gt; which converts the
Google Earth Engine table in a sf object. This function provides three
different options to convert the table (feature collection) into a sf
object:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;getInfo: which is fast and direct but has a limit of 5000 features&lt;/li&gt;
&lt;li&gt;drive: which exports data through your Google Drive account&lt;/li&gt;
&lt;li&gt;gsc: which exports data through your Google Cloud Storage account&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can find more information about this function in the help:
?ee_as_sf&lt;/p&gt;
&lt;p&gt;We use here the &lt;code&gt;getInfo&lt;/code&gt; option given it is direct and simple. However,
this option has a limit of 5000 features to convert. For that reason, we
are going to run a loop, processing 1000 features (points) per time to
avoid errors. If memory limit errors are display, then you can reduce
the number of points to extract each time by changing the &lt;code&gt;each&lt;/code&gt;
argument on the &lt;code&gt;rep&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;In this example we only have 100 points so the loop will only run once,
but for larger datasets the loop may run multiple times.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;datasf$uniq &amp;lt;- rep(1:1000, each=1000)[1:nrow(datasf)] #This is for up to 1 million points. To increase the max number of points, increase the value for max repetitions. To change the number of points to run per time, change the value in the argument each (up to 5000).

start_time &amp;lt;- Sys.time()
dataoutput &amp;lt;- data.frame()
for(x in unique(datasf$uniq)){
  data1 &amp;lt;- datasf %&amp;gt;% filter(uniq == x)
  # Send sf to GEE
  data &amp;lt;- sf_as_ee(data1)
  # Transform day into milliseconds
  data&amp;lt;-data$map(add_date)
  # Apply the join
  Data_match&amp;lt;-saveBestJoin$apply(data, imagecoll, maxDiffFilter)
  # Add pixel value to the data
  DataFinal&amp;lt;-Data_match$map(add_value)
  # Remove image property from the data
  DataFinal&amp;lt;-DataFinal$map(removeProperty)
  # Move GEE object into R
  temp&amp;lt;- ee_as_sf(DataFinal, via = &#39;getInfo&#39;)
  # Append
  dataoutput &amp;lt;- rbind(dataoutput, temp)
}
end_time &amp;lt;- Sys.time()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The time needed to run 100 points was:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;end_time - start_time

## Time difference of 3.329701 secs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new sf data frame with the pixel values in now stored as the
&lt;code&gt;dataoutput&lt;/code&gt; object. You can use this for further analysis.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;names(dataoutput)[4] &amp;lt;- band
dataoutput

## Simple feature collection with 100 features and 7 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: 34.99598 ymin: -2.693471 xmax: 37.5994 ymax: -1.148282
## Geodetic CRS:  WGS 84
## First 10 features:
##                   Date DateTimeImage ID NDVI date_millis
## 1  2010-08-10 15:00:00    2010_08_13  1 3011  1552145792
## 2  2011-06-26 12:00:00    2011_06_26  2 3632  -875425280
## 3  2011-10-19 03:00:00    2011_10_16  3 2957   438240128
## 4  2011-11-20 12:00:00    2011_11_17  4 4952 -1059527168
## 5  2010-08-29 14:00:00    2010_08_29  5 2699 -1104821504
## 6  2010-12-20 05:00:00    2010_12_19  6 3518    36043904
## 7  2010-07-16 18:01:00    2010_07_12  7 3227  -596994208
## 8  2011-12-09 03:01:00    2011_12_03  8 4460   549732832
## 9  2012-01-01 07:00:00    2012_01_01  9 2624 -1743694464
## 10 2012-04-16 04:00:00    2012_04_22 10 5840 -1186029056
##              timestamp uniq                   geometry
## 1  2010-08-10 15:00:00    1 POINT (35.21622 -1.164488)
## 2  2011-06-26 12:00:00    1 POINT (36.83339 -1.462866)
## 3  2011-10-19 03:00:00    1 POINT (36.90053 -1.404862)
## 4  2011-11-20 12:00:00    1 POINT (36.91039 -1.430901)
## 5  2010-08-29 14:00:00    1 POINT (35.30668 -1.345507)
## 6  2010-12-20 05:00:00    1 POINT (36.91189 -1.433012)
## 7  2010-07-16 18:01:00    1 POINT (35.24742 -1.324172)
## 8  2011-12-09 03:01:00    1   POINT (37.565 -2.446763)
## 9  2012-01-01 07:00:00    1 POINT (37.03885 -2.620116)
## 10 2012-04-16 04:00:00    1 POINT (35.52517 -1.233949)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;visualize-locations&#34;&gt;Visualize locations&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Pres &amp;lt;- dataoutput

library(tmap)
tmap_mode(&#39;plot&#39;)
tm_shape(Pres) + tm_dots(col = &#39;blue&#39;, title = &amp;quot;Presence&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;tutorial_files/figure-markdown_strict/unnamed-chunk-11-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;session&#34;&gt;Session&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;devtools::session_info()

## ─ Session info ─────────────────────────────────────────────────
##  setting  value
##  version  R version 4.4.1 (2024-06-14)
##  os       macOS Sonoma 14.5
##  system   aarch64, darwin20
##  ui       RStudio
##  language (EN)
##  collate  en_US.UTF-8
##  ctype    en_US.UTF-8
##  tz       Europe/Dublin
##  date     2024-07-20
##  rstudio  2024.04.2+764 Chocolate Cosmos (desktop)
##  pandoc   3.1.11 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)
## 
## ─ Packages ─────────────────────────────────────────────────────
##  package           * version   date (UTC) lib source
##  abind               1.4-5     2016-07-21 [1] CRAN (R 4.4.0)
##  base64enc           0.1-3     2015-07-28 [1] CRAN (R 4.4.0)
##  cachem              1.1.0     2024-05-16 [1] CRAN (R 4.4.0)
##  class               7.3-22    2023-05-03 [1] CRAN (R 4.4.1)
##  classInt            0.4-10    2023-09-05 [1] CRAN (R 4.4.0)
##  cli                 3.6.3     2024-06-21 [1] CRAN (R 4.4.0)
##  codetools           0.2-20    2024-03-31 [1] CRAN (R 4.4.1)
##  crayon              1.5.3     2024-06-20 [1] CRAN (R 4.4.0)
##  crosstalk           1.2.1     2023-11-23 [1] CRAN (R 4.4.0)
##  crul                1.5.0     2024-07-19 [1] CRAN (R 4.4.0)
##  curl                5.2.1     2024-03-01 [1] CRAN (R 4.4.0)
##  DBI                 1.2.3     2024-06-02 [1] CRAN (R 4.4.0)
##  devtools            2.4.5     2022-10-11 [1] CRAN (R 4.4.0)
##  dichromat           2.0-0.1   2022-05-02 [1] CRAN (R 4.4.0)
##  digest              0.6.36    2024-06-23 [1] CRAN (R 4.4.0)
##  dplyr             * 1.1.4     2023-11-17 [1] CRAN (R 4.4.0)
##  e1071               1.7-14    2023-12-06 [1] CRAN (R 4.4.0)
##  ellipsis            0.3.2     2021-04-29 [1] CRAN (R 4.4.0)
##  evaluate            0.24.0    2024-06-10 [1] CRAN (R 4.4.0)
##  fansi               1.0.6     2023-12-08 [1] CRAN (R 4.4.0)
##  fastmap             1.2.0     2024-05-15 [1] CRAN (R 4.4.0)
##  fs                  1.6.4     2024-04-25 [1] CRAN (R 4.4.0)
##  generics            0.1.3     2022-07-05 [1] CRAN (R 4.4.0)
##  geojson             0.3.5     2023-08-08 [1] CRAN (R 4.4.0)
##  geojsonio           0.11.3    2023-09-06 [1] CRAN (R 4.4.0)
##  geojsonsf           2.0.3     2022-05-30 [1] CRAN (R 4.4.0)
##  glue                1.7.0     2024-01-09 [1] CRAN (R 4.4.0)
##  highr               0.11      2024-05-26 [1] CRAN (R 4.4.0)
##  htmltools           0.5.8.1   2024-04-04 [1] CRAN (R 4.4.0)
##  htmlwidgets         1.6.4     2023-12-06 [1] CRAN (R 4.4.0)
##  httpcode            0.3.0     2020-04-10 [1] CRAN (R 4.4.0)
##  httpuv              1.6.15    2024-03-26 [1] CRAN (R 4.4.0)
##  jqr                 1.3.3     2023-12-04 [1] CRAN (R 4.4.0)
##  jquerylib           0.1.4     2021-04-26 [1] CRAN (R 4.4.0)
##  jsonlite            1.8.8     2023-12-04 [1] CRAN (R 4.4.0)
##  KernSmooth          2.23-24   2024-05-17 [1] CRAN (R 4.4.1)
##  knitr               1.48      2024-07-07 [1] CRAN (R 4.4.0)
##  later               1.3.2     2023-12-06 [1] CRAN (R 4.4.0)
##  lattice             0.22-6    2024-03-20 [1] CRAN (R 4.4.1)
##  lazyeval            0.2.2     2019-03-15 [1] CRAN (R 4.4.0)
##  leafem              0.2.3     2023-09-17 [1] CRAN (R 4.4.0)
##  leaflet             2.2.2     2024-03-26 [1] CRAN (R 4.4.0)
##  leaflet.providers   2.0.0     2023-10-17 [1] CRAN (R 4.4.0)
##  leafsync            0.1.0     2019-03-05 [1] CRAN (R 4.4.0)
##  lifecycle           1.0.4     2023-11-07 [1] CRAN (R 4.4.0)
##  lwgeom              0.2-14    2024-02-21 [1] CRAN (R 4.4.0)
##  magrittr            2.0.3     2022-03-30 [1] CRAN (R 4.4.0)
##  Matrix              1.7-0     2024-04-26 [1] CRAN (R 4.4.1)
##  memoise             2.0.1     2021-11-26 [1] CRAN (R 4.4.0)
##  mime                0.12      2021-09-28 [1] CRAN (R 4.4.0)
##  miniUI              0.1.1.1   2018-05-18 [1] CRAN (R 4.4.1)
##  pillar              1.9.0     2023-03-22 [1] CRAN (R 4.4.0)
##  pkgbuild            1.4.4     2024-03-17 [1] CRAN (R 4.4.0)
##  pkgconfig           2.0.3     2019-09-22 [1] CRAN (R 4.4.0)
##  pkgload             1.4.0     2024-06-28 [1] CRAN (R 4.4.0)
##  png                 0.1-8     2022-11-29 [1] CRAN (R 4.4.0)
##  processx            3.8.4     2024-03-16 [1] CRAN (R 4.4.0)
##  profvis             0.3.8     2023-05-02 [1] CRAN (R 4.4.0)
##  promises            1.3.0     2024-04-05 [1] CRAN (R 4.4.0)
##  proxy               0.4-27    2022-06-09 [1] CRAN (R 4.4.0)
##  ps                  1.7.7     2024-07-02 [1] CRAN (R 4.4.0)
##  purrr               1.0.2     2023-08-10 [1] CRAN (R 4.4.0)
##  R6                  2.5.1     2021-08-19 [1] CRAN (R 4.4.0)
##  raster              3.6-26    2023-10-14 [1] CRAN (R 4.4.0)
##  RColorBrewer        1.1-3     2022-04-03 [1] CRAN (R 4.4.0)
##  Rcpp                1.0.12    2024-01-09 [1] CRAN (R 4.4.0)
##  remotes             2.5.0     2024-03-17 [1] CRAN (R 4.4.0)
##  reticulate          1.38.0    2024-06-19 [1] CRAN (R 4.4.0)
##  rgee              * 1.1.7     2023-09-27 [1] CRAN (R 4.4.0)
##  rlang               1.1.4     2024-06-04 [1] CRAN (R 4.4.0)
##  rmarkdown         * 2.27      2024-05-17 [1] CRAN (R 4.4.0)
##  rstudioapi          0.16.0    2024-03-24 [1] CRAN (R 4.4.0)
##  s2                  1.1.7     2024-07-17 [1] CRAN (R 4.4.0)
##  sessioninfo         1.2.2     2021-12-06 [1] CRAN (R 4.4.0)
##  sf                * 1.0-16    2024-03-24 [1] CRAN (R 4.4.0)
##  shiny               1.8.1.1   2024-04-02 [1] CRAN (R 4.4.0)
##  sp                  2.1-4     2024-04-30 [1] CRAN (R 4.4.0)
##  stars               0.6-6     2024-07-16 [1] CRAN (R 4.4.0)
##  stringi             1.8.4     2024-05-06 [1] CRAN (R 4.4.0)
##  stringr             1.5.1     2023-11-14 [1] CRAN (R 4.4.0)
##  terra               1.7-78    2024-05-22 [1] CRAN (R 4.4.0)
##  tibble              3.2.1     2023-03-20 [1] CRAN (R 4.4.0)
##  tidyselect          1.2.1     2024-03-11 [1] CRAN (R 4.4.0)
##  tmap              * 3.3-4     2023-09-12 [1] CRAN (R 4.4.0)
##  tmaptools           3.1-1     2021-01-19 [1] CRAN (R 4.4.0)
##  units               0.8-5     2023-11-28 [1] CRAN (R 4.4.0)
##  urlchecker          1.0.1     2021-11-30 [1] CRAN (R 4.4.0)
##  usethis             2.2.3     2024-02-19 [1] CRAN (R 4.4.0)
##  utf8                1.2.4     2023-10-22 [1] CRAN (R 4.4.0)
##  V8                  4.4.2     2024-02-15 [1] CRAN (R 4.4.0)
##  vctrs               0.6.5     2023-12-01 [1] CRAN (R 4.4.0)
##  viridisLite         0.4.2     2023-05-02 [1] CRAN (R 4.4.0)
##  webshot             0.5.5     2023-06-26 [1] CRAN (R 4.4.0)
##  wk                  0.9.2     2024-07-09 [1] CRAN (R 4.4.0)
##  xfun                0.45      2024-06-16 [1] CRAN (R 4.4.0)
##  XML                 3.99-0.17 2024-06-25 [1] CRAN (R 4.4.0)
##  xtable              1.8-4     2019-04-21 [1] CRAN (R 4.4.0)
##  yaml                2.3.9     2024-07-05 [1] CRAN (R 4.4.0)
## 
##  [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library
## 
## ─ Python configuration ─────────────────────────────────────────
##  python:         /Users/ramirocrego/.virtualenvs/rgee/bin/python
##  libpython:      /Users/ramirocrego/Library/r-miniconda-arm64/lib/libpython3.10.dylib
##  pythonhome:     /Users/ramirocrego/.virtualenvs/rgee:/Users/ramirocrego/.virtualenvs/rgee
##  version:        3.10.12 (main, Jul  5 2023, 15:02:25) [Clang 14.0.6 ]
##  numpy:          /Users/ramirocrego/.virtualenvs/rgee/lib/python3.10/site-packages/numpy
##  numpy_version:  1.25.1
##  ee:             /Users/ramirocrego/.virtualenvs/rgee/lib/python3.10/site-packages/ee
##  
##  NOTE: Python version was forced by RETICULATE_PYTHON
## 
## ────────────────────────────────────────────────────────────────
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to spatial ecology with R - Part 1</title>
      <link>//localhost:4321/teaching/r/</link>
      <pubDate>Thu, 18 Aug 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/teaching/r/</guid>
      <description>&lt;h2 id=&#34;foreword&#34;&gt;Foreword&lt;/h2&gt;
&lt;p&gt;Geographic Information Systems, use of satellite imagery, modeling, and
mapping have become essentials in the toolbox of many researchers,
natural resource managers, and conservationists. Yet, these resources
are often not readily accessible to practitioners around the world. Most
restrictive is the limited access to specialized and expensive
commercial software. In recent years, several powerful open-source tools
for geospatial analysis have emerged. R is a widely used statistical
programming language with considerable geospatial analysis capabilities.
This training focuses on performing geospatial work in R.&lt;/p&gt;
&lt;h2 id=&#34;learning-outcomes&#34;&gt;Learning Outcomes&lt;/h2&gt;
&lt;p&gt;By the end of these tutorials, you will be able to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Understand R coding language&lt;/li&gt;
&lt;li&gt;Understand how to troubleshoot for R errors&lt;/li&gt;
&lt;li&gt;Perform database and spatial queries in R&lt;/li&gt;
&lt;li&gt;Create and import spatial data in R&lt;/li&gt;
&lt;li&gt;Know basic raster and vector analysis functions in R&lt;/li&gt;
&lt;li&gt;Project spatial data in R&lt;/li&gt;
&lt;li&gt;Use R to create maps and visualize data&lt;/li&gt;
&lt;li&gt;Extract environmental values for spatial points and regions&lt;/li&gt;
&lt;li&gt;Fit Generalized Linear Models and predictions over space&lt;/li&gt;
&lt;li&gt;Learn to simulate that and the basics of Bayesian statistics.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;about-this-material&#34;&gt;About this material&lt;/h2&gt;
&lt;p&gt;This content has been the product of years of work and collaborations
with many amazing people. Some of the code has been provided by them.&lt;/p&gt;
&lt;p&gt;We thank Dr. Quingyu Huangm, Dr. Grant Connette, and Dr. Joseph Kolowski
for their inputs.&lt;/p&gt;
&lt;h2 id=&#34;required-software&#34;&gt;Required software&lt;/h2&gt;
&lt;p&gt;During the course, students will use R and R-Studio. R is a programming
language and free software environment for statistical computing widely
used by researchers. R-Studio is an integrated development environment
for R that makes the software more user friendly. Both R and R-Studio
are compatible with the most common operating systems and are free to
use. Before the course begins, you should have the software installed on
your personal computers. Installation files can be accessed at:&lt;/p&gt;
&lt;p&gt;-R: &lt;a href=&#34;https://www.r-project.org&#34;&gt;https://www.r-project.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;-RStudio Desktop: &lt;a href=&#34;https://rstudio.com/products/rstudio/&#34;&gt;https://rstudio.com/products/rstudio/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data-access&#34;&gt;Data access&lt;/h2&gt;
&lt;p&gt;All the data used in the tutorials are available in this
&lt;a href=&#34;https://github.com/ramirocrego/R-Tutorials/&#34;&gt;link&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;an-intro-to-the-r-programming-language&#34;&gt;An intro to the R programming language&lt;/h1&gt;
&lt;h2 id=&#34;what-is-r-and-why-use-r&#34;&gt;What is R and why use R?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; is a very powerful statistical programming language that is used broadly by researchers around the world. &lt;strong&gt;R&lt;/strong&gt; is an attractive programming language because it is free, open source, and platform independent. With all the libraries that are available (and those that are in rapid development), it is quickly becoming a one-stop shop for all your analysis needs. Most academic statisticians now use &lt;strong&gt;R&lt;/strong&gt;, which has allowed for greater sharing of &lt;strong&gt;R&lt;/strong&gt; code or packages to implement their recommended methods. One of the very first things academics often ask when hiring someone is simply, “Can you describe your &lt;strong&gt;R&lt;/strong&gt; or statistical programming experience?” It is now critical to have this background to be competitive for scientific (and many other) positions.&lt;/p&gt;
&lt;p&gt;Among the reasons to use &lt;strong&gt;R&lt;/strong&gt; you have:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It’s free – open source! If you are a teacher or a student, the
benefits are obvious.&lt;/li&gt;
&lt;li&gt;It runs on a variety of platforms including Windows, Unix and MacOS.&lt;/li&gt;
&lt;li&gt;It provides an unparalleled platform for programming new statistical
methods in an easy and straightforward manner.&lt;/li&gt;
&lt;li&gt;It contains advanced statistical routines not yet available in other
software.&lt;/li&gt;
&lt;li&gt;New add-on “packages” are being created and updated constantly.&lt;/li&gt;
&lt;li&gt;It has state-of-the-art graphics capabilities.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; does have a steep learning curve that can often be intimidating to
new users, particularly those without prior coding experience. While
this can be very frustrating in the initial stages, learning &lt;strong&gt;R&lt;/strong&gt; is
like learning a language where proficiency requires practice and
continual use of the program.&lt;/p&gt;
&lt;p&gt;Our advice is to push yourself to use this tool in everything you do. At
first, &lt;strong&gt;R&lt;/strong&gt; will not be the easiest or quickest option. With
persistence, however, you will see the benefit of &lt;strong&gt;R&lt;/strong&gt; and continue to
find new ways to use it in your work.&lt;/p&gt;
&lt;h2 id=&#34;r-or-rstudio-how-to-get-them&#34;&gt;R or RStudio? How to get them?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; is available for Linux, MacOS X, and Windows (95 or later)
platforms. Software can be downloaded from one of the &lt;a href=&#34;https://cran.r-project.org/&#34;&gt;Comprehensive R
Archive Network&lt;/a&gt; (CRAN) mirror sites. Once
installed, &lt;strong&gt;R&lt;/strong&gt; will open a console where you run code. You can also
work on a script file, where you can write and save your work, and other
windows that will show up on demand such as the plot tab (Fig. 1).&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;FIGURES/IntroToR_Fig1.png&#34;
alt=&#34;R console, script and plot tabs.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;R console, script and plot
tabs.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;RStudio&lt;/strong&gt; is an enterprise-ready professional software tool that
integrates with &lt;strong&gt;R&lt;/strong&gt;. It has some nice features beyond the normal &lt;strong&gt;R&lt;/strong&gt;
interface, which many users feel it is easier to use than &lt;strong&gt;R&lt;/strong&gt; (Fig.
2). Once you have installed &lt;strong&gt;R&lt;/strong&gt;, you should also download and install
&lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/&#34;&gt;RStudio&lt;/a&gt;. For this
course, we will work exclusively in &lt;em&gt;RStudio&lt;/em&gt;.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;FIGURES/IntroToR_Fig2.png&#34; alt=&#34;RStudio sowfware&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;RStudio sowfware&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&#34;getting-help&#34;&gt;Getting Help&lt;/h2&gt;
&lt;p&gt;One of the most useful commands in &lt;strong&gt;R&lt;/strong&gt; is &lt;code&gt;?&lt;/code&gt;. At the command prompt
(signified by &lt;code&gt;&amp;gt;&lt;/code&gt; in your Console window), type &lt;code&gt;?&lt;/code&gt; followed by any
command and you will be prompted with a help tab for that command (e.g.,
&lt;code&gt;?mean&lt;/code&gt; Fig. 3). You can also search through the help tab directly by
searching functions on the search bar.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;FIGURES/IntroToR_Fig3.png&#34; alt=&#34;Getting help on R.&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Getting help on R.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The internet also contains a vast quantity of useful information. There
are blogs, mailing lists, and various websites (e.g.,
&lt;a href=&#34;https://stackoverflow.com/&#34;&gt;https://stackoverflow.com/&lt;/a&gt;) dedicated to providing information about
&lt;strong&gt;R&lt;/strong&gt;, its packages, and potential error messages that you may encounter
(among other things). The trick is usually determining the key terms to
limit your search. I generally start any web-based search with
&lt;strong&gt;“R-Cran”&lt;/strong&gt;, which limits and focuses the search. Using “&lt;strong&gt;R&lt;/strong&gt;” as part
of your key terms does not, by itself, limit the search.&lt;/p&gt;
&lt;h2 id=&#34;basic-r-concepts&#34;&gt;Basic R concepts&lt;/h2&gt;
&lt;p&gt;There are a few concepts that are important to keep in mind before you
start coding. The fact that &lt;strong&gt;R&lt;/strong&gt; is a programming language may deter
some users who think “I can’t program”. This should not be the case for
two reasons. First, &lt;strong&gt;R&lt;/strong&gt; is an interpreted language, not a compiled
one, meaning that all commands typed on the keyboard are directly
executed without requiring you to build a complete program like in most
computer languages (C, Pascal, . . . ). Second, &lt;strong&gt;R&lt;/strong&gt;’s syntax is very
simple and intuitive. For instance, a linear regression can be done with
the command &lt;code&gt;lm(y ~ x)&lt;/code&gt; which means fitting a linear model with y as the
response and x as a predictor.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt;, in order to be executed, a function always needs to be written
with parentheses, even if there is nothing within them (e.g., &lt;code&gt;ls()&lt;/code&gt;).
If you type the name of a function without parentheses, &lt;strong&gt;R&lt;/strong&gt; will
display the content of the function.&lt;/p&gt;
&lt;p&gt;When &lt;strong&gt;R&lt;/strong&gt; is running, variables, data, functions, results, etc…, are
stored in the active memory of the computer in the form of objects that
you assign a name.The user can do actions on these objects with
operators (arithmetic, logical, comparison, . . . ) and functions (which
are themselves objects).&lt;/p&gt;
&lt;p&gt;The name of an object must start with a letter (A-Z or a-z) and can be
followed by letters, digits (0-9), dots (.), and underscores (_).&lt;/p&gt;
&lt;p&gt;When referring to the directory of a folder or a data file, &lt;strong&gt;R&lt;/strong&gt; uses
forward slash “/”. You need to pay close attention to the direction of
the slash if you copy a file path or directory from a Windows machine.&lt;/p&gt;
&lt;p&gt;It is also important to know that &lt;strong&gt;R&lt;/strong&gt; discriminates between uppercase
and lowercase letters in the names of objects, so that x and X can name
two distinct objects (even under Windows).&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;starting-with-r&#34;&gt;Starting with R&lt;/h2&gt;
&lt;h3 id=&#34;setting-your-working-directory&#34;&gt;Setting your working directory&lt;/h3&gt;
&lt;p&gt;Like in many other programs, you should start your session by defining
your working directory - the folder where you will work. This will be
the location on your computer where any files you save will be located.
To determine your current working directory, type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;getwd()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use &lt;code&gt;setwd()&lt;/code&gt; to change or set a new working directory. For instance,
you can set your working directory to be in your Documents folder on the
C: drive, or in any folder you prefer.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;setwd(&amp;quot;C:/Documents/R_Practice&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In &lt;em&gt;RStudio&lt;/em&gt;, you can do some basic operations, such as setting your
working directory, using the point-and-click interface: Session &amp;gt; Set
Working Directory &amp;gt; Choose Directory … as shown in Fig. 4.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;FIGURES/IntroToR_Fig4.png&#34;
alt=&#34;Setting working directory in RStudio&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Setting working directory in
RStudio&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;You can also work with &lt;strong&gt;R projects&lt;/strong&gt;. R projects have the advantage
that they enhance organization, collaboration, and reproducibility in
R-based work by providing a structured and isolated workspace for your
projects. They contribute to a more efficient and transparent workflow,
particularly when working on multiple projects or collaborating with
others.&lt;/p&gt;
&lt;p&gt;The main advantage is that R Projects create a dedicated workspace for
your R-related work, keeping all files, scripts, data, and outputs
within a well-defined directory. This isolation helps avoid conflicts
between projects and ensures a clean environment for each project. R
projects use relative paths, allowing you to refer to files and
directories within the project without specifying the full path. This
enhances portability and makes it easier to share your project with
others.&lt;/p&gt;
&lt;p&gt;To start a new R Project click File &amp;gt; New Project or directly click
on the R Project icon and follow the directions. You can set up your new
project on a new folder or an existing folder.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;FIGURES/IntroToR_Fig5.png&#34; alt=&#34;RStudio sowfware&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;RStudio sowfware&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&#34;r-fundamentals&#34;&gt;&lt;strong&gt;R&lt;/strong&gt; Fundamentals&lt;/h2&gt;
&lt;h3 id=&#34;data-types&#34;&gt;Data Types&lt;/h3&gt;
&lt;p&gt;There are four fundamental data types in &lt;strong&gt;R&lt;/strong&gt; that you will work with:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Character&lt;/li&gt;
&lt;li&gt;Numeric&lt;/li&gt;
&lt;li&gt;Integer&lt;/li&gt;
&lt;li&gt;Logical&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can check the data type of an object using the function &lt;code&gt;class()&lt;/code&gt;.
To convert between data types you can use: &lt;code&gt;as.integer()&lt;/code&gt;,
&lt;code&gt;as.numeric()&lt;/code&gt;, &lt;code&gt;as.logical()&lt;/code&gt;, &lt;code&gt;as. character()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;city &amp;lt;- &#39;Nairobi&#39;
class(city)

## [1] &amp;quot;character&amp;quot;

number &amp;lt;- 3
class(number)

## [1] &amp;quot;numeric&amp;quot;

Integer &amp;lt;- as.integer(number)
class(Integer)

## [1] &amp;quot;integer&amp;quot;

logical &amp;lt;- 3 &amp;gt; 5
logical

## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;assigning-data-to-objects&#34;&gt;Assigning data to objects&lt;/h3&gt;
&lt;p&gt;Since &lt;strong&gt;R&lt;/strong&gt; is a programming language, we can store information as
objects to avoid unnecessary repetition. &lt;em&gt;Note again that values are
case sensitive; ‘x’ is not the same as ‘X’!&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;city &amp;lt;- &amp;quot;front royal&amp;quot;
summary(city)

number &amp;lt;- 2
summary(number)

character &amp;lt;- as.character(2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Data are very often stored in different folders to maintain an
organizational pattern in your projects. In those cases, it is not
necessary to re-set the working directory every time we want to import
files to &lt;strong&gt;R&lt;/strong&gt; that are stored in different folders, as long as these
folders are within the root directory you have previously set. For
instance, let’s say you have a table stored in a folder called &lt;em&gt;data&lt;/em&gt;,
which is a subfolder within your root working directory
&lt;em&gt;(C:/Documents/R_Practice)&lt;/em&gt;. You can point to the &lt;em&gt;data&lt;/em&gt; folder when
reading the table as in the example below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;table &amp;lt;- read.csv(file=&amp;quot;data/TheDataIWantToReadIn.csv&amp;quot;, header=TRUE) # read a csv table stored in the data folder
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that because &lt;em&gt;data&lt;/em&gt; is a subfolder in your root directory, you do
not need to provide the complete directory information when reading the
table &lt;strong&gt;“data/TheDataIWantToReadIn.csv”&lt;/strong&gt;. You can always provide the
full directory of a data file stored on your local drive to avoid
confusion.&lt;/p&gt;
&lt;h3 id=&#34;special-characters&#34;&gt;Special characters&lt;/h3&gt;
&lt;p&gt;The # character is used to add comments to your code. # indicates the
beginning of a comment and everything after # on a line will be ignored
and not run as code. Adding comments to your code is considered good
practice because it allows you to describe in plain language (for
yourself or others) what your code is doing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#This is a comment
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The semicolon (;) defines a line continuation character so that you can
write different commands on the same line of code.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a &amp;lt;- 3; b &amp;lt;- 6; c &amp;lt;- a+b
a

## [1] 3

b

## [1] 6

c

## [1] 9
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;r-data-structure&#34;&gt;R Data Structure&lt;/h2&gt;
&lt;h3 id=&#34;vectors&#34;&gt;Vectors&lt;/h3&gt;
&lt;p&gt;Vectors are a basic data structure in &lt;strong&gt;R&lt;/strong&gt;. They contain a sequence of
data and can contain characters, numbers, or be TRUE/FALSE values.
&lt;em&gt;Remember: If you are unsure or need help, use the help function (e.g.,
&lt;code&gt;help(seq)&lt;/code&gt; or &lt;code&gt;?seq&lt;/code&gt;)&lt;/em&gt;. Below are several ways to create vectors in
&lt;strong&gt;R&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1:20

##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20

c(1,2,3,4,5)

## [1] 1 2 3 4 5

seq(0,100,by=10)

##  [1]   0  10  20  30  40  50  60  70  80  90 100

rep(1:5,5)

##  [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5

rep(&amp;quot;A rolling stone gathers no moss&amp;quot;,4)

## [1] &amp;quot;A rolling stone gathers no moss&amp;quot;
## [2] &amp;quot;A rolling stone gathers no moss&amp;quot;
## [3] &amp;quot;A rolling stone gathers no moss&amp;quot;
## [4] &amp;quot;A rolling stone gathers no moss&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;extract-subset-of-values-from-a-vector-using--notation&#34;&gt;Extract subset of values from a vector using [] notation&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;x &amp;lt;- 1:10
y &amp;lt;- c(1.5, 9, 3.46, 12.2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see only part (i.e., a subset) of the data stored in a vector, you
need to “ask” &lt;strong&gt;R&lt;/strong&gt; to extract the information you want using square
brackets. Most commonly, you will indicate in square brackets the
position of the data you want to extract (from beginning of the vector
&lt;/p&gt;
\[1\]
&lt;p&gt; to the Nth slot in the vector &lt;/p&gt;
\[n\]
&lt;p&gt;). If you only wanted to see
the first 5 values of ‘x’, how would you do that? Or only the 2nd and
4th element of y? What if you wanted to see all the records in &lt;code&gt;y&lt;/code&gt;,
except for the 2nd and 3rd records? There are more ways to use notation
to select subsets of data, which we will cover in more detail below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x

##  [1]  1  2  3  4  5  6  7  8  9 10

(x &amp;lt;- 1:10)

##  [1]  1  2  3  4  5  6  7  8  9 10

x[1:5]

## [1] 1 2 3 4 5

y[c(2,4)]

## [1]  9.0 12.2

y[-c(2,3)]

## [1]  1.5 12.2
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;matrices-and-dataframes&#34;&gt;Matrices and Dataframes&lt;/h3&gt;
&lt;p&gt;Matrices and dataframes are common ways to store tabular data.
Understanding how to manipulate them is important to be able to conduct
more complex analyses. Both matrices and dataframes are composed of rows
and columns. The main difference between matrices and dataframes is that
dataframes can contain many different classes of data (numeric,
character, etc.), while matrices can only contain a single class.&lt;/p&gt;
&lt;p&gt;Create a matrix with 4 rows and 5 columns using the data from &lt;code&gt;x&lt;/code&gt; above.
Consult the help (e.g., &lt;code&gt;help(matrix)&lt;/code&gt; or &lt;code&gt;?matrix&lt;/code&gt;) to determine the
syntax required.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;test_matrix &amp;lt;- matrix(data = x, nrow = 4, ncol = 5)
test_matrix

##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    5    9    3    7
## [2,]    2    6   10    4    8
## [3,]    3    7    1    5    9
## [4,]    4    8    2    6   10

# Note, I can assign any name to an object that I create.  Generally it is best to name things in a way that is meaningful, but we&#39;ll have some fun here!
superman &amp;lt;- matrix(data = x, nrow = 4, ncol = 5)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;subset-of-matrices-and-dataframes&#34;&gt;Subset of Matrices and Dataframes&lt;/h4&gt;
&lt;p&gt;Now, if we wanted to reference any value in the matrix, we could do so
with matrix notation. The first value in matrix notation references the
row and the second value references the column. COMMIT THIS TO MEMORY! I
remember this by thinking &lt;strong&gt;R&lt;/strong&gt;oman &lt;strong&gt;C&lt;/strong&gt;atholic. So, if you wanted to
view only the value in the 1st row, 5th column, you’d type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#test_matrix(row,column)
test_matrix[1,5]

## [1] 7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In addition to using positive integers to indicate the exact location of
the subset of data we want to extract, you can also use other notation
to indicate subsets of data that you want to include or exclude. You can
use: negative integers (to exclude data at a specific location), zero
(to create empty objects with consistent format), blank spaces (to
select the entire row/column), logical values (to select the data
associated with TRUE values), or names (to select specific columns or
rows by their names). Try to understand how each type of notation works!&lt;/p&gt;
&lt;p&gt;For example, what if you wanted to view all the values in the 5th
column? This literally says, extract all rows but only the 5th column
from the object called test_matrix.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;test_matrix[,5]

## [1]  7  8  9 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What about the 4th row?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;test_matrix[4,]

## [1]  4  8  2  6 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What if we wanted to view the values in the 3rd row, but only the 2nd
and 4th columns?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;test_matrix[3,c(2,4)]

## [1] 7 5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What happens to the matrix if we append a character field? Use the
&lt;code&gt;cbind()&lt;/code&gt; (column bind) command to bind a new column, called
‘countries’. Note that I am not changing the contents of test_matrix.
Can you figure out how to do a row bind (hint: use &lt;code&gt;rbind()&lt;/code&gt;)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;countries &amp;lt;- c(&amp;quot;United States&amp;quot;, &amp;quot;Pakistan&amp;quot;, &amp;quot;Ireland&amp;quot;, &amp;quot;China&amp;quot;)
cbind(test_matrix,countries)

##                            countries      
## [1,] &amp;quot;1&amp;quot; &amp;quot;5&amp;quot; &amp;quot;9&amp;quot;  &amp;quot;3&amp;quot; &amp;quot;7&amp;quot;  &amp;quot;United States&amp;quot;
## [2,] &amp;quot;2&amp;quot; &amp;quot;6&amp;quot; &amp;quot;10&amp;quot; &amp;quot;4&amp;quot; &amp;quot;8&amp;quot;  &amp;quot;Pakistan&amp;quot;     
## [3,] &amp;quot;3&amp;quot; &amp;quot;7&amp;quot; &amp;quot;1&amp;quot;  &amp;quot;5&amp;quot; &amp;quot;9&amp;quot;  &amp;quot;Ireland&amp;quot;      
## [4,] &amp;quot;4&amp;quot; &amp;quot;8&amp;quot; &amp;quot;2&amp;quot;  &amp;quot;6&amp;quot; &amp;quot;10&amp;quot; &amp;quot;China&amp;quot;

#Note that I am not changing/overwriting the contents of test_matrix.  I could, but I&#39;d have to change my code to
#test_matrix &amp;lt;- cbind(test_matrix,countries)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why is everything inside the table now enclosed in quotes? Recall what
we said about matrices only containing one data type. What happens if I
coerce this to a dataframe?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;test_dataframe &amp;lt;- data.frame(test_matrix,countries)
test_dataframe

##   X1 X2 X3 X4 X5     countries
## 1  1  5  9  3  7 United States
## 2  2  6 10  4  8      Pakistan
## 3  3  7  1  5  9       Ireland
## 4  4  8  2  6 10         China

# Have I changed the file type?
class(test_dataframe)

## [1] &amp;quot;data.frame&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Can I rename the column headings?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;names(test_dataframe) &amp;lt;- c(&amp;quot;Val1&amp;quot;, &amp;quot;Val2&amp;quot;, &amp;quot;Val3&amp;quot;, &amp;quot;Val4&amp;quot;, &amp;quot;Val5&amp;quot;, &amp;quot;Countries&amp;quot;)
test_dataframe

##   Val1 Val2 Val3 Val4 Val5     Countries
## 1    1    5    9    3    7 United States
## 2    2    6   10    4    8      Pakistan
## 3    3    7    1    5    9       Ireland
## 4    4    8    2    6   10         China

# Also see the colnames() function
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Can I use the same matrix notation to reference a particular row and
column? Are there other ways to reference a value?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;test_dataframe[3,5]

## [1] 9

test_dataframe[,5]

## [1]  7  8  9 10

test_dataframe$Val5[3]

## [1] 9

test_dataframe$Val5

## [1]  7  8  9 10

test_dataframe[,&amp;quot;Val5&amp;quot;]

## [1]  7  8  9 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use some very simple commands to determine the size of
dataframes or matrices.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nrow(test_dataframe)

## [1] 4

ncol(test_dataframe)

## [1] 6

dim(test_dataframe)

## [1] 4 6
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can delete individual objects to clear your working directory
(&lt;code&gt;rm(dataset)&lt;/code&gt;), or start every script with the following command to
make sure you are starting fresh (this is good programming practice):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#rm(list=ls())
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;functions&#34;&gt;Functions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; functions can be defined as a collection of arguments structured
together for carrying out a definite task. Functions have optional input
and output arguments that return a value. Custom functions can be easily
constructed in &lt;strong&gt;R&lt;/strong&gt;. Most often, however, we will use built-in
functions within base packages or other downloadable packages.&lt;/p&gt;
&lt;p&gt;Most functions have optional arguments or are given default values (in
the function’s help document, under the ‘Usage’ section, the optional
arguments are given a default value following the “=” symbol). When you
don’t specify the optional arguments, they will take the default values.
Functions normally can be called using the following format:
function_name(input_data, argument1, argument2.)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;print(2+2)

## [1] 4

x &amp;lt;- matrix(1:10, 5, 2)
x

##      [,1] [,2]
## [1,]    1    6
## [2,]    2    7
## [3,]    3    8
## [4,]    4    9
## [5,]    5   10

y &amp;lt;- matrix(1:5)
y

##      [,1]
## [1,]    1
## [2,]    2
## [3,]    3
## [4,]    4
## [5,]    5

df.example &amp;lt;- cbind(x, y)
df.example

##      [,1] [,2] [,3]
## [1,]    1    6    1
## [2,]    2    7    2
## [3,]    3    8    3
## [4,]    4    9    4
## [5,]    5   10    5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;?function_name&lt;/em&gt; can load the function help file. Also note that any
functions in non-base packages will require installing and loading that
package.&lt;/p&gt;
&lt;p&gt;Here, for example, we install and load package named “ggplot2” that we
will use for data visualization.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;ggplot2&amp;quot;)
library(ggplot2)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;pre-existing-functions&#34;&gt;Pre-existing Functions&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; also contains many pre-existing functions in the base software.
Numeric functions include &lt;code&gt;sum()&lt;/code&gt;, &lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;sd()&lt;/code&gt;, &lt;code&gt;min()&lt;/code&gt;, &lt;code&gt;max()&lt;/code&gt;,
&lt;code&gt;median()&lt;/code&gt;, &lt;code&gt;range()&lt;/code&gt;, &lt;code&gt;quantile()&lt;/code&gt;, or &lt;code&gt;summary()&lt;/code&gt;. Try a few of these
on the numeric vectors you have created.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sum(x)

## [1] 55

summary(x)

##        V1          V2    
##  Min.   :1   Min.   : 6  
##  1st Qu.:2   1st Qu.: 7  
##  Median :3   Median : 8  
##  Mean   :3   Mean   : 8  
##  3rd Qu.:4   3rd Qu.: 9  
##  Max.   :5   Max.   :10

range(y)

## [1] 1 5
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;calculations--arithmetic-operators&#34;&gt;Calculations &amp;amp; Arithmetic Operators&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; can be used to perform basic calculations and report the results
back to the user.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;4+2

## [1] 6

6*8

## [1] 48

(842-62)/3

## [1] 260
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Exponentiation: ^&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2^3

## [1] 8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Max and Min: max(), min()&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vector_numbers &amp;lt;- c(2, 3, 4, 10)
max(vector_numbers) 

## [1] 10

min(vector_numbers)

## [1] 2
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Can you calculate the square root and then subtract 5 for each element
in vector_number?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;relational-operators&#34;&gt;Relational Operators&lt;/h3&gt;
&lt;p&gt;&amp;lt;,&amp;gt;, =, !=, &amp;gt;=, &amp;lt;=, Evaluate a conditional expression and
return TRUE or FALSE&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;3 &amp;gt; max(c(2,3,4,5))

## [1] FALSE
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;loops&#34;&gt;Loops&lt;/h2&gt;
&lt;p&gt;The for loop is used to iterate over a sequence (numeric vector, list,
or other iterable objects). Loops are very important to perform
opperations and especial building blocks of many advanced models.&lt;/p&gt;
&lt;p&gt;Here is a simple for loop that print numbers 1 to 5. As you can see, i
is the element in which the loop is iterating. It can take a value of 1
to 5, and the loop ends when it reaches the last element of the
sequence.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for (i in 1:5) {
  print(i)
}

## [1] 1
## [1] 2
## [1] 3
## [1] 4
## [1] 5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But the loop can iterate not just on numbers, but also lists.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;my_list &amp;lt;- c(&amp;quot;apple&amp;quot;, &amp;quot;orange&amp;quot;, &amp;quot;banana&amp;quot;)
for (fruit in my_list) {
  print(fruit)
}

## [1] &amp;quot;apple&amp;quot;
## [1] &amp;quot;orange&amp;quot;
## [1] &amp;quot;banana&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can create a vector from which we will add 5 to each element and save
it in a new vector. For this, we first need to create an empty vector
where we will save the new numbers. Note how we use &lt;strong&gt;[]&lt;/strong&gt; to access
the elements in the &lt;strong&gt;i&lt;/strong&gt; positions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vector &amp;lt;- c(2,3,4,5,2) #Data vector
newdata &amp;lt;- NULL #Vector to store output
for (i in 1:length(vector)){
  newdata[i] &amp;lt;- vector[i] + 5
}
newdata

## [1]  7  8  9 10  7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can nest loops. A loop inside a loop. Make sure you
understand dimensions before trying to understand the nested loop.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vector &amp;lt;- c(1,2,3,4,5) #Data vector
newdata &amp;lt;- matrix(NA, 5,5) #Vector to store output
for (i in 1:5) {
  for (j in 1:5) {
    newdata[i,j] &amp;lt;- vector[i] * vector[j]
  }
}
newdata

##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    2    3    4    5
## [2,]    2    4    6    8   10
## [3,]    3    6    9   12   15
## [4,]    4    8   12   16   20
## [5,]    5   10   15   20   25
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;installing-swirl&#34;&gt;Installing SWIRL&lt;/h2&gt;
&lt;p&gt;A good way to learn more about R is to use SWIRL. This is a
user-generated program (also called a &lt;strong&gt;package&lt;/strong&gt; or &lt;strong&gt;library&lt;/strong&gt;) for
learning how to code in &lt;strong&gt;R&lt;/strong&gt;. To access this, you must first install
the package so it is accessible. In the Console window (bottom left),
type the following and press ENTER:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;swirl&amp;quot;)

# Data can also be installed locally if you&#39;ve downloaded the zip file to your hard drive
#install.packages(&amp;quot;yourzip.tar.gz&amp;quot;, repos=NULL)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This may take a little while, but when the stop sign in the upper right
of the console window is gone, you can proceed. For any package you
install in &lt;strong&gt;R&lt;/strong&gt;, you will also need to turn them on before using them.
You can do this with the &lt;code&gt;require()&lt;/code&gt; or &lt;code&gt;library()&lt;/code&gt; functions. Type this
now:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(swirl)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note: You may be prompted to select a “mirror” from which to download
the package. If this is the case, it is recommended that you choose the
mirror that is geographically closest to you.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To install the lesson, you will need to use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install_from_swirl(&amp;quot;R Programming&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Find out more about other courses, and other download options here:
&lt;a href=&#34;https://github.com/swirldev/swirl_courses&#34;&gt;https://github.com/swirldev/swirl_courses&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;swirl-lessons&#34;&gt;SWIRL Lessons&lt;/h3&gt;
&lt;p&gt;There are many lessons within &lt;strong&gt;R&lt;/strong&gt;. Once SWIRL is loaded (below), you
will be given the option of which lessons to complete. Some of the core
lessons can be found in the initial section labeled &lt;strong&gt;R Programming&lt;/strong&gt;
(estimated time to compete required lessons is about 2 hours). We
recommend to start with the following lessons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Basic Building Blocks (10 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Workspace and Files (15 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sequences of Numbers (5 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vectors (8 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Missing Values (5 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Subsetting Vectors (12 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Matrices and Data Frames (13 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Logic (optional)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Functions (30 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;lapply and sapply (optional)&lt;/li&gt;
&lt;li&gt;vapply and tapply (optional)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Looking at Data (5 min)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Simulation (optional)&lt;/li&gt;
&lt;li&gt;Dates and Times (10 min) (optional)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Base Graphics (10 Min)&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;run-swirl&#34;&gt;Run SWIRL&lt;/h3&gt;
&lt;p&gt;Type the following to begin using SWIRL. Also, when restarting your
session later, you’ll need to “turn on” SWIRL each time with either
&lt;code&gt;library(swirl)&lt;/code&gt; or &lt;code&gt;require(swirl)&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;swirl()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Have fun!&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;introduction-to-data-analysis&#34;&gt;Introduction to Data Analysis&lt;/h1&gt;
&lt;p&gt;Now that you’ve learned the basics of &lt;strong&gt;R&lt;/strong&gt; programming, we’ll take
things a step further.This chapter will walk you through a new set of
analyses.&lt;/p&gt;
&lt;p&gt;We’ll be working with the dataset “mtcars” which comes pre-loaded with
&lt;strong&gt;R&lt;/strong&gt;. The goal of this exercise is to test your basic skills in &lt;strong&gt;R&lt;/strong&gt;
programming, specifically in manipulating data and to reiterate some
principles in statistical modelling. This chapter will help as we move
towards our ultimate goal of conducting more advanced analyses on animal
point data.&lt;/p&gt;
&lt;p&gt;You may not be familiar with all the operations you need to execute in
this exercise. Part of the goal with this exercise, however, is for you
to become more familiar with the &lt;em&gt;help&lt;/em&gt; commands in &lt;strong&gt;R&lt;/strong&gt; and with the
internet solutions that exist. Our ultimate goal is to make you aware of
the tools that are available to you so that you can become an effective
problem solver, working independently on data analyses.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;For this tutorial section I followed the book: &lt;a href=&#34;https://www.eco-explore.co.uk/data-analysis-consulting/data-analysis-guidebook/&#34;&gt;Data Analysis with R
Statistical Software - A Guidebook for
Scientists&lt;/a&gt;
This is, in my opinion, one of the best resources out there for an
introduction to data analysis with R.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Whenever you start working with a new script, you should first set a
working directory. If you are working within a &lt;strong&gt;R-Studio&lt;/strong&gt; project, the
working directory will automatically be set by default. This directory
will contain all the data for your analysis and will be where you will
save all the data outputs.&lt;/p&gt;
&lt;p&gt;Remember that you can check the current working directory by typing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;getwd()

## [1] &amp;quot;/Users/ramirocrego/Documents/GitHub/R-Tutorials&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s change the working directory to a location of your choosing.
Create a folder if you don’t have one already, then make sure your
working directory is in that folder. If you already have a folder, just
set the working directory to the folder you want to use.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;setwd(&amp;quot;C:/....&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;data-management-and-data-manipulation&#34;&gt;Data Management and Data Manipulation&lt;/h2&gt;
&lt;h3 id=&#34;exploring-the-data&#34;&gt;Exploring the Data&lt;/h3&gt;
&lt;p&gt;Let’s start investigating a data set to later fit a linear model.&lt;/p&gt;
&lt;p&gt;Load the “mtcars”” data set. This dataset comes with R. We will use this
dataset as it is intuitive to think about it and is a good example on
how to tackle many other datasets.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data(mtcars)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;View the first 10 lines of the data set.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;head(mtcars, 10)

##                    mpg cyl  disp  hp drat    wt  qsec vs am gear
## Mazda RX4         21.0   6 160.0 110 3.90 2.620 16.46  0  1    4
## Mazda RX4 Wag     21.0   6 160.0 110 3.90 2.875 17.02  0  1    4
## Datsun 710        22.8   4 108.0  93 3.85 2.320 18.61  1  1    4
## Hornet 4 Drive    21.4   6 258.0 110 3.08 3.215 19.44  1  0    3
## Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3
## Valiant           18.1   6 225.0 105 2.76 3.460 20.22  1  0    3
## Duster 360        14.3   8 360.0 245 3.21 3.570 15.84  0  0    3
## Merc 240D         24.4   4 146.7  62 3.69 3.190 20.00  1  0    4
## Merc 230          22.8   4 140.8  95 3.92 3.150 22.90  1  0    4
## Merc 280          19.2   6 167.6 123 3.92 3.440 18.30  1  0    4
##                   carb
## Mazda RX4            4
## Mazda RX4 Wag        4
## Datsun 710           1
## Hornet 4 Drive       1
## Hornet Sportabout    2
## Valiant              1
## Duster 360           4
## Merc 240D            2
## Merc 230             2
## Merc 280             4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Assess the overall structure of the data set to get a sense of the
number and type of variables included. When you work with your own data,
you will be familiar with the data structure, but it is always good
practice to examine your data before moving on to any model fitting.
Assure that the data structure of each column of the data frame is
correct and/or what you expect it to be.&lt;/p&gt;
&lt;p&gt;Note, all columns/variables included in this sample dataset are
numeric-type. You can confirm the data type of each column by typing
&lt;strong&gt;is.numeric()&lt;/strong&gt; next to the variable name (e.g.,
&lt;code&gt;is.numeric(mtcars$mpg)&lt;/code&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;str(mtcars)

## &#39;data.frame&#39;:    32 obs. of  11 variables:
##  $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
##  $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
##  $ disp: num  160 160 108 258 360 ...
##  $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
##  $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
##  $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
##  $ qsec: num  16.5 17 18.6 19.4 17 ...
##  $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
##  $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
##  $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
##  $ carb: num  4 4 1 1 2 1 4 2 2 4 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, summarize the data to provide a list of each variable with the
mean, min, and max.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summary(mtcars)

##       mpg             cyl             disp             hp       
##  Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  
##  1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  
##  Median :19.20   Median :6.000   Median :196.3   Median :123.0  
##  Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  
##  3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  
##  Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  
##       drat             wt             qsec             vs        
##  Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  
##  1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  
##  Median :3.695   Median :3.325   Median :17.71   Median :0.0000  
##  Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  
##  3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  
##  Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  
##        am              gear            carb      
##  Min.   :0.0000   Min.   :3.000   Min.   :1.000  
##  1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  
##  Median :0.0000   Median :4.000   Median :2.000  
##  Mean   :0.4062   Mean   :3.688   Mean   :2.812  
##  3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  
##  Max.   :1.0000   Max.   :5.000   Max.   :8.000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;‘Summary’ is a great function to have a quick view at the data. But what
if you want to save the mean, min, or max values of each variable? There
is a family of functions in &lt;strong&gt;R&lt;/strong&gt; that are great for applying functions
to all columns or all rows in a matrix and that return the result as a
vector or list of values. This is the &lt;code&gt;apply&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;apply&lt;/code&gt; function has two main arguments. The MARGIN that is a 1 or a
2, indicating whether you want to operate on rows (1) or columns (2) and
the FUN arguments that tell &lt;strong&gt;R&lt;/strong&gt; what function is to be applied. For
example, to obtain the mean of each variable in the mtcars dataset, we
do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apply(mtcars, 2, mean)

##        mpg        cyl       disp         hp       drat         wt 
##  20.090625   6.187500 230.721875 146.687500   3.596563   3.217250 
##       qsec         vs         am       gear       carb 
##  17.848750   0.437500   0.406250   3.687500   2.812500
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare with the values reported by the &lt;code&gt;summary&lt;/code&gt; function.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTION: Can you calculate the min and max values for each variable?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let’s have a quick look at all our variables together (since they are
all numeric) by looking at scatter plots of each variable combination.
Use the function “pairs” or “plot” on the data set.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plot(mtcars)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-69-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You should be able to see cases where there seems to be a strong
relationship between two variables. “mpg” vs. “wt” is a good example of
this. This is miles per gallon vs. the weight of the car, and this makes
sense, a heavier car should consume more petrol per distance. We should
transform miles to kilometers, because, what kind of measurement is
miles? But in appreciation of all my American friends, we will use
miles, just for this exercise. Is the slope here positive or negative?&lt;/p&gt;
&lt;p&gt;We can plot these two variables against each other to examine the
relationship closer.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plot(mtcars$mpg ~ mtcars$wt)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-70-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You could plot any of the variables in the data frame. Plotting the data
is one of the simplest ways to look and explore the data.&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt; you can customize your plots. We will dedicate a section to
ggplot2. But for now, can you change the ‘x’ and ‘y’ variable names and
add a title to this plot? Use the help file &lt;code&gt;help(plot)&lt;/code&gt; or &lt;code&gt;?plot&lt;/code&gt; to
determine the proper syntax, or simply Google “add tile to plot in R”.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plot(mtcars$mpg ~ mtcars$wt, xlab=&amp;quot;Weight&amp;quot;, ylab=&amp;quot;MPG&amp;quot;, main=&amp;quot;MPG vs Weight&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-71-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Calculate the correlation coefficient between the two variables, then
perform a correlation test to see if they are significantly correlated.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cor(mtcars$mpg, mtcars$wt)

## [1] -0.8676594

cor.test(mtcars$mpg, mtcars$wt)

## 
##  Pearson&#39;s product-moment correlation
## 
## data:  mtcars$mpg and mtcars$wt
## t = -9.559, df = 30, p-value = 1.294e-10
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.9338264 -0.7440872
## sample estimates:
##        cor 
## -0.8676594
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p-value&lt;/em&gt; is very small and the correlation coefficient of
-0.8676594 is very high. We also note that this value is negative,
meaning that as the weight increases, the fuel efficiency decreases.
This makes intuitive sense. We will talk about the difference between
correlation and causation later.&lt;/p&gt;
&lt;p&gt;Let’s practice some data management before we look into these variables
in more detail.&lt;/p&gt;
&lt;p&gt;Create a new data set called “my_mtcars”, excluding the variables “vs”
and “am” using vector notation. Then look at your new data set to make
sure it worked. We don’t necessarily need to remove these variables to
continue the analysis. We are simply doing this so that you get more
familiar with manipulating data frames.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;head(mtcars)

##                    mpg cyl disp  hp drat    wt  qsec vs am gear
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3
##                   carb
## Mazda RX4            4
## Mazda RX4 Wag        4
## Datsun 710           1
## Hornet 4 Drive       1
## Hornet Sportabout    2
## Valiant              1

my_mtcars &amp;lt;- mtcars[, -c(8,9)] #Remove columns 8 and 9
head(my_mtcars, 10) 

##                    mpg cyl  disp  hp drat    wt  qsec gear carb
## Mazda RX4         21.0   6 160.0 110 3.90 2.620 16.46    4    4
## Mazda RX4 Wag     21.0   6 160.0 110 3.90 2.875 17.02    4    4
## Datsun 710        22.8   4 108.0  93 3.85 2.320 18.61    4    1
## Hornet 4 Drive    21.4   6 258.0 110 3.08 3.215 19.44    3    1
## Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02    3    2
## Valiant           18.1   6 225.0 105 2.76 3.460 20.22    3    1
## Duster 360        14.3   8 360.0 245 3.21 3.570 15.84    3    4
## Merc 240D         24.4   4 146.7  62 3.69 3.190 20.00    4    2
## Merc 230          22.8   4 140.8  95 3.92 3.150 22.90    4    2
## Merc 280          19.2   6 167.6 123 3.92 3.440 18.30    4    4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, keeping the same name for your data set, exclude the “gear” and
“carb” columns without using vector notation. Instead use the “subset”
function. Check out the help (&lt;code&gt;?subset&lt;/code&gt;) for this function to figure out
how to exclude columns by name.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;my_mtcars &amp;lt;- subset(my_mtcars, select = -c(gear, carb))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the initial data of my_mycars with 9 variables no longer
exists, because my syntax states to save the modified 7 variable data
with the original name.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTION: How could you do this without overwriting the original data?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You should now have a data set called my_mtcars that has 32
observations of 7 variables. Check this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;str(my_mtcars)

## &#39;data.frame&#39;:    32 obs. of  7 variables:
##  $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
##  $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
##  $ disp: num  160 160 108 258 360 ...
##  $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
##  $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
##  $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
##  $ qsec: num  16.5 17 18.6 19.4 17 ...

dim(my_mtcars)

## [1] 32  7
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTION: What does &lt;code&gt;## [1] 32 7&lt;/code&gt; tells us? Hint, recall vector
notation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Another way of checking the number of rows and columns is using &lt;code&gt;nrow()&lt;/code&gt;
and &lt;code&gt;ncol()&lt;/code&gt; functions.&lt;/p&gt;
&lt;p&gt;The variable “cyl” represents the number of cylinders in the car engine.
You’ll see this is classified as a numeric variable. However, we aren’t
necessarily interested in this as an actual number. For us, the number
of cylinders is more useful as a grouping mechanisms to serve as a
factor, or categorical variable. Let’s use the &lt;code&gt;as.factor&lt;/code&gt; function to
convert it, keeping the same variable name. Then check what the class of
the variable is, to confirm the conversion worked.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;my_mtcars$cyl &amp;lt;- as.factor(my_mtcars$cyl)
class(my_mtcars$cyl)

## [1] &amp;quot;factor&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating a categorical factor variable will enable us to generate
summary statistics and plot data by groups.&lt;/p&gt;
&lt;p&gt;We can now use this factor variable to group different operations.
&lt;code&gt;tapply&lt;/code&gt; is a great function to use for grouped operations. Check the
help for &lt;code&gt;?tapply&lt;/code&gt; and try to calculate the mean of “mpg” for each
factor of the “cyl” variable.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tapply(my_mtcars$mpg, my_mtcars$cyl, mean)

##        4        6        8 
## 26.66364 19.74286 15.10000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s create box plots of our two variables of interest (mpg, wt) to
visualize their distribution. First, change your graphic parameter to
show two graphs side by side.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Question: How do you think you’d specify the title of each box plot?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;par(mfrow=c(1, 2))
boxplot(my_mtcars$mpg, main = &amp;quot;mpg&amp;quot;)
boxplot(my_mtcars$wt, main = &amp;quot;weight&amp;quot;)  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-78-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can see that two points are potential outliers in the plot for&lt;code&gt;wt&lt;/code&gt;.
The plot gives you a tool to make a decision whether to remove the data
points. Here we will keep them.&lt;/p&gt;
&lt;p&gt;Since &lt;code&gt;cyl&lt;/code&gt; is a categorical variable, we can also visualize the
distribution of &lt;code&gt;mpg&lt;/code&gt; and &lt;code&gt;wt&lt;/code&gt; across different cylinder classes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;par(mfrow=c(1, 2))
boxplot(my_mtcars$mpg ~ my_mtcars$cyl, main = &amp;quot;mpg&amp;quot;)
boxplot(my_mtcars$wt ~ my_mtcars$cyl, main = &amp;quot;weight&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-79-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTION: How do you modify the label for x axis and y axis?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Before we move forward, let’s exclude these two observations by using a
logical expression that removes the points (rows in the dataframe) in
the data set where weight is greater than 5.3 tons. There are a few
different ways to do this, as is the case with most things in &lt;strong&gt;R&lt;/strong&gt;.
Let’s use the &lt;code&gt;subset&lt;/code&gt; function again.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;my_mtcars &amp;lt;- subset(my_mtcars, wt &amp;lt;= 5.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should now have a data set with 30 observations of 7 variables.&lt;/p&gt;
&lt;p&gt;Note that removing data points from an analysis is not a good
statistical practice and when done, it should be justified. But here,
the goal is to use different functions on how we can work with data
frames.&lt;/p&gt;
&lt;h2 id=&#34;data-table-manipulation-with-dplyr&#34;&gt;Data Table Manipulation with Dplyr&lt;/h2&gt;
&lt;p&gt;The most basic R skills is to query and manipulate various data tables.
Table manipulation is also something that is almost always required,
regardless of what you decide to apply R for. For beginners,
familiarizing and reinforcing table manipulation skills to meet
different needs is a great way of improving R skills. If you wish to
become really good at R, but don’t know where to start, start with
tables!&lt;/p&gt;
&lt;p&gt;The base R functions that come with the default R installation have the
capacity for almost all the table manipulation you will need (e.g.,
&lt;code&gt;split(), subset(), apply(), sapply(), lapply(), tapply(), aggregate()&lt;/code&gt;).
However, sometimes their syntax are less user-friendly and intuitive
than some of the special packages built for table manipulation purposes.
So, here we are introducing a few of the most useful table manipulation
functions within &lt;code&gt;dplyr&lt;/code&gt; package. This is a package I use a lot.&lt;/p&gt;
&lt;p&gt;Note that you will have to use &lt;code&gt;install.packages()&lt;/code&gt; and &lt;code&gt;library()&lt;/code&gt;
function to download and activate the &lt;code&gt;dplyr&lt;/code&gt; before using it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#install.packages(&amp;quot;dplyr&amp;quot;)
library(dplyr)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we will see how different functions of this package work.&lt;/p&gt;
&lt;h3 id=&#34;select&#34;&gt;&lt;code&gt;select()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;We can use &lt;code&gt;select()&lt;/code&gt; to select column(s) that meet an specific pattern:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select(mtcars, mpg) # select column called mpg (miles per galon)

##                      mpg
## Mazda RX4           21.0
## Mazda RX4 Wag       21.0
## Datsun 710          22.8
## Hornet 4 Drive      21.4
## Hornet Sportabout   18.7
## Valiant             18.1
## Duster 360          14.3
## Merc 240D           24.4
## Merc 230            22.8
## Merc 280            19.2
## Merc 280C           17.8
## Merc 450SE          16.4
## Merc 450SL          17.3
## Merc 450SLC         15.2
## Cadillac Fleetwood  10.4
## Lincoln Continental 10.4
## Chrysler Imperial   14.7
## Fiat 128            32.4
## Honda Civic         30.4
## Toyota Corolla      33.9
## Toyota Corona       21.5
## Dodge Challenger    15.5
## AMC Javelin         15.2
## Camaro Z28          13.3
## Pontiac Firebird    19.2
## Fiat X1-9           27.3
## Porsche 914-2       26.0
## Lotus Europa        30.4
## Ford Pantera L      15.8
## Ferrari Dino        19.7
## Maserati Bora       15.0
## Volvo 142E          21.4

select(mtcars, -mpg) # select all columns in the data except mpg column

##                     cyl  disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4             6 160.0 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag         6 160.0 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710            4 108.0  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive        6 258.0 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout     8 360.0 175 3.15 3.440 17.02  0  0    3    2
## Valiant               6 225.0 105 2.76 3.460 20.22  1  0    3    1
## Duster 360            8 360.0 245 3.21 3.570 15.84  0  0    3    4
## Merc 240D             4 146.7  62 3.69 3.190 20.00  1  0    4    2
## Merc 230              4 140.8  95 3.92 3.150 22.90  1  0    4    2
## Merc 280              6 167.6 123 3.92 3.440 18.30  1  0    4    4
## Merc 280C             6 167.6 123 3.92 3.440 18.90  1  0    4    4
## Merc 450SE            8 275.8 180 3.07 4.070 17.40  0  0    3    3
## Merc 450SL            8 275.8 180 3.07 3.730 17.60  0  0    3    3
## Merc 450SLC           8 275.8 180 3.07 3.780 18.00  0  0    3    3
## Cadillac Fleetwood    8 472.0 205 2.93 5.250 17.98  0  0    3    4
## Lincoln Continental   8 460.0 215 3.00 5.424 17.82  0  0    3    4
## Chrysler Imperial     8 440.0 230 3.23 5.345 17.42  0  0    3    4
## Fiat 128              4  78.7  66 4.08 2.200 19.47  1  1    4    1
## Honda Civic           4  75.7  52 4.93 1.615 18.52  1  1    4    2
## Toyota Corolla        4  71.1  65 4.22 1.835 19.90  1  1    4    1
## Toyota Corona         4 120.1  97 3.70 2.465 20.01  1  0    3    1
## Dodge Challenger      8 318.0 150 2.76 3.520 16.87  0  0    3    2
## AMC Javelin           8 304.0 150 3.15 3.435 17.30  0  0    3    2
## Camaro Z28            8 350.0 245 3.73 3.840 15.41  0  0    3    4
## Pontiac Firebird      8 400.0 175 3.08 3.845 17.05  0  0    3    2
## Fiat X1-9             4  79.0  66 4.08 1.935 18.90  1  1    4    1
## Porsche 914-2         4 120.3  91 4.43 2.140 16.70  0  1    5    2
## Lotus Europa          4  95.1 113 3.77 1.513 16.90  1  1    5    2
## Ford Pantera L        8 351.0 264 4.22 3.170 14.50  0  1    5    4
## Ferrari Dino          6 145.0 175 3.62 2.770 15.50  0  1    5    6
## Maserati Bora         8 301.0 335 3.54 3.570 14.60  0  1    5    8
## Volvo 142E            4 121.0 109 4.11 2.780 18.60  1  1    4    2

select(mtcars, hp:vs) # select a continuous block columns starting from hp column and end on vs column 

##                      hp drat    wt  qsec vs
## Mazda RX4           110 3.90 2.620 16.46  0
## Mazda RX4 Wag       110 3.90 2.875 17.02  0
## Datsun 710           93 3.85 2.320 18.61  1
## Hornet 4 Drive      110 3.08 3.215 19.44  1
## Hornet Sportabout   175 3.15 3.440 17.02  0
## Valiant             105 2.76 3.460 20.22  1
## Duster 360          245 3.21 3.570 15.84  0
## Merc 240D            62 3.69 3.190 20.00  1
## Merc 230             95 3.92 3.150 22.90  1
## Merc 280            123 3.92 3.440 18.30  1
## Merc 280C           123 3.92 3.440 18.90  1
## Merc 450SE          180 3.07 4.070 17.40  0
## Merc 450SL          180 3.07 3.730 17.60  0
## Merc 450SLC         180 3.07 3.780 18.00  0
## Cadillac Fleetwood  205 2.93 5.250 17.98  0
## Lincoln Continental 215 3.00 5.424 17.82  0
## Chrysler Imperial   230 3.23 5.345 17.42  0
## Fiat 128             66 4.08 2.200 19.47  1
## Honda Civic          52 4.93 1.615 18.52  1
## Toyota Corolla       65 4.22 1.835 19.90  1
## Toyota Corona        97 3.70 2.465 20.01  1
## Dodge Challenger    150 2.76 3.520 16.87  0
## AMC Javelin         150 3.15 3.435 17.30  0
## Camaro Z28          245 3.73 3.840 15.41  0
## Pontiac Firebird    175 3.08 3.845 17.05  0
## Fiat X1-9            66 4.08 1.935 18.90  1
## Porsche 914-2        91 4.43 2.140 16.70  0
## Lotus Europa        113 3.77 1.513 16.90  1
## Ford Pantera L      264 4.22 3.170 14.50  0
## Ferrari Dino        175 3.62 2.770 15.50  0
## Maserati Bora       335 3.54 3.570 14.60  0
## Volvo 142E          109 4.11 2.780 18.60  1

select(mtcars, starts_with(&amp;quot;c&amp;quot;)) # select all columns that start with &amp;quot;c&amp;quot; in their column names

##                     cyl carb
## Mazda RX4             6    4
## Mazda RX4 Wag         6    4
## Datsun 710            4    1
## Hornet 4 Drive        6    1
## Hornet Sportabout     8    2
## Valiant               6    1
## Duster 360            8    4
## Merc 240D             4    2
## Merc 230              4    2
## Merc 280              6    4
## Merc 280C             6    4
## Merc 450SE            8    3
## Merc 450SL            8    3
## Merc 450SLC           8    3
## Cadillac Fleetwood    8    4
## Lincoln Continental   8    4
## Chrysler Imperial     8    4
## Fiat 128              4    1
## Honda Civic           4    2
## Toyota Corolla        4    1
## Toyota Corona         4    1
## Dodge Challenger      8    2
## AMC Javelin           8    2
## Camaro Z28            8    4
## Pontiac Firebird      8    2
## Fiat X1-9             4    1
## Porsche 914-2         4    2
## Lotus Europa          4    2
## Ford Pantera L        8    4
## Ferrari Dino          6    6
## Maserati Bora         8    8
## Volvo 142E            4    2
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;starts_with&lt;/code&gt; argument is very convenient because it allow you to
select multiple columns that start with the same text. A few similar
arguments are available to define other naming patterns.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ends_with()&lt;/code&gt;= Select columns that end with a character string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;contains()&lt;/code&gt;= Select columns that contain a character string.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;matches()&lt;/code&gt;= Select columns that match a regular expression.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;one_of()&lt;/code&gt;= Select columns names that are from a group of names.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Question: How do you select or exclude two columns: mpg and cyl?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;filter&#34;&gt;&lt;code&gt;filter()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Filter/select row(s) of data based on specific requirement of column(s)
values:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;filter(mtcars, cyl %in% c(4,6)) # select cars with 4 or 6 cylinders

##                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## Valiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
## Merc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
## Merc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
## Merc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
## Merc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
## Fiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
## Honda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
## Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
## Toyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
## Fiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
## Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
## Lotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
## Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
## Volvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2

filter (mtcars, mpg&amp;gt;20) # select rows that have mpg &amp;gt; 20

##                 mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## Merc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
## Merc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
## Fiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
## Honda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
## Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
## Toyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
## Fiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
## Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
## Lotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
## Volvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2

filter(mtcars, mpg&amp;gt;20 &amp;amp; cyl == 6) # select rows that have mpg&amp;gt;20 AND cyl == 6

##                 mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4      21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag  21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1

filter(mtcars, mpg&amp;gt;20 | hp &amp;gt; 100) # select rows that have mpg&amp;gt;20 OR hp &amp;gt; 100

##                      mpg cyl  disp  hp drat    wt  qsec vs am gear
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4
##                     carb
## Mazda RX4              4
## Mazda RX4 Wag          4
## Datsun 710             1
## Hornet 4 Drive         1
## Hornet Sportabout      2
## Valiant                1
## Duster 360             4
## Merc 240D              2
## Merc 230               2
## Merc 280               4
## Merc 280C              4
## Merc 450SE             3
## Merc 450SL             3
## Merc 450SLC            3
## Cadillac Fleetwood     4
## Lincoln Continental    4
## Chrysler Imperial      4
## Fiat 128               1
## Honda Civic            2
## Toyota Corolla         1
## Toyota Corona          1
## Dodge Challenger       2
## AMC Javelin            2
## Camaro Z28             4
## Pontiac Firebird       2
## Fiat X1-9              1
## Porsche 914-2          2
## Lotus Europa           2
## Ford Pantera L         4
## Ferrari Dino           6
## Maserati Bora          8
## Volvo 142E             2
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Question 1: How do you select rows with 6 and 8 cylinders knowing that
cyl is a factor?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;pipe-operator&#34;&gt;pipe operator&lt;/h3&gt;
&lt;p&gt;The pipe operator allows you to pipe the output from one function to the
input of the next function. Instead of nesting functions (reading from
the inside to the outside), the idea of of piping is to read the
functions from left to right. It can also help you avoid creating and
saving a lot of intermediate variables that you don’t need to keep. The
old operator for pipes was &lt;code&gt;%&amp;gt;%&lt;/code&gt;, but now a new version has been
introduced, &lt;code&gt;|&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# old operator
pipe_result&amp;lt;- mtcars %&amp;gt;%
  select(mpg, cyl) %&amp;gt;%
  head()
pipe_result

##                    mpg cyl
## Mazda RX4         21.0   6
## Mazda RX4 Wag     21.0   6
## Datsun 710        22.8   4
## Hornet 4 Drive    21.4   6
## Hornet Sportabout 18.7   8
## Valiant           18.1   6

# new operator
pipe_result&amp;lt;- mtcars |&amp;gt;
  select(mpg, cyl) |&amp;gt;
  head()
pipe_result

##                    mpg cyl
## Mazda RX4         21.0   6
## Mazda RX4 Wag     21.0   6
## Datsun 710        22.8   4
## Hornet 4 Drive    21.4   6
## Hornet Sportabout 18.7   8
## Valiant           18.1   6
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;arrange&#34;&gt;&lt;code&gt;arrange()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This function arranges or re-orders rows based on their value, the rows
are arranged by default in ascending order&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;order_data1&amp;lt;- mtcars %&amp;gt;% 
    arrange(mpg) 
order_data1

##                      mpg cyl  disp  hp drat    wt  qsec vs am gear
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4
##                     carb
## Cadillac Fleetwood     4
## Lincoln Continental    4
## Camaro Z28             4
## Duster 360             4
## Chrysler Imperial      4
## Maserati Bora          8
## Merc 450SLC            3
## AMC Javelin            2
## Dodge Challenger       2
## Ford Pantera L         4
## Merc 450SE             3
## Merc 450SL             3
## Merc 280C              4
## Valiant                1
## Hornet Sportabout      2
## Merc 280               4
## Pontiac Firebird       2
## Ferrari Dino           6
## Mazda RX4              4
## Mazda RX4 Wag          4
## Hornet 4 Drive         1
## Volvo 142E             2
## Toyota Corona          1
## Datsun 710             1
## Merc 230               2
## Merc 240D              2
## Porsche 914-2          2
## Fiat X1-9              1
## Honda Civic            2
## Lotus Europa           2
## Fiat 128               1
## Toyota Corolla         1

order_data2&amp;lt;- mtcars %&amp;gt;%
    arrange(cyl, mpg)
order_data2

##                      mpg cyl  disp  hp drat    wt  qsec vs am gear
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3
##                     carb
## Volvo 142E             2
## Toyota Corona          1
## Datsun 710             1
## Merc 230               2
## Merc 240D              2
## Porsche 914-2          2
## Fiat X1-9              1
## Honda Civic            2
## Lotus Europa           2
## Fiat 128               1
## Toyota Corolla         1
## Merc 280C              4
## Valiant                1
## Merc 280               4
## Ferrari Dino           6
## Mazda RX4              4
## Mazda RX4 Wag          4
## Hornet 4 Drive         1
## Cadillac Fleetwood     4
## Lincoln Continental    4
## Camaro Z28             4
## Duster 360             4
## Chrysler Imperial      4
## Maserati Bora          8
## Merc 450SLC            3
## AMC Javelin            2
## Dodge Challenger       2
## Ford Pantera L         4
## Merc 450SE             3
## Merc 450SL             3
## Hornet Sportabout      2
## Pontiac Firebird       2

# Now we learn pipe operator, can you understand what order_data1 and order_data2 are producing? 
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Question: Can you arrange the table first by wt and then by hp in
decending order?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;mutate&#34;&gt;&lt;code&gt;mutate()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;mutate()&lt;/code&gt; command creates new column(s) and define their values.
For instance, we can create a new column with random numbers between 0
and 100 using a uniform distribution.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;new_col&amp;lt;- mtcars %&amp;gt;%
    mutate(new_col = runif(n = nrow(mtcars), min = 0, max = 100)) # note the use of nrow to get the exact number of random numbers as there are rows in the dataframe.
new_col

##                      mpg cyl  disp  hp drat    wt  qsec vs am gear
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4
##                     carb   new_col
## Mazda RX4              4 45.325167
## Mazda RX4 Wag          4 71.595137
## Datsun 710             1 22.307502
## Hornet 4 Drive         1 76.575520
## Hornet Sportabout      2 64.404899
## Valiant                1 40.328984
## Duster 360             4 47.745387
## Merc 240D              2 31.470114
## Merc 230               2 13.385267
## Merc 280               4 94.321241
## Merc 280C              4 90.905093
## Merc 450SE             3 61.463729
## Merc 450SL             3 54.021893
## Merc 450SLC            3 89.290931
## Cadillac Fleetwood     4 34.698049
## Lincoln Continental    4 80.192777
## Chrysler Imperial      4 86.516655
## Fiat 128               1 80.952402
## Honda Civic            2 28.039848
## Toyota Corolla         1  9.075513
## Toyota Corona          1 47.913452
## Dodge Challenger       2 74.917562
## AMC Javelin            2 69.675243
## Camaro Z28             4 68.928527
## Pontiac Firebird       2 98.925896
## Fiat X1-9              1 71.136517
## Porsche 914-2          2 32.845551
## Lotus Europa           2 48.634291
## Ford Pantera L         4 50.484564
## Ferrari Dino           6  9.983938
## Maserati Bora          8 14.290994
## Volvo 142E             2 70.938767

new_col2 &amp;lt;- mtcars %&amp;gt;%
    mutate(new_col = runif(n = nrow(mtcars), min = 0, max = 100),  wt_kg = wt * 1000) # you can create multiple columns at once. Lets transform the weight from tones to kg
new_col2

##                      mpg cyl  disp  hp drat    wt  qsec vs am gear
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4
##                     carb   new_col wt_kg
## Mazda RX4              4 21.726533  2620
## Mazda RX4 Wag          4 76.479457  2875
## Datsun 710             1 28.338550  2320
## Hornet 4 Drive         1 44.659981  3215
## Hornet Sportabout      2 97.065341  3440
## Valiant                1 21.809142  3460
## Duster 360             4 19.656055  3570
## Merc 240D              2 30.474729  3190
## Merc 230               2 72.416235  3150
## Merc 280               4 81.880788  3440
## Merc 280C              4  9.650029  3440
## Merc 450SE             3 26.996484  4070
## Merc 450SL             3  3.633103  3730
## Merc 450SLC            3 25.531053  3780
## Cadillac Fleetwood     4 70.150704  5250
## Lincoln Continental    4 18.229201  5424
## Chrysler Imperial      4 13.783610  5345
## Fiat 128               1 99.729064  2200
## Honda Civic            2 10.482039  1615
## Toyota Corolla         1 44.710859  1835
## Toyota Corona          1 82.108444  2465
## Dodge Challenger       2 33.709436  3520
## AMC Javelin            2 31.310435  3435
## Camaro Z28             4 93.793183  3840
## Pontiac Firebird       2 59.477393  3845
## Fiat X1-9              1 59.247134  1935
## Porsche 914-2          2 41.332330  2140
## Lotus Europa           2 26.183015  1513
## Ford Pantera L         4 61.933894  3170
## Ferrari Dino           6 52.228334  2770
## Maserati Bora          8 57.030247  3570
## Volvo 142E             2 33.710105  2780
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Can you create a new column call zero and give it a value of 0 ?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;summarise&#34;&gt;&lt;code&gt;summarise()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This function calculates a summary statistics among all rows or rows
within certain grouping, often used in combination with &lt;code&gt;group_by()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sum_table &amp;lt;- mtcars %&amp;gt;% 
summarise(mean(wt))
sum_table

##   mean(wt)
## 1  3.21725

sum_table2 &amp;lt;- mtcars%&amp;gt;% 
summarise(avg_wt= mean(wt), min_wt= min(wt))
sum_table2

##    avg_wt min_wt
## 1 3.21725  1.513
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;group_by&#34;&gt;&lt;code&gt;group_by()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This is a great function. &lt;code&gt;group_by()&lt;/code&gt; divides data rows into groups
based on grouping column(s) provided, often used in combination with
other functions which define what you do with them after placing them in
groups. When &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;summarise()&lt;/code&gt; are used together, you are
essentially telling R to separate rows into different groups, and for
each groups you use &lt;code&gt;summarise()&lt;/code&gt; to generate a series of summary
statistics that characterize the column values.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;group_summary &amp;lt;- mtcars |&amp;gt;
  group_by(cyl) |&amp;gt;
  summarise(avg_wt= mean(wt), min_wt= min(wt))
group_summary

## # A tibble: 3 × 3
##     cyl avg_wt min_wt
##   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     4   2.29   1.51
## 2     6   3.12   2.62
## 3     8   4.00   3.17
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also create groups by the combination of two or multiple columns&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;group_summary2&amp;lt;- mtcars |&amp;gt;
  group_by(cyl, gear) |&amp;gt;
  summarise(avg_wt= mean(wt), min_wt= min(wt))

## `summarise()` has grouped output by &#39;cyl&#39;. You can override using
## the `.groups` argument.

group_summary2

## # A tibble: 8 × 4
## # Groups:   cyl [3]
##     cyl  gear avg_wt min_wt
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     4     3   2.46   2.46
## 2     4     4   2.38   1.62
## 3     4     5   1.83   1.51
## 4     6     3   3.34   3.22
## 5     6     4   3.09   2.62
## 6     6     5   2.77   2.77
## 7     8     3   4.10   3.44
## 8     8     5   3.37   3.17
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;join-table&#34;&gt;Join table&lt;/h3&gt;
&lt;p&gt;Let’s read two other tables that are available in the package ‘dplyr’&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data(band_members)
band_members

## # A tibble: 3 × 2
##   name  band   
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  
## 1 Mick  Stones 
## 2 John  Beatles
## 3 Paul  Beatles

data(band_instruments)
band_instruments

## # A tibble: 3 × 2
##   name  plays 
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 John  guitar
## 2 Paul  bass  
## 3 Keith guitar
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;left_join()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Returns all records from the left table, and the matched (matched by
shared ID columns) records from the right table. The result is NULL from
the right side, if there is no match.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;left_join(band_members, band_instruments, by = c(&amp;quot;name&amp;quot;= &amp;quot;name&amp;quot;))

## # A tibble: 3 × 3
##   name  band    plays 
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
## 1 Mick  Stones  &amp;lt;NA&amp;gt;  
## 2 John  Beatles guitar
## 3 Paul  Beatles bass
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;full_join()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Return all records in both tables.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;full_join(band_members, band_instruments, by = c(&amp;quot;name&amp;quot;= &amp;quot;name&amp;quot;))

## # A tibble: 4 × 3
##   name  band    plays 
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
## 1 Mick  Stones  &amp;lt;NA&amp;gt;  
## 2 John  Beatles guitar
## 3 Paul  Beatles bass  
## 4 Keith &amp;lt;NA&amp;gt;    guitar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other than &lt;code&gt;left_join()&lt;/code&gt; and &lt;code&gt;full_join()&lt;/code&gt; there are a few other join
functions that would join table differently. Sometimes you will find
them useful for a specific table you want to make, but in general, you
can reply on &lt;code&gt;left_join()&lt;/code&gt; for most of the job.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;right_join()&lt;/code&gt;: similar to left join, it keeps all records from the
right table instead.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;inner_join()&lt;/code&gt;: return only the matched records from both tables.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion-on-data-management&#34;&gt;Conclusion on data management&lt;/h3&gt;
&lt;p&gt;This has been a glimpse to what can be done in R to work with tabular
data. There are plenty other packages that in time you will learn by
Googling and learning from other people, but for now, all the functions
we covered are a very good set of tools to do most of what you will
need.&lt;/p&gt;
&lt;h2 id=&#34;statistical-modelling&#34;&gt;Statistical Modelling&lt;/h2&gt;
&lt;p&gt;Let’s move on into data analysis.&lt;/p&gt;
&lt;h3 id=&#34;general-principles&#34;&gt;General Principles&lt;/h3&gt;
&lt;p&gt;When building an statistical model, you need to specify a &lt;strong&gt;dependent
variable&lt;/strong&gt; (what you are trying to explain) and one or more
&lt;strong&gt;independent variables&lt;/strong&gt; (the variables that you are using to explain
the dependent variable).&lt;/p&gt;
&lt;p&gt;Thus, to build a model you will first need to identify the dependent and
independent variables which come from the research question. Once you
have identified the variables, you need to decide what kind of model
structure is appropriate for the data set at hand. For this reason,
knowing models and model structures can help you design the data
collection process as you have a good idea of what type of data you need
for a specific model.&lt;/p&gt;
&lt;p&gt;Running models can be easy, but before you can make interpretations from
the model, you need to check that the assumptions of the model are valid
&lt;strong&gt;(model validation)&lt;/strong&gt;, decide what is the best model structure &lt;strong&gt;(model
selection)&lt;/strong&gt; and then, finally, &lt;strong&gt;interpret the parameters of the model
and/or make predictions.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The general structure for defining any model in &lt;strong&gt;R&lt;/strong&gt; is:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;model.type(dependent.variable ~ independent.variable1 +
independent.variable2, data = dataframe)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Note that in the model equation you do not have to specify the
intercept. We have assumed in this example that there are 2 different
independent variables in the example provided (independent.variable1 and
independent.variable2), but the model could contain any number of
independent variables.&lt;/p&gt;
&lt;h3 id=&#34;regression-vs-classification&#34;&gt;Regression vs Classification&lt;/h3&gt;
&lt;p&gt;The dependent variable can either be continuous or categorical data. We
refer to these separate parameterizations as a regression model or a
classification model, respectively. Most of the models we demonstrate
here are regression models, but the structure to build classification
models in &lt;strong&gt;R&lt;/strong&gt; are almost identical. In most cases, the data type of
the dependent variable determines whether the model is a regression
(non-categorical numeric-type dependent variable) or classification
(categorical factor-type dependent variable). You can use functions such
as &lt;code&gt;as.factor()&lt;/code&gt; and &lt;code&gt;as.numeric()&lt;/code&gt; to convert different data types of
data to a factor or numeric variable. Note, just because a data set
contains numbers, does &lt;strong&gt;NOT&lt;/strong&gt; necessarily mean the numbers are
numeric-type. Numbers can be used as symbols to differentiate categories
as well. It is always a good practice to confirm the data type of the
dependent and independent variables that you are inputing into the
model.&lt;/p&gt;
&lt;h2 id=&#34;linear-regression&#34;&gt;Linear Regression&lt;/h2&gt;
&lt;p&gt;We will start with a simple linear regression analysis.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTION: What is the difference between correlation and regression?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;model-design-and-model-fit&#34;&gt;Model design and model fit&lt;/h3&gt;
&lt;p&gt;Model design involves deciding &lt;strong&gt;what we are trying to explain&lt;/strong&gt; (i.e.,
the dependent variable) and &lt;strong&gt;what we are going to use to explain it&lt;/strong&gt;
(i.e., the independent variables). These are questions that are informed
by the researcher.&lt;/p&gt;
&lt;p&gt;Then, we need to decide &lt;strong&gt;what kind of model structure&lt;/strong&gt; is appropriate
to the data set. In our case, we will start with a simple linear
regression model. Later in the course, however, we will investigate more
complex model structures.&lt;/p&gt;
&lt;p&gt;Run a basic linear regression model, attempting to predict/explain the
fuel efficiency of a car (mpg) based on its weight. Finally, assign the
model output “lm1”. Remember to specify the &lt;code&gt;my_mtcars&lt;/code&gt; data set in the
model so the &lt;strong&gt;R&lt;/strong&gt; understands that the name of dependent and
independent variables are columns in that specific dataframe.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lm1 &amp;lt;- lm(mpg ~ wt, data = my_mtcars)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;investigate-your-model&#34;&gt;Investigate your model&lt;/h3&gt;
&lt;p&gt;Once you have fit the model, you can use the summary function to
investigate the beta coefficient, SE, and intercept values.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summary(lm1)

## 
## Call:
## lm(formula = mpg ~ wt, data = my_mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.1820 -2.4603 -0.4526  1.5046  6.3191 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)   39.913      2.002  19.936  &amp;lt; 2e-16 ***
## wt            -6.287      0.630  -9.979 1.01e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.793 on 28 degrees of freedom
## Multiple R-squared:  0.7805, Adjusted R-squared:  0.7727 
## F-statistic: 99.59 on 1 and 28 DF,  p-value: 1.007e-10
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;model-validation---checking-the-assumptions-of-your-model&#34;&gt;Model validation - Checking the assumptions of your model&lt;/h3&gt;
&lt;p&gt;IMPORTANT: Before you can trust your model, you need to examine whether
the assumptions on which the model is based are actually valid. &lt;strong&gt;If the
assumptions are not satisfied, then your model will be unreliable&lt;/strong&gt;, at
least to some extent!&lt;/p&gt;
&lt;p&gt;If you apply the function &lt;strong&gt;plot&lt;/strong&gt; to the model, &lt;strong&gt;R&lt;/strong&gt; will provide a
series of plots that will help you to inspect model assumptions. Click
enter to get all the plots.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plot(lm1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-95-1.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-95-2.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-95-3.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-95-4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Assumption 1&lt;/strong&gt;: The residuals are normally distributed&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Check the Q-Q (quantile-quantile) plot. A perfect normal distribution is
represented by a straight line. Your residuals should be close to a
straight line.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Assumption 2&lt;/strong&gt;: The variances of the residuals are homogeneous
(homoscedasticity)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The variability of the residuals should be uniform across the range of
fitted values of the dependent variable. In the plot of &lt;strong&gt;residuals vs
fitted values of y&lt;/strong&gt; and &lt;strong&gt;standardized residuals vs. fitted values&lt;/strong&gt;
there should be a “scatter” of dots across the graphs, with no
discernible pattern. Points should be randomly distributed. If you have
a scatter of points on one side of the graph, your data may NOT be
homogeneous.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Assumption 3&lt;/strong&gt;: The independent variables are independent of each
other (no collinearity)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are different ways you can address this before you fit your model.
For instance, you can estimate the correlation of each pair of
covariates and discard variables or exclude them from analysis if they
highly correlated (positively or negatively). We will examine this later
in the course when dealing with more complex models.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Assumption 4&lt;/strong&gt;: The data set does not contain serial
auto-correlation&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Serial autocorrelation is when there is significant correlation between
successive data points in the data set. Spatial data or time-series data
tend to be autocorrelated. There are different ways to deal with
autocorrelation, such as using mixed-effect models.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Assumption 5&lt;/strong&gt;: The model is not biased by unduly influential
observations.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can check this by looking at the plot of standardized residuals vs
leverage and “Cook’s Distance.”&lt;/p&gt;
&lt;p&gt;Leverage is a measure of the influence of individual data points on the
model’s parameters, measured on the scale of 0-1, where high values
indicate a strong influence on the model’s parameters.&lt;/p&gt;
&lt;p&gt;Cook’s distance is the sum of squared distances between the fitted
values using the whole data set, and the fitted values with the &lt;em&gt;i&lt;/em&gt;th
observation removed. A large difference indicates that the &lt;em&gt;i&lt;/em&gt;th
observation exerts a strong influence on the model’s parameters.&lt;/p&gt;
&lt;p&gt;No values beyond 1.&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTION: How does the QQ plot look? Does it indicate a potential
problem?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If your standardized residuals are not normally distributed you can
&lt;strong&gt;transform the dependent variable&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Let’s try a log transformation, which is commonly used:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lm1 &amp;lt;- lm(log(mpg) ~ wt, data = my_mtcars)
plot(lm1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-96-1.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-96-2.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-96-3.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-96-4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTION: Does this improve the result?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The residuals are now randomly distributed and are homogeneous. We can
now trust model results.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Continuing with interpreting results, the slope value should be
-0.3055548. This means that for each unit of weight added to a car (1
ton), the log of miles per gallon it achieves is predicted to REDUCE by
a value of 0.3055548. There is a negative effect of weight on car
efficiency.&lt;/p&gt;
&lt;p&gt;The intercept of 3.9259255 sets the start of the regression line at the
weight of zero. In this case, this isn’t very useful (a car will not
weigh zero tons) but it is a necessary element of describing a linear
relationship. Here, the equation for the line is
&lt;code&gt;log(mpg) = 3.92593 -0.30555 (wt)&lt;/code&gt;. Note that you can call the
individual coefficients from a model directly using, in this example,
“lm1$coefficients”.&lt;/p&gt;
&lt;p&gt;Now, plot again a scatterplot of weight vs. mpg and draw the regression
line, in &lt;span style=&#34;color:blue&#34;&gt;blue&lt;/span&gt;. First return your
graphing parameter to it’s default setting of (1,1)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;par(mfrow=c(1, 1))
plot(log(mpg) ~ wt, data = my_mtcars)
abline(lm1, col=&amp;quot;blue&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-97-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here are two other ways you can draw the predicted regression line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;abline(coef = lm1$coefficients, col=&amp;quot;green&amp;quot;)
abline(lm1$coefficients, col=&amp;quot;red&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;model-selection&#34;&gt;Model Selection&lt;/h3&gt;
&lt;p&gt;In any mathematical modeling approach, there may be other variables, or
some combination of variables, that are most effective and efficient at
predicting your response variable of interest. In this case, our
response variable is &lt;code&gt;mpg&lt;/code&gt;. Looking at your plot of all the two-way
relationships between variables, are there any other variables that may
help predict &lt;code&gt;mpg&lt;/code&gt;? Horsepower (&lt;code&gt;hp&lt;/code&gt;) seems to be potentially
informative. The question now is, which model might be &lt;strong&gt;best&lt;/strong&gt; at
predicting &lt;code&gt;mpg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s say we have three options: 1. mpg ~ wt 2. mpg ~ wt + hp 3. mpg ~
hp&lt;/p&gt;
&lt;p&gt;We’ve already fitted the first model. Now, fit a linear regression model
for the next two parameter combinations, giving them unique names (&lt;code&gt;lm2&lt;/code&gt;
and &lt;code&gt;lm3&lt;/code&gt;), and look at the summary of their results.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lm2 &amp;lt;- lm(log(mpg) ~ wt + hp, data = my_mtcars)
lm3 &amp;lt;- lm(log(mpg) ~ hp, data = my_mtcars)
summary(lm2)

## 
## Call:
## lm(formula = log(mpg) ~ wt + hp, data = my_mtcars)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.17048 -0.05589 -0.03043  0.07386  0.19392 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  3.8995420  0.0705574  55.268  &amp;lt; 2e-16 ***
## wt          -0.2287735  0.0284846  -8.031 1.25e-08 ***
## hp          -0.0014795  0.0003458  -4.278 0.000211 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.09807 on 27 degrees of freedom
## Multiple R-squared:  0.8857, Adjusted R-squared:  0.8772 
## F-statistic: 104.6 on 2 and 27 DF,  p-value: 1.932e-13

summary(lm3)

## 
## Call:
## lm(formula = log(mpg) ~ hp, data = my_mtcars)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.44058 -0.06574 -0.02156  0.09492  0.34549 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  3.4444246  0.0759960  45.324  &amp;lt; 2e-16 ***
## hp          -0.0032294  0.0004855  -6.652 3.22e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1773 on 28 degrees of freedom
## Multiple R-squared:  0.6125, Adjusted R-squared:  0.5986 
## F-statistic: 44.25 on 1 and 28 DF,  p-value: 3.225e-07
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you’ll see, all 3 of these models are reasonably good. Which is
optimal? You might know that when you add more independent variables to
a model, the model fit will often improve. But, it is certainly not
ideal to have a model with a large number of independent variables
(because we want to avoid overfitting). Akaike’s Information Criteria
(AIC) provides a good mechanism for model comparison. AIC ranks a
model’s performance by accounting for model fit while penalizing models
with more variables. When adding a variable, the improved fit of the
model must outweight the penalty, otherwise the improved fit will not be
deemed worthwhile given the additional model complexity.&lt;/p&gt;
&lt;p&gt;Use the &lt;code&gt;AIC&lt;/code&gt; function to compare the AIC values of our 3 models. The
lowest AIC indicates that the model is a “better” representation of the
data and has a better predictive power. Note, AIC is not a measure of
fit.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;AIC(lm1)

## [1] -35.82462

AIC(lm2)

## [1] -49.35107

AIC(lm3)

## [1] -14.73444
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What can we conclude? The best model (from the three we have tried) for
predicting miles per gallon of a car uses the horsepower and weight of
the car in the prediction (&lt;code&gt;lm2&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;To finish, let’s see if we can now use this model (&lt;code&gt;lm2&lt;/code&gt;) to predict the
fuel efficiency of a car with a &lt;code&gt;hp = 225&lt;/code&gt; and a &lt;code&gt;wt = 4.0&lt;/code&gt; tons. Making
prediction with a new set of independent variables when dependent
variable is absent, is ultimately one of the main goals of a regression
analyses.&lt;/p&gt;
&lt;p&gt;First, we need a dataframe with our new independent variables to be used
in the prediction. Then, we can use the &lt;code&gt;predict()&lt;/code&gt; function to apply
our established linear model to the new information. Lastly, we need to
transform miles per gallon back from the log scale to make it more
easily interpretable.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nd &amp;lt;- data.frame(hp = 225, wt = 4.0)
exp(predict(lm2, newdata = nd, type = &amp;quot;response&amp;quot;))

##        1 
## 14.17612
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can get this same result without using the &lt;code&gt;predict&lt;/code&gt; command, simply
by writing out the linear equation. That is, our predicted response
equals our intercept term, plus our coefficient for &lt;code&gt;wt&lt;/code&gt; multiplied by
the weight value, plus our coefficient for &lt;code&gt;hp&lt;/code&gt; multiplied by our
horsepower value (The function &lt;code&gt;predict()&lt;/code&gt; just makes things a little
easier for us). That is:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; = &lt;em&gt;β&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt; + &lt;em&gt;β&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;em&gt;x&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt; + &lt;em&gt;ϵ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;We must also use the &lt;code&gt;exp()&lt;/code&gt; function to back-transform from the
log-scale.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;exp(lm2$coefficients[[1]] + (lm2$coefficients[[2]]*4.0) + (lm2$coefficients[[3]]*225))

## [1] 14.17612
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;analysis-of-variance-anova&#34;&gt;Analysis of Variance: ANOVA&lt;/h2&gt;
&lt;p&gt;The analysis of variance (ANOVA) is a lineal model, but the explanatory
variable is categorical. As we saw before, the categorical variable must
be a factor. Remember that if the category has been coded with numbers,
&lt;strong&gt;R&lt;/strong&gt; will assume the variable is continuous.&lt;/p&gt;
&lt;p&gt;We will continue working with the &lt;code&gt;mtcars&lt;/code&gt; data set. As we did before,
we specified cylinders as a categorical variable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mtcars$cyl &amp;lt;- as.factor(mtcars$cyl)
class(mtcars$cyl)

## [1] &amp;quot;factor&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;one-way-anova&#34;&gt;One-way ANOVA&lt;/h3&gt;
&lt;p&gt;Here we ask the question, do different cylinders imply more power?&lt;/p&gt;
&lt;p&gt;Our hypothesis (&lt;em&gt;H&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;) is that more cylinders will provide
more power to the car, expressed in gross horsepower (HP). The null
hypothesis (&lt;em&gt;H&lt;/em&gt;&lt;sub&gt;0&lt;/sub&gt;) is that there is no difference in HP among
number of cylinders.&lt;/p&gt;
&lt;p&gt;To perform an ANOVA in &lt;strong&gt;R&lt;/strong&gt;, we use the function &lt;code&gt;aov()&lt;/code&gt; and
&lt;code&gt;summary()&lt;/code&gt; to see the results.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model1 &amp;lt;- aov(hp ~ cyl, data=mtcars)
summary(model1)

##             Df Sum Sq Mean Sq F value   Pr(&amp;gt;F)    
## cyl          2 104031   52015   36.18 1.32e-08 ***
## Residuals   29  41696    1438                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the results, the table shows us a &lt;em&gt;p-value&lt;/em&gt;, representing the overall
probability of significance for the categorical variable. If the term is
significant, then we know at least one level is significantly different
from the others.&lt;/p&gt;
&lt;p&gt;We can reject the null hypothesis and conclude that gross horsepower
differs among different number of cylinders.&lt;/p&gt;
&lt;p&gt;However, before we know we can trust this result, we need to check the
model assumptions. We will do this in the same way we did for the lineal
model, using &lt;code&gt;plot()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plot(model1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-105-1.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-105-2.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-105-3.png&#34; alt=&#34;&#34;&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-105-4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;From the second plot we can conclude that the residuals are normally
distributed (straight line). From the first and third plots, we can see
that the variances of the residuals are homogeneous (homoscedasticity).
From the final plot, we can conclude that the model is not biased by
unduly influential observations.&lt;/p&gt;
&lt;h3 id=&#34;pairwise-port-hoc-tests&#34;&gt;Pairwise port-hoc tests&lt;/h3&gt;
&lt;p&gt;To understand how levels compare to each other once we know that the
ANOVA is significant, we can use a post-hoc test. We will use the
&lt;strong&gt;Tukey post-hoc test&lt;/strong&gt; with the function &lt;code&gt;TukeyHSD()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;TukeyHSD(model1)

##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = hp ~ cyl, data = mtcars)
## 
## $cyl
##          diff       lwr       upr     p adj
## 6-4  39.64935 -5.627454  84.92616 0.0949068
## 8-4 126.57792 88.847251 164.30859 0.0000000
## 8-6  86.92857 43.579331 130.27781 0.0000839
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;diff&lt;/strong&gt; is the difference in mean between two levels, &lt;strong&gt;lwr&lt;/strong&gt; and
&lt;strong&gt;upr&lt;/strong&gt; are the lower and upper 95% confidence intervals for the
difference and &lt;strong&gt;padj&lt;/strong&gt; is the &lt;code&gt;p-value&lt;/code&gt; for the difference.&lt;/p&gt;
&lt;p&gt;In this example, we can see that there is not HP significant difference
between 6 and 4 cylinders (&lt;code&gt;p &amp;gt; 0.05&lt;/code&gt;), and that 8 cylinders have more
HP than 4 and 6 cylinders (&lt;code&gt;p &amp;lt; 0.05&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id=&#34;non-parametric-random-forest-model&#34;&gt;Non-parametric Random Forest Model&lt;/h2&gt;
&lt;p&gt;In the past few decades, there has been an increasing number of studies
that use non-parametric machine learning models for classification or
regression. In the most simplistic of terms, non-parametric/machine
learning models do not require the predictive variables to take a
predetermined distribution (e.g. normal distribution). They are also
relatively less stringent in terms of model assumptions.&lt;/p&gt;
&lt;p&gt;One of the most popular and also most powerful machine learning tools is
Random Forest. Random Forests is an ensemble method for classification-
or regression-typed analyses that operate by constructing a series of
decision trees. We will not go into detail to discuss the Random Forest
algorithm or how it works. But in general, Random Forest models perform
really well when there are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Large number of independent variables.&lt;/li&gt;
&lt;li&gt;Significant correlation among independent variables.&lt;/li&gt;
&lt;li&gt;Independent variables that are not normally distributed.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;random-forest-regression&#34;&gt;Random Forest Regression&lt;/h3&gt;
&lt;p&gt;Although the Random Forest algorithm is complicated, running a Random
Forest model in &lt;strong&gt;R&lt;/strong&gt; is as easy as running a linear model. For the most
part, we just need to specify the data set, and the regression model
formula. Let’s use the “mtcars” data set again for this example.&lt;/p&gt;
&lt;p&gt;Load the “mtcars”” data set, and load the random forest package.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;randomForest&amp;quot;)

data(mtcars)
library( randomForest)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s run a model that includes all metrics in the data set to
predict the &lt;code&gt;mpg&lt;/code&gt; of a car.&lt;/p&gt;
&lt;p&gt;Note that in the following code, the formula was simplified &lt;code&gt;mpg ~ .&lt;/code&gt;.
The &lt;code&gt;.&lt;/code&gt;. represents the rest of the columns in the dataframe that are
not defined as predictive variable. Whenever you have a dataframe that
contains only the independent and dependent variables you need in the
model, you can simplify the formula in this way. This essentially tells
&lt;strong&gt;R&lt;/strong&gt; to use all the variables included in the dataframe.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rf.model&amp;lt;-  randomForest(mpg ~ ., data=mtcars)
rf.model

## 
## Call:
##  randomForest(formula = mpg ~ ., data = mtcars) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##           Mean of squared residuals: 5.8623
##                     % Var explained: 83.34
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that one of the most important results of Random Forest is the “%
variance explained”. It can be considered equivalet to a &lt;em&gt;R&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;
value in a linear models quantifying how “good” the model fits the data.
The closer the “% var explained” is to 100, the better the model’s
performance.&lt;/p&gt;
&lt;p&gt;Here you can see the default number of trees used in the model is 500.
In reality, the number of tree is one of very few parameters that need
to be modified by the user. The number of trees determines the number of
ensemble models that are created in the modeling process. As we increase
the tree number, the model results will tend to vary and eventually
stabilize. But we don’t want to create too many ensemble tree models
because it will take more computational time. The general rule is to
increase the number of trees incrementally until the value of “% var
explained” changes very little.&lt;/p&gt;
&lt;p&gt;Let’s change the default number of trees parameter to 1000 and 5000 and
observe the difference in model results&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rf.model.1000&amp;lt;- randomForest( mpg ~ ., data=mtcars, ntree=1000)
rf.model.1000

## 
## Call:
##  randomForest(formula = mpg ~ ., data = mtcars, ntree = 1000) 
##                Type of random forest: regression
##                      Number of trees: 1000
## No. of variables tried at each split: 3
## 
##           Mean of squared residuals: 5.728827
##                     % Var explained: 83.72

rf.model.5000&amp;lt;- randomForest( mpg ~ ., data=mtcars, ntree=5000)
rf.model.5000

## 
## Call:
##  randomForest(formula = mpg ~ ., data = mtcars, ntree = 5000) 
##                Type of random forest: regression
##                      Number of trees: 5000
## No. of variables tried at each split: 3
## 
##           Mean of squared residuals: 5.650456
##                     % Var explained: 83.94
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The bigger number of trees (&lt;code&gt;ntree&lt;/code&gt;) does not change the “% var
explained” significantly. So the default &lt;code&gt;ntree= 500&lt;/code&gt; is as good as
&lt;code&gt;ntree= 1000&lt;/code&gt; or &lt;code&gt;ntree=5000&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Lastly, a convenient feature of Random Forest model is that it
internally summarizes how important each variable is to model
performance. The model does this by replacing each predictive variable
separately with randomly permuted values. After running the model with
replacement, the more the model accuracy decreases, the more important
the specific variable (that was replaced in the process) is. You can
retrieve and visualize the variable importance data using &lt;code&gt;importance()&lt;/code&gt;
and &lt;code&gt;varImPlot()&lt;/code&gt; functions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;importance(rf.model)        

##      IncNodePurity
## cyl      167.20002
## disp     249.45925
## hp       198.12700
## drat      65.09282
## wt       242.46816
## qsec      31.99083
## vs        32.47995
## am        14.66387
## gear      15.03880
## carb      29.43084

varImpPlot(rf.model)  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-111-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note that “IncNodePurity” is just a measure of how much the model
performance has decreased. The higher that value, the more important the
variable is.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTION: Which variable is contributing most to predicting mpg of a
car?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Lastly, just as with all the other models, the most powerful use of
Random Forest model is to predict the dependent variable when you have a
set of independent variables. You can, once again, use the &lt;code&gt;predict()&lt;/code&gt;
function to perform this action. Below, we will create a fictitious car,
changing the Hornet-4 Drive from 6 cylinder to 8 cylinders. We want to
know what the mpg of this new car is.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;new.car&amp;lt;- mtcars[4,]
new.car$cyl&amp;lt;- 8
new.car

##                 mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Hornet 4 Drive 21.4   8  258 110 3.08 3.215 19.44  1  0    3    1

predict(rf.model, newdata = new.car, type = &amp;quot;response&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;QUESTIONS:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Do you think the prediction make sense? Why?&lt;/li&gt;
&lt;li&gt;Can you build a random forest classification model to predict the
number of cylinders based on other metrics included in the
dataset?&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;generalized-linear-models&#34;&gt;Generalized Linear Models&lt;/h2&gt;
&lt;p&gt;A primary goal of basic ecological and applied conservation research is
to understand how species are distributed across space and through time.
However, animal locations or abundance data typically cannot be modelled
by a normal distribution. As a result, other types of model structures
are needed.&lt;/p&gt;
&lt;p&gt;Generalized linear models (GLM) are used when the residuals are
non-normal, when there are non-linear relationships between dependent
and independent variables, and/or when the variance in the dependent
variable is not uniform across its range. E.g., presence-absence data,
count data.&lt;/p&gt;
&lt;p&gt;GLMs consist of three elements:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A probability distribution from the exponential family.&lt;/li&gt;
&lt;li&gt;A linear predictor &lt;em&gt;η&lt;/em&gt; = &lt;em&gt;X**β&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;A link function &lt;em&gt;g&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A GLM allows the specification of a variety of different error
distributions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Poisson errors (useful with count data)&lt;/li&gt;
&lt;li&gt;Binomial errors (useful with data on proportions)&lt;/li&gt;
&lt;li&gt;Gamma errors (useful with data showing a constant coefficient of
variation)&lt;/li&gt;
&lt;li&gt;Exponential errors (useful with data on time to event - e.g.,
survival analysis)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The linear predictor η (eta) is the quantity which incorporates the
information about the independent variables into the model. It is
related to the expected value of the dependent variable through the link
function.&lt;/p&gt;
&lt;p&gt;η is expressed as linear combinations of unknown parameters β.&lt;/p&gt;
&lt;p&gt;The linear predictor can be represented as a vector of coefficient
values that is multiplied the matrix containing your independent
variables  X. . η can thus be expressed as &lt;em&gt;η&lt;/em&gt; = &lt;em&gt;X**β&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The link function &lt;code&gt;g&lt;/code&gt; provides the relationship between the linear
predictor and the mean, or expected value, of the distribution function.&lt;/p&gt;
&lt;p&gt;There are many commonly used link functions, and their choice can seem
somewhat arbitrary. It can be convenient to match the domain of the link
function to the range of the distribution function’s mean.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;FIGURES/IntroToDataAnalysis_Picture1.png&#34;
alt=&#34;Commonly used link functions&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;Commonly used link functions&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;binomial-glm-for-binary-data-logistic-regressionlogistic-glm&#34;&gt;Binomial GLM for binary data (logistic regression/logistic GLM)&lt;/h3&gt;
&lt;p&gt;A logistic regression model allows us to establish a relationship
between a binary (0 vs. 1) outcome variable and a group of predictor
variables. It models the logit-transformed probability of a certain
outcome as a linear relationship with the predictor variables.&lt;/p&gt;
&lt;p&gt;To demonstrate how linear regression model works, we will use the
following study:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/1051-0761(1997)007%5B0552:RORTHF%5D2.0.CO;2&#34;&gt;Bolger et
al. (1997)&lt;/a&gt;
investigated the impacts of habitat fragmentation on the occurrence of
native rodents. &lt;a href=&#34;https://www2.ib.unicamp.br/profs/fsantos/apostilas/Quinn%20&amp;amp;%20Keough.pdf&#34;&gt;Quinn and Keough
(2002)&lt;/a&gt;
subsequently modeled the presence/absence native rodents against some
Bolger et al. (1997) biogeographic variables.&lt;/p&gt;
&lt;p&gt;Bolger et al. (1997) studied whether small fragments of the shrub
habitats in canyons of San Diego, CA, isolated by urbanization, were
capable of supporting viable populations of native rodent species.&lt;/p&gt;
&lt;p&gt;The data set consists of rodent presence/absence and three predictor
variables: 1. PERSHRUB = percentage of shrub cover 2. DISTX = the
distance to the nearest large (&amp;gt;100 ha) “source canyon.” 3. AGE =
time elapsed since the fragment was isolated by development&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;FIGURES/BolderStudyArea.jpg&#34; alt=&#34;From Bolger et al. 1997&#34; /&gt;
&lt;figcaption aria-hidden=&#34;true&#34;&gt;From Bolger et al. 1997&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr&gt;
&lt;p&gt;For this demonstration we need to install and load a new package.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#install.packages(&amp;quot;usdm&amp;quot;) #Install package if it is not installed in your computer.
library(usdm)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;import-data-set&#34;&gt;Import data set&lt;/h3&gt;
&lt;p&gt;Import the data set suing the ‘read.table’ function. The data for this
example is in a .txt format. &lt;code&gt;Read.table&lt;/code&gt; will read the .txt file and
load it as a data frame into the &lt;strong&gt;R&lt;/strong&gt; environment.&lt;/p&gt;
&lt;p&gt;Look at the first lines of data using the &lt;code&gt;head&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bolger &amp;lt;- read.table(&amp;quot;data/bolger.txt&amp;quot;, header=T, sep= &amp;quot;&amp;quot;)
head(bolger)

##   PERSHRUB DISTX AGE RODENTSP
## 1       66  2100  50        1
## 2       90   914  20        1
## 3       75  1676  34        1
## 4       75   243  34        1
## 5       60   822  16        1
## 6       50   121  14        1
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: It is often best to rescale continuous covariates to improve
numerical stability in the models. We will skip this step for this
example, but we will look into scaling in other examples.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;investigate-potential-multicollinearity&#34;&gt;Investigate potential (multi)collinearity&lt;/h3&gt;
&lt;p&gt;When we fit a model we assume that the estimated effects of predictor
variables are independent of each other. Thus, before we fit a model we
first need to check our independent variables for potential
collinearity.&lt;/p&gt;
&lt;p&gt;Collinearity occurs when 2 or more independent variables have a strong
linear relationship, making it difficult to determine which of the two
collinear variables are more strongly associated with the response
variable. Collinearity affects parameter estimates and increases both
standard errors and p-values of parameters, likely obscuring some
important relationships.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plot(bolger[,1:3])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-115-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;To make sure we do not have a (multi)collinearity problem in our
predictor variables, we can look at the Variance Inflation Factor (VIF)
for each covariate. Variance inflation is a measure of the degree of
collinearity between variables. Any variables with a VIF value &amp;gt; to 3
(or 5 or 10 depending who you ask) are the cause of concerning
collinearity in the model. If a covariate has a VIF &amp;gt; 3, remove it
(or other correlated variables) and recalculate VIF after deletion.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vifstep(bolger[,1:3])

## No variable from the 3 input variables has collinearity problem. 
## 
## The linear correlation coefficients ranges between: 
## min correlation ( DISTX ~ PERSHRUB ):  -0.2745893 
## max correlation ( AGE ~ PERSHRUB ):  -0.7952976 
## 
## ---------- VIFs of the remained variables -------- 
##   Variables      VIF
## 1  PERSHRUB 2.743579
## 2     DISTX 1.093362
## 3       AGE 2.750798
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our example there is no evidence of collinearity as all VIFs are &amp;lt;
3. Good!&lt;/p&gt;
&lt;h3 id=&#34;fit-a-binomial-glm&#34;&gt;Fit a Binomial GLM&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;bolger.glm &amp;lt;- glm(RODENTSP ~ DISTX + AGE + PERSHRUB,
                family=binomial (link= &amp;quot;logit&amp;quot;),
                data=bolger)
summary(bolger.glm)

## 
## Call:
## glm(formula = RODENTSP ~ DISTX + AGE + PERSHRUB, family = binomial(link = &amp;quot;logit&amp;quot;), 
##     data = bolger)
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&amp;gt;|z|)  
## (Intercept) -5.9099159  3.1125426  -1.899   0.0576 .
## DISTX        0.0003087  0.0007741   0.399   0.6900  
## AGE          0.0250077  0.0376618   0.664   0.5067  
## PERSHRUB     0.0958695  0.0406119   2.361   0.0182 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 34.617  on 24  degrees of freedom
## Residual deviance: 19.358  on 21  degrees of freedom
## AIC: 27.358
## 
## Number of Fisher Scoring iterations: 5
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;model-assumptions-validation&#34;&gt;Model assumptions validation&lt;/h3&gt;
&lt;p&gt;In the case of a linear model, we used ‘plot(model1)’ to check the
standardized residuals for any “patterns”. For binomial data, however,
you will just see two bands in the residuals due to the binomial nature
of the dependent variable.&lt;/p&gt;
&lt;p&gt;What we need to check is evidence of model fit, thus, that the model
fits the data well. To do this we extract the &lt;strong&gt;deviance residuals&lt;/strong&gt; and
examine their distribution. Observations with a deviance residual &amp;gt; 2
may indicate a lack of fit.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;devresid&amp;lt;-resid(bolger.glm, type = &amp;quot;deviance&amp;quot;)
hist(devresid)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-118-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this case, we can conclude there is no strong evidence of lack of
fit. We can now feel confident about our model to make interpretations.&lt;/p&gt;
&lt;h3 id=&#34;model-interpretation-and-predictions&#34;&gt;Model interpretation and predictions&lt;/h3&gt;
&lt;p&gt;Let’s look again at the model summary:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summary(bolger.glm)

## 
## Call:
## glm(formula = RODENTSP ~ DISTX + AGE + PERSHRUB, family = binomial(link = &amp;quot;logit&amp;quot;), 
##     data = bolger)
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&amp;gt;|z|)  
## (Intercept) -5.9099159  3.1125426  -1.899   0.0576 .
## DISTX        0.0003087  0.0007741   0.399   0.6900  
## AGE          0.0250077  0.0376618   0.664   0.5067  
## PERSHRUB     0.0958695  0.0406119   2.361   0.0182 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 34.617  on 24  degrees of freedom
## Residual deviance: 19.358  on 21  degrees of freedom
## AIC: 27.358
## 
## Number of Fisher Scoring iterations: 5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The chance of native rodent occurrence increases significantly with
increasing shrub cover (&lt;em&gt;B&lt;/em&gt; = 0.096, &lt;em&gt;p&lt;/em&gt; = 0.0182). Neither fragment
isolation age or distance had significant effects.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;FIGURES/logregeq.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The default results are on the logit scale. The coefficient of PERSHRUB
is: 0.096, so that a one unit change in percentage of shrub cover
produces approximately a 0.096 unit change in the log odds of presence
(i.e. a 0.096 unit change on the logit scale).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The odds of presence are defined as the ratio of the probability of
presence over the probability of absence. For instance, if the
probability of presence is 0.8 and the probability of absence is 0.2,
the odd ratios is 0.8/0.2=4, or the odds of presence are 4 to 1. For
more information on how to interpret odds visit:
&lt;a href=&#34;https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/&#34;&gt;https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is hard to think in terms of logits. We can plot the association
between the probability of native rodent presence and percentage shrub
cover.&lt;/p&gt;
&lt;p&gt;See how the code for this plot has gotten much longer and more complex.
Make sure you understand each line of code. Remember to use the &lt;code&gt;help&lt;/code&gt;
command when you do not understand a specific function and all its
arguments.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xs &amp;lt;- seq(0, 100, 1)
bolger.predict &amp;lt;- predict(bolger.glm, type=&amp;quot;response&amp;quot;, se=T, 
                          newdata=data.frame(DISTX=mean(bolger$DISTX), AGE=mean(bolger$AGE), PERSHRUB=xs))

# Plot results
plot(bolger$RODENTSP ~ bolger$PERSHRUB, xlab=&amp;quot;Pecentage shrub cover&amp;quot;, ylab=&amp;quot;Rodent presence probability&amp;quot;, axes=T, pch=16)
lines(bolger.predict$fit~xs, type=&amp;quot;l&amp;quot;, col=&amp;quot;gray&amp;quot;)
lines(bolger.predict$fit + bolger.predict$se.fit~xs, col=&amp;quot;red&amp;quot;, type= &amp;quot;l&amp;quot;, lty=2)
lines(bolger.predict$fit - bolger.predict$se.fit~xs, col=&amp;quot;red&amp;quot;, type= &amp;quot;l&amp;quot;, lty=2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;00-Preface_files/figure-markdown_strict/unnamed-chunk-120-1.png&#34; alt=&#34;&#34;&gt;
***&lt;/p&gt;
&lt;p&gt;What is the probability of native rodent occurrence with a shrub cover
of 80%, distanceX of 100, and fragment isolation age of 5.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;predict(bolger.glm, type=&amp;quot;response&amp;quot;, se=T, newdata=data.frame(DISTX=100, AGE=5, PERSHRUB=80))

## $fit
##         1 
## 0.8716415 
## 
## $se.fit
##         1 
## 0.1277815 
## 
## $residual.scale
## [1] 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the predict function already converts values from the logit
scale back to the probability scale.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;FIGURES/invlogit.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;To do that manually, we can do the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x &amp;lt;- -5.9099159 + 0.0003087*100 + 0.0250077 * 5 + 0.0958695 * 80
exp(x)/(exp(x)+1) # This is the inverse of the logit scale

## [1] 0.8716417

plogis(x) # Use a built in function

## [1] 0.8716417
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;This is the end of part 1. In the next section, we will learn to do spatial analyses in R. We will then combine modeling with spatial analysis in a case study.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Moving through the mosaic: identifying critical linkage zones for large herbivores across a multiple‐use African landscape</title>
      <link>//localhost:4321/papers/article21/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article21/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hello R Markdown</title>
      <link>//localhost:4321/post/2020-12-01-r-rmarkdown/</link>
      <pubDate>Tue, 01 Dec 2020 21:13:14 -0500</pubDate>
      <guid>//localhost:4321/post/2020-12-01-r-rmarkdown/</guid>
      <description>&lt;h1 id=&#34;r-markdown&#34;&gt;R Markdown&lt;/h1&gt;
&lt;p&gt;This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;a href=&#34;http://rmarkdown.rstudio.com&#34;&gt;http://rmarkdown.rstudio.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can embed an R code chunk like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cars&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##      speed           dist       &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##  Min.   : 4.0   Min.   :  2.00  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##  1st Qu.:12.0   1st Qu.: 26.00  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##  Median :15.0   Median : 36.00  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##  Mean   :15.4   Mean   : 42.98  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##  3rd Qu.:19.0   3rd Qu.: 56.00  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##  Max.   :25.0   Max.   :120.00&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dist&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;speed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cars&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## Call:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## lm(formula = dist ~ speed, data = cars)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## Coefficients:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;## (Intercept)        speed  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##     -17.579        3.932&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;including-plots&#34;&gt;Including Plots&lt;/h1&gt;
&lt;p&gt;You can also embed plots. See Figure &lt;a href=&#34;#fig:pie&#34;&gt;1&lt;/a&gt; for example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;par&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;pie&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;280&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;60&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;Sky&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;Sunny side of pyramid&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;Shady side of pyramid&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;#0292D8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;#F7EA39&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;#C4B632&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;init.angle&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;-50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;border&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;//localhost:4321/post/2020-12-01-r-rmarkdown/index.en_files/figure-html/pie-1.png&#34; alt=&#34;A fancy pie chart.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;span id=&#34;fig:pie&#34;&gt;&lt;/span&gt;Figure 1: A fancy pie chart.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Colaboración científica con la Armada de Chile en estudios ornitológicos a largo plazo en el archipiélago Diego Ramírez: Primer monitoreo del ciclo anual del ensamble de aves en la isla Gonzalo</title>
      <link>//localhost:4321/papers/article20/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article20/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Un centinela para el monitoreo del cambio climático y su impacto sobre la biodiversidad en la cumbre austral de América: La nueva red de estudios a largo Plazo Cabo de Hornos</title>
      <link>//localhost:4321/papers/article19/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nest-site selection and breeding success of passerines in the world’s southernmost forests</title>
      <link>//localhost:4321/papers/article17/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article17/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Unexpected lack of effect of the invasive American mink on the nesting survival of forest birds</title>
      <link>//localhost:4321/papers/article18/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Laikipia Shiny app</title>
      <link>//localhost:4321/project/laikipia/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/project/laikipia/</guid>
      <description>&lt;p&gt;I have designed this Shiny app to help managers visualize the results of our studies across Laikipia, Kenya, and make decisions on the ground related to livestock management, fence deployment and their effects on herbivore species richness and landscape connectivity, and species abundance.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Spatiotemporal dynamics of wild herbivore species richness and occupancy across a savannah rangeland: Implications for conservation</title>
      <link>//localhost:4321/papers/article16/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article16/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Breeding strategies of open-cup-nesting birds in sub-Antarctic forests of Navarino Island, Chile</title>
      <link>//localhost:4321/papers/article15/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article15/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New records of invasive mammals from the sub-Antarctic Cape Horn Archipelago</title>
      <link>//localhost:4321/papers/article14/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article14/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fur Trade and the Biotic Homogenization of Subpolar Ecosystems</title>
      <link>//localhost:4321/books/book1/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/books/book1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Los ojos del árbol: percibiendo, registrando, comprendiendo y contrarrestando las invasiones biológicas en tiempos de rápida homogeneizacion biocultural</title>
      <link>//localhost:4321/papers/article13/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article13/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Macro- and micro-habitat selection of small rodents and their predation risk perception under a novel invasive predator at the southern end of the Americas</title>
      <link>//localhost:4321/papers/article11/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article11/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Potential niche expansion of the American mink invading a remote island free of native-predatory mammals</title>
      <link>//localhost:4321/papers/article12/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article12/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Management regime mediates the precipitation-vegetation relationship in rangelands: Implications for ‘climate-smart’ ecological restoration planning</title>
      <link>//localhost:4321/posters/poster4/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Native-predator-invasive-prey trophic interactions in Tierra del Fuego: the beginning of biological resistance?</title>
      <link>//localhost:4321/papers/article10/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article10/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Primer registro de Vespula vulgaris (Linnaeus 1758) (Hymenoptera: Vespidae) en la isla Navarino, Chile</title>
      <link>//localhost:4321/papers/article9/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article9/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A synergistic trio of invasive mammals? Facilitative interactions among beavers, muskrats, and mink at the southern end of the Americas</title>
      <link>//localhost:4321/papers/article8/</link>
      <pubDate>Wed, 01 Jun 2016 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article8/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Seasonal dynamic habitat use suggests niche expansion of an invasive predator at the southernmost forest of the world</title>
      <link>//localhost:4321/posters/poster7/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster7/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Expansión de la invasión del Visón Norteamericano (Neovison vison) en la Reserva de la Biosfera de Cabo de Hornos, Chile</title>
      <link>//localhost:4321/papers/article7/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article7/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Filosofía ambiental de campo: ecología y ética en las redes LTER-Chile e ILTER</title>
      <link>//localhost:4321/papers/article6/</link>
      <pubDate>Mon, 01 Sep 2014 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Potential impact of the alien American mink (Neovison vison) on Magellanic woodpeckers (Campephilus magallanicus) in Navarino Island, southern Chile</title>
      <link>//localhost:4321/papers/article5/</link>
      <pubDate>Tue, 01 Jul 2014 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Climate change and conservation implications for wet meadows in dry Patagonia</title>
      <link>//localhost:4321/papers/article4/</link>
      <pubDate>Sun, 01 Jun 2014 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modeling meadow distribution for conservation action in arid and semi-arid Patagonia, Argentina</title>
      <link>//localhost:4321/papers/article3/</link>
      <pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Capturing and radio ear-tagging neonatal vicuñas</title>
      <link>//localhost:4321/papers/article2/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Assessing habitat preference of invasive minks (Neovison vison) using trap-cameras in Navarino Island, Chile</title>
      <link>//localhost:4321/posters/poster6/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Breeding strategies of passerines in the world’s southernmost forests</title>
      <link>//localhost:4321/posters/poster8/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster8/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Identifying nesting habitats of shorebirds under mink predation in subantarctic environments</title>
      <link>//localhost:4321/posters/poster9/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster9/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Movement patterns around dens in two Illinois beaver populations</title>
      <link>//localhost:4321/posters/poster1/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Donkey and guanacos abundances and group characteristics before and after donkey removal in Northwestern Argentina</title>
      <link>//localhost:4321/posters/poster5/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Una técnica para la estimación de la densidad y el monitoreo de poblaciones de inambú común (Nothura maculosa) en ambientes de pastizal</title>
      <link>//localhost:4321/papers/article1/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/papers/article1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Capturing and marking newborn vicuñas with ear tag transmitters at San Guillermo National Park, Argentina</title>
      <link>//localhost:4321/posters/poster3/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Vigilant and foraging budgets of vicuñas (Vicugna vicugna) in habitats with different vegetation structure</title>
      <link>//localhost:4321/posters/poster2/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/posters/poster2/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>//localhost:4321/experience/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>//localhost:4321/experience/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
